## 01. What I Learned

> 캐글 커널 커리큘럼을 통해 배운 것을 정리한 것입니다.
>
> 첫번째 캐글 커널은 [타이타닉](https://www.kaggle.com/c/titanic) 입니다.

<br>

### 1. [첫번째 커널](https://kaggle-kr.tistory.com/17?category=868316)

> 첫번재 필사 커널은 EDA 중심
>
> [본인이 공부한 내용]([https://github.com/donge-can/kaggle_practice/blob/master/01.%20titanic/1.%20titanic_pilsa_01.ipynb](https://github.com/donge-can/kaggle_practice/blob/master/01. titanic/1. titanic_pilsa_01.ipynb))

#### 1.1 plot style 일괄 설정

```python
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('seaborn')
sns.set(font_scale=2.5)
```

- graph의 font_size를 일일이 설정할 필요 없음

<br>

### 1.2 warnings 설정

```python
import warnings
warnings.filterwarnings('ignore')
```

- 불필요한 경고창 생략

<br>

#### 1.3 Missingno 모듈

- 결측치 시각화 모듈
- 구체적인 내용은, [Missingno정리]([https://github.com/donge-can/EDA/blob/master/05.%20missingno.ipynb](https://github.com/donge-can/EDA/blob/master/05. missingno.ipynb)) 

<br>

#### 1.4 Subplot 과 Subplots 

- 여러 그래프를 동시에 보고 싶을 때 사용
- 구체적인 내용은 [subplot 과 subplots]([https://github.com/donge-can/EDA/blob/master/04.%20subplot%2C%20subplots.ipynb](https://github.com/donge-can/EDA/blob/master/04. subplot%2C subplots.ipynb))

<br>

### 2. [두번째 커널](https://www.kaggle.com/ash316/eda-to-prediction-dietanic)

> [본인이 공부한 내용]([https://github.com/donge-can/kaggle_practice/blob/master/01.%20titanic/1.%20titanic_pilsa_02.ipynb](https://github.com/donge-can/kaggle_practice/blob/master/01. titanic/1. titanic_pilsa_02.ipynb))
>
> 간단한 Feature Engineering 이해

#### 2.1 pd.qcut

- 동일한 개수를 갖는 범주 만들기
- 구체적인 내용은 [cut_qcut]([https://github.com/donge-can/EDA/blob/master/17.%20cut_qcut.ipynb](https://github.com/donge-can/EDA/blob/master/17. cut_qcut.ipynb))

```python
data["Fare_Range"] = pd.qcut(data["Fare"], 4)
# qcut : 동일 개수로 나누어서 범주 만들기
```

- 4개의 범주 만들기 - 해당 범주는 모두 동일한 value_counts()를 갖는다.

<br>

#### 2.2 앙상블

- 구체적인 내용은 [앙상블 정리]([https://github.com/donge-can/MachineLearning/blob/master/06.%20%EC%95%99%EC%83%81%EB%B8%94(Ensemble).md](https://github.com/donge-can/MachineLearning/blob/master/06. 앙상블(Ensemble).md)
  - AdaBoost, Gradient Boosting, XGBoost

<br>

### 3. [세번째 커널](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling)

> [본인이 공부한 내용]([https://github.com/donge-can/kaggle_practice/blob/master/01.%20titanic/1.%20titanic_pilsa_03.ipynb](https://github.com/donge-can/kaggle_practice/blob/master/01. titanic/1. titanic_pilsa_03.ipynb))
>
> 앙상블이 중심

#### 3.1 이상치 탐지

- outlier 를 분위수를 이용해서 확인했다.
- 통계적 접근으로, 분위수를 확인한 점이 인상적

<br>

#### 3.2 더미 변수 만들기(One-Hot Encoding)

- `get_dummies` 활용

<br>

#### 3.3 조건에 맞는 인덱스 찾기

- `np.argsort`
- 구체적인 내용은 [numpy argsort](https://blog.naver.com/bosongmoon/221791527433)

<br>

#### 3.4 부족한 점

- `plt_learning_curve` 사용자 함수를 아직 이해하지 못했다. 특히, 그래프 해석 부분에서 부족함을 많이 느낌

<br>

### 4. [네번째 커널](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python)

> [본인이 공부한 내용]([https://github.com/donge-can/kaggle_practice/blob/master/01.%20titanic/1.%20titanic_pilsa_04.ipynb](https://github.com/donge-can/kaggle_practice/blob/master/01. titanic/1. titanic_pilsa_04.ipynb))
>
> 객체 지향 앙상블 API

#### 4.1 객체지향 모델링

- `SklearnHelper` , `get_oof` 


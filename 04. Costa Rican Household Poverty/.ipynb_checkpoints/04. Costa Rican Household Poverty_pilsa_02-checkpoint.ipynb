{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(font_scale=2.2)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import featuretools as ft\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/user/Desktop/kaggle_data/04. costa-rican-household-poverty-prediction/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1. Check datasets\n",
    "#### 1.1 Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path+'train.csv')\n",
    "df_test = pd.read_csv(path+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (9557, 143)    df_test shape:  (23856, 142)\n"
     ]
    }
   ],
   "source": [
    "print('df_train shape:', df_train.shape, '  ', 'df_test shape: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
       "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
       "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
       "0     0  ...          100    1849               1        100             0   \n",
       "1     0  ...          144    4489               1        144             0   \n",
       "2     0  ...          121    8464               1          0             0   \n",
       "3     0  ...           81     289              16        121             4   \n",
       "4     0  ...          121    1369              16        121             4   \n",
       "\n",
       "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
       "0         1.000000            0.0      100.0   1849       4  \n",
       "1         1.000000           64.0      144.0   4489       4  \n",
       "2         0.250000           64.0      121.0   8464       4  \n",
       "3         1.777778            1.0      121.0    289       4  \n",
       "4         1.777778            1.0      121.0   1369       4  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_2f6873615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1c78846d2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>256</td>\n",
       "      <td>1681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_e5442cf6a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>289</td>\n",
       "      <td>1681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_a8db26a79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>256</td>\n",
       "      <td>3481</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256.00</td>\n",
       "      <td>3481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_a62966799</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>121</td>\n",
       "      <td>324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>64.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_2f6873615       NaN       0      5       0     1       1     0    NaN   \n",
       "1  ID_1c78846d2       NaN       0      5       0     1       1     0    NaN   \n",
       "2  ID_e5442cf6a       NaN       0      5       0     1       1     0    NaN   \n",
       "3  ID_a8db26a79       NaN       0     14       0     1       1     1    1.0   \n",
       "4  ID_a62966799  175000.0       0      4       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  age  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  \\\n",
       "0     1  ...    4            0      16               9          0   \n",
       "1     1  ...   41          256    1681               9          0   \n",
       "2     1  ...   41          289    1681               9          0   \n",
       "3     0  ...   59          256    3481               1        256   \n",
       "4     0  ...   18          121     324               1          0   \n",
       "\n",
       "   SQBhogar_nin  SQBovercrowding  SQBdependency  SQBmeaned  agesq  \n",
       "0             1             2.25           0.25     272.25     16  \n",
       "1             1             2.25           0.25     272.25   1681  \n",
       "2             1             2.25           0.25     272.25   1681  \n",
       "3             0             1.00           0.00     256.00   3481  \n",
       "4             1             0.25          64.00        NaN    324  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns=='adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n",
      "v2a1\n",
      "hacdor\n",
      "rooms\n",
      "hacapo\n",
      "v14a\n",
      "refrig\n",
      "v18q\n",
      "v18q1\n",
      "r4h1\n",
      "r4h2\n",
      "r4h3\n",
      "r4m1\n",
      "r4m2\n",
      "r4m3\n",
      "r4t1\n",
      "r4t2\n",
      "r4t3\n",
      "tamhog\n",
      "tamviv\n",
      "escolari\n",
      "rez_esc\n",
      "hhsize\n",
      "paredblolad\n",
      "paredzocalo\n",
      "paredpreb\n",
      "pareddes\n",
      "paredmad\n",
      "paredzinc\n",
      "paredfibras\n",
      "paredother\n",
      "pisomoscer\n",
      "pisocemento\n",
      "pisoother\n",
      "pisonatur\n",
      "pisonotiene\n",
      "pisomadera\n",
      "techozinc\n",
      "techoentrepiso\n",
      "techocane\n",
      "techootro\n",
      "cielorazo\n",
      "abastaguadentro\n",
      "abastaguafuera\n",
      "abastaguano\n",
      "public\n",
      "planpri\n",
      "noelec\n",
      "coopele\n",
      "sanitario1\n",
      "sanitario2\n",
      "sanitario3\n",
      "sanitario5\n",
      "sanitario6\n",
      "energcocinar1\n",
      "energcocinar2\n",
      "energcocinar3\n",
      "energcocinar4\n",
      "elimbasu1\n",
      "elimbasu2\n",
      "elimbasu3\n",
      "elimbasu4\n",
      "elimbasu5\n",
      "elimbasu6\n",
      "epared1\n",
      "epared2\n",
      "epared3\n",
      "etecho1\n",
      "etecho2\n",
      "etecho3\n",
      "eviv1\n",
      "eviv2\n",
      "eviv3\n",
      "dis\n",
      "male\n",
      "female\n",
      "estadocivil1\n",
      "estadocivil2\n",
      "estadocivil3\n",
      "estadocivil4\n",
      "estadocivil5\n",
      "estadocivil6\n",
      "estadocivil7\n",
      "parentesco1\n",
      "parentesco2\n",
      "parentesco3\n",
      "parentesco4\n",
      "parentesco5\n",
      "parentesco6\n",
      "parentesco7\n",
      "parentesco8\n",
      "parentesco9\n",
      "parentesco10\n",
      "parentesco11\n",
      "parentesco12\n",
      "idhogar\n",
      "hogar_nin\n",
      "hogar_adul\n",
      "hogar_mayor\n",
      "hogar_total\n",
      "dependency\n",
      "edjefe\n",
      "edjefa\n",
      "meaneduc\n",
      "instlevel1\n",
      "instlevel2\n",
      "instlevel3\n",
      "instlevel4\n",
      "instlevel5\n",
      "instlevel6\n",
      "instlevel7\n",
      "instlevel8\n",
      "instlevel9\n",
      "bedrooms\n",
      "overcrowding\n",
      "tipovivi1\n",
      "tipovivi2\n",
      "tipovivi3\n",
      "tipovivi4\n",
      "tipovivi5\n",
      "computer\n",
      "television\n",
      "mobilephone\n",
      "qmobilephone\n",
      "lugar1\n",
      "lugar2\n",
      "lugar3\n",
      "lugar4\n",
      "lugar5\n",
      "lugar6\n",
      "area1\n",
      "area2\n",
      "age\n",
      "SQBescolari\n",
      "SQBage\n",
      "SQBhogar_total\n",
      "SQBedjefe\n",
      "SQBhogar_nin\n",
      "SQBovercrowding\n",
      "SQBdependency\n",
      "SQBmeaned\n",
      "agesq\n"
     ]
    }
   ],
   "source": [
    "for i in df_test.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2 Make description df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "#### 1.3 Check Null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rez_esc</th>\n",
       "      <td>7928</td>\n",
       "      <td>82.954902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v18q1</th>\n",
       "      <td>7342</td>\n",
       "      <td>76.823271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2a1</th>\n",
       "      <td>6860</td>\n",
       "      <td>71.779847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaneduc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQBmeaned</th>\n",
       "      <td>5</td>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techozinc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techoentrepiso</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techocane</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techootro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cielorazo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguadentro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguafuera</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguano</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planpri</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noelec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coopele</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total    Percent\n",
       "rez_esc           7928  82.954902\n",
       "v18q1             7342  76.823271\n",
       "v2a1              6860  71.779847\n",
       "meaneduc             5   0.052318\n",
       "SQBmeaned            5   0.052318\n",
       "techozinc            0   0.000000\n",
       "techoentrepiso       0   0.000000\n",
       "techocane            0   0.000000\n",
       "techootro            0   0.000000\n",
       "cielorazo            0   0.000000\n",
       "abastaguadentro      0   0.000000\n",
       "sanitario3           0   0.000000\n",
       "abastaguafuera       0   0.000000\n",
       "abastaguano          0   0.000000\n",
       "public               0   0.000000\n",
       "planpri              0   0.000000\n",
       "noelec               0   0.000000\n",
       "coopele              0   0.000000\n",
       "sanitario1           0   0.000000\n",
       "sanitario2           0   0.000000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending = False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending = False)\n",
    "missing_df = pd.concat([total, percent], axis =1, keys = ['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.4 Fill Missing values\n",
    "- edjefe : 남자 교육 기간\n",
    "- edjefa : 여자 교육 기간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefa\"] = df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefe\"] = df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefa\"] = df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefe\"] = df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with 4\n",
    "df_train.loc[df_train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_train.loc[df_train['edjefe'] == \"yes\", \"edjefe\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_test.loc[df_test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# create feature with max education of either head of household\n",
    "df_train['edjef'] = np.max(df_train[['edjefa','edjefe']], axis=1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa','edjefe']], axis=1)\n",
    "\n",
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n",
    "# if there is no water we'll assume they do not\n",
    "df_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"v14a\"] = 0\n",
    "df_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "df_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"v14a\"] = 0\n",
    "df_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**reaz_esz, SQBmeaned**\n",
    "- `rez_esc` : years behind in school-> filled with 0\n",
    "- `SQBmeaned` : square of the mean years of education of adults in the household ages, Age squared - > same with rez_esc -> filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc'].fillna(0, inplace = True)\n",
    "df_test['rez_esc'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SQBmeaned'].fillna(0, inplace = True)\n",
    "df_test['SQBmeaned'].fillna(0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**meaneduc**\n",
    "\n",
    "- meaneduc : avearge years of education for adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['meaneduc'].fillna(0, inplace = True)\n",
    "df_test['meaneduc'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**v18q1**\n",
    "\n",
    "- number of tablets household own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7342\n",
       "1    2215\n",
       "Name: v18q, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.v18q.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1586\n",
       "2.0     444\n",
       "3.0     129\n",
       "4.0      37\n",
       "5.0      13\n",
       "6.0       6\n",
       "Name: v18q1, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['v18q'] == 1, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: v18q1, dtype: int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['v18q1'] == 0, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v18q1'].fillna(0, inplace = True)\n",
    "df_test['v18q1'].fillna(0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**tipovivi3**\n",
    "\n",
    "- rent or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7821\n",
       "1    1736\n",
       "Name: tipovivi3, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['tipovivi3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 1, 'v2a1'], label = 'Monthly rent paymetn of household(rented =1)')\n",
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] ==0, 'v2a1'], label = 'Montly rent payment of household (rent =0)')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v2a1'].fillna(0, inplace = True)\n",
    "df_test['v2a1'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edjef</th>\n",
       "      <td>9557</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coopele</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noelec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planpri</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguano</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguafuera</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguadentro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cielorazo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techootro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techocane</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techoentrepiso</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techozinc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energcocinar1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total  Percent\n",
       "edjef             9557    100.0\n",
       "Target               0      0.0\n",
       "sanitario3           0      0.0\n",
       "sanitario2           0      0.0\n",
       "sanitario1           0      0.0\n",
       "coopele              0      0.0\n",
       "noelec               0      0.0\n",
       "planpri              0      0.0\n",
       "public               0      0.0\n",
       "abastaguano          0      0.0\n",
       "abastaguafuera       0      0.0\n",
       "abastaguadentro      0      0.0\n",
       "cielorazo            0      0.0\n",
       "techootro            0      0.0\n",
       "techocane            0      0.0\n",
       "techoentrepiso       0      0.0\n",
       "techozinc            0      0.0\n",
       "sanitario5           0      0.0\n",
       "sanitario6           0      0.0\n",
       "energcocinar1        0      0.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending = False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending = False)\n",
    "\n",
    "missing_df = pd.concat([total, percent], axis = 1, keys = ['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edjef</th>\n",
       "      <td>23856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguano</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coopele</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noelec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planpri</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguafuera</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguadentro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cielorazo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techootro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techocane</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techoentrepiso</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techozinc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pisonotiene</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elimbasu5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total  Percent\n",
       "edjef            23856    100.0\n",
       "abastaguano          0      0.0\n",
       "sanitario2           0      0.0\n",
       "sanitario1           0      0.0\n",
       "coopele              0      0.0\n",
       "noelec               0      0.0\n",
       "planpri              0      0.0\n",
       "public               0      0.0\n",
       "abastaguafuera       0      0.0\n",
       "sanitario5           0      0.0\n",
       "abastaguadentro      0      0.0\n",
       "cielorazo            0      0.0\n",
       "techootro            0      0.0\n",
       "techocane            0      0.0\n",
       "techoentrepiso       0      0.0\n",
       "techozinc            0      0.0\n",
       "sanitario3           0      0.0\n",
       "sanitario6           0      0.0\n",
       "pisonotiene          0      0.0\n",
       "elimbasu5            0      0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_test.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_test.isnull().sum() / df_test.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2. Feature Engineering\n",
    "\n",
    "#### 2.1 Object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_object = [col for col in df_train.columns if df_train[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_object = []\n",
    "for col in df_train.select_dtypes('object'):\n",
    "    features_object.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['Id', 'idhogar', 'dependency', 'edjefe', 'edjefa']"
      ],
      "text/plain": [
       "['Id', 'idhogar', 'dependency', 'edjefe', 'edjefa']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**dependency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['dependency'] = np.sqrt(df_train['SQBdependency'])\n",
    "df_test['dependency'] = np.sqrt(df_test['SQBdependency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**edjefe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefe(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df_train['edjefe'] = df_train['edjefe'].apply(replace_edjefe).astype(float)\n",
    "df_test['edjefe'] = df_test['edjefe'].apply(replace_edjefe).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**edjefa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefa(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df_train['edjefa'] = df_train['edjefa'].apply(replace_edjefa).astype(float)\n",
    "df_test['edjefa'] = df_test['edjefa'].apply(replace_edjefa).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['edjef'] = np.max(df_train[['edjefa', 'edjefe']], axis = 1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa', 'edjefe']], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**roof and electricity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['roof_waste_material'] = np.nan\n",
    "df_test['roof_waste_material'] = np.nan\n",
    "df_train['electricity_other'] = np.nan\n",
    "df_test['electricity_other'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_roof_exception(x):\n",
    "    if (x['techozinc'] ==0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def fill_no_electricity(x):\n",
    "    if (x['public'] ==0) and(x['planpri'] ==0) and (x['noelec'] ==0) and(x['coopele'] ==0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['roof_waste_material'] = df_train.apply(lambda x : fill_roof_exception(x), axis =1)\n",
    "df_test['roof_waste_material'] = df_test.apply(lambda x : fill_roof_exception(x), axis =1)\n",
    "\n",
    "df_train['electricity_other'] = df_train.apply(lambda x : fill_no_electricity(x), axis =1)\n",
    "df_test['electricity_other'] = df_test.apply(lambda x : fill_no_electricity(x), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.2 Extract cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in df_train.columns if df_train[col].value_counts().shape[0] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.3 Make new features using continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [col for col in df_train.columns if col not in binary_cat_features]\n",
    "continuous_features = [col for col in continuous_features if col not in features_object]\n",
    "continuous_features = [col for col in continuous_features if col not in ['Id', 'Target', 'idhogar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 continuous features\n"
     ]
    }
   ],
   "source": [
    "print('There are {} continuous features'.format(len(continuous_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0     2792\n",
       "11.0    1150\n",
       "9.0      723\n",
       "8.0      474\n",
       "15.0     473\n",
       "3.0      459\n",
       "0.0      435\n",
       "7.0      413\n",
       "4.0      400\n",
       "5.0      398\n",
       "14.0     328\n",
       "17.0     278\n",
       "2.0      278\n",
       "16.0     247\n",
       "10.0     207\n",
       "12.0     185\n",
       "13.0     155\n",
       "1.0       65\n",
       "21.0      48\n",
       "18.0      22\n",
       "19.0      18\n",
       "20.0       9\n",
       "Name: edjef, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['edjef'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `hhsize` 와 `tamhog` 이 똑같은 의미라고 판단해, tamhog 지움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('tamhog', axis = 1, inplace = True)\n",
    "df_test.drop('tamhog', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Family features\n",
    "- hogar_nin, hogar_adul, hogar_mayor, hogar_total, r4h1, r4h2, r4h3, r4m1, r4m2, r4m3, r4t1, r4t2, r4t3, tmbhog, tamvid, rez_esc, escolari\n",
    "\n",
    "**Family size features (substract, ratio)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['adult'] = df_train['hogar_adul'] - df_train['hogar_mayor']\n",
    "\n",
    "df_train['dependency_count'] = df_train['hogar_nin'] + df_train['hogar_mayor']\n",
    "\n",
    "df_train['dependency'] = df_train['dependency_count'] / df_train['adult']\n",
    "\n",
    "df_train['child_percent'] = df_train['hogar_nin'] / df_train['hogar_total']\n",
    "\n",
    "df_train['elder_percent'] = df_train['hogar_mayor'] / df_train['hogar_total']\n",
    "\n",
    "df_train['adult_percent'] = df_train['hogar_adul'] / df_train['hogar_total']\n",
    "\n",
    "df_train['males_younger_12_years_percent'] = df_train['r4h1'] / df_train['hogar_total']\n",
    "\n",
    "df_train['males_older_12_years_percent'] = df_train['r4h2'] / df_train['hogar_total']\n",
    "\n",
    "df_train['males_percent'] = df_train['r4h3'] / df_train['hogar_total']\n",
    "\n",
    "df_train['females_younger_12_years_percent'] = df_train['r4m1'] / df_train['hogar_total']\n",
    "\n",
    "df_train['females_older_12_years_percent'] = df_train['r4m2'] / df_train['hogar_total']\n",
    "\n",
    "df_train['females_percent'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "\n",
    "df_train['persons_younger_12_years_percent'] = df_train['r4t1'] / df_train['hogar_total']\n",
    "\n",
    "df_train['persons_older_12_years_percent'] = df_train['r4t2'] / df_train['hogar_total']\n",
    "\n",
    "df_train['persons_percent'] = df_train['r4t3'] / df_train['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['adult'] = df_test['hogar_adul'] - df_test['hogar_mayor']\n",
    "\n",
    "df_test['dependency_count'] = df_test['hogar_nin'] + df_test['hogar_mayor']\n",
    "\n",
    "df_test['dependency'] = df_test['dependency_count'] / df_test['adult']\n",
    "\n",
    "df_test['child_percent'] = df_test['hogar_nin'] / df_test['hogar_total']\n",
    "\n",
    "df_test['elder_percent'] = df_test['hogar_mayor'] / df_test['hogar_total']\n",
    "\n",
    "df_test['adult_percent'] = df_test['hogar_adul'] / df_test['hogar_total']\n",
    "\n",
    "df_test['males_younger_12_years_percent'] = df_test['r4h1'] / df_test['hogar_total']\n",
    "\n",
    "df_test['males_older_12_years_percent'] = df_test['r4h2'] / df_test['hogar_total']\n",
    "\n",
    "df_test['males_percent'] = df_test['r4h3'] / df_test['hogar_total']\n",
    "\n",
    "df_test['females_younger_12_years_percent'] = df_test['r4m1'] / df_test['hogar_total']\n",
    "\n",
    "df_test['females_older_12_years_percent'] = df_test['r4m2'] / df_test['hogar_total']\n",
    "\n",
    "df_test['females_percent'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "\n",
    "df_test['persons_younger_12_years_percent'] = df_test['r4t1'] / df_test['hogar_total']\n",
    "\n",
    "df_test['persons_older_12_years_percent'] = df_test['r4t2'] / df_test['hogar_total']\n",
    "\n",
    "df_test['persons_percent'] = df_test['r4t3'] / df_test['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['males_younger_12_years_in_household_size'] = df_train['r4h1'] / df_train['hhsize']\n",
    "df_train['males_older_12_years_in_household_size'] = df_train['r4h2'] / df_train['hhsize']\n",
    "df_train['males_in_household_size'] = df_train['r4h3'] / df_train['hhsize']\n",
    "df_train['females_younger_12_years_in_household_size'] = df_train['r4m1'] / df_train['hhsize']\n",
    "df_train['females_older_12_years_in_household_size'] = df_train['r4m2'] / df_train['hhsize']\n",
    "df_train['females_in_household_size'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "df_train['persons_younger_12_years_in_household_size'] = df_train['r4t1'] / df_train['hhsize']\n",
    "df_train['persons_older_12_years_in_household_size'] = df_train['r4t2'] / df_train['hhsize']\n",
    "df_train['persons_in_household_size'] = df_train['r4t3'] / df_train['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['males_younger_12_years_in_household_size'] = df_test['r4h1'] / df_test['hhsize']\n",
    "df_test['males_older_12_years_in_household_size'] = df_test['r4h2'] / df_test['hhsize']\n",
    "df_test['males_in_household_size'] = df_test['r4h3'] / df_test['hhsize']\n",
    "df_test['females_younger_12_years_in_household_size'] = df_test['r4m1'] / df_test['hhsize']\n",
    "df_test['females_older_12_years_in_household_size'] = df_test['r4m2'] / df_test['hhsize']\n",
    "df_test['females_in_household_size'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "df_test['persons_younger_12_years_in_household_size'] = df_test['r4t1'] / df_test['hhsize']\n",
    "df_test['persons_older_12_years_in_household_size'] = df_test['r4t2'] / df_test['hhsize']\n",
    "df_test['persons_in_household_size'] = df_test['r4t3'] / df_test['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['overcrowding_room_and_bedroom'] = (df_train['hacdor'] + df_train['hacapo'])/2\n",
    "df_test['overcrowding_room_and_bedroom'] = (df_test['hacdor'] + df_test['hacapo'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['escolari_age'] = df_train['escolari']/df_train['age']\n",
    "df_test['escolari_age'] = df_test['escolari']/df_test['age']\n",
    "\n",
    "df_train['age_12_19'] = df_train['hogar_nin'] - df_train['r4t1']\n",
    "df_test['age_12_19'] = df_test['hogar_nin'] - df_test['r4t1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['phones-per-capita'] = df_train['qmobilephone'] / df_train['tamviv']\n",
    "df_train['tablets-per-capita'] = df_train['v18q1'] / df_train['tamviv']\n",
    "df_train['rooms-per-capita'] = df_train['rooms'] / df_train['tamviv']\n",
    "df_train['rent-per-capita'] = df_train['v2a1'] / df_train['tamviv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['phones-per-capita'] = df_test['qmobilephone'] / df_test['tamviv']\n",
    "df_test['tablets-per-capita'] = df_test['v18q1'] / df_test['tamviv']\n",
    "df_test['rooms-per-capita'] = df_test['rooms'] / df_test['tamviv']\n",
    "df_test['rent-per-capita'] = df_test['v2a1'] / df_test['tamviv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9509"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train['hogar_total'] == df_train['r4t3']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Rent per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size_features = ['adult', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total', 'r4h1', \n",
    "                        'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'hhsize']\n",
    "new_feats = []\n",
    "\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v2a1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v2a1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v2a1'] / df_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['new_v2a1_per_adult', 'new_v2a1_per_hogar_adul', 'new_v2a1_per_hogar_mayor', 'new_v2a1_per_hogar_nin', 'new_v2a1_per_hogar_total', 'new_v2a1_per_r4h1', 'new_v2a1_per_r4h2', 'new_v2a1_per_r4h3', 'new_v2a1_per_r4m1', 'new_v2a1_per_r4m2', 'new_v2a1_per_r4m3', 'new_v2a1_per_r4t1', 'new_v2a1_per_r4t2', 'new_v2a1_per_r4t3', 'new_v2a1_per_hhsize']"
      ],
      "text/plain": [
       "['new_v2a1_per_adult',\n",
       " 'new_v2a1_per_hogar_adul',\n",
       " 'new_v2a1_per_hogar_mayor',\n",
       " 'new_v2a1_per_hogar_nin',\n",
       " 'new_v2a1_per_hogar_total',\n",
       " 'new_v2a1_per_r4h1',\n",
       " 'new_v2a1_per_r4h2',\n",
       " 'new_v2a1_per_r4h3',\n",
       " 'new_v2a1_per_r4m1',\n",
       " 'new_v2a1_per_r4m2',\n",
       " 'new_v2a1_per_r4m3',\n",
       " 'new_v2a1_per_r4t1',\n",
       " 'new_v2a1_per_r4t2',\n",
       " 'new_v2a1_per_r4t3',\n",
       " 'new_v2a1_per_hhsize']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_train[col].fillna(0, inplace = True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_test[col].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Room per familly features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rooms'] / df_test[col]\n",
    "    \n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_train[col].fillna(0, inplace = True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_test[col].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Bedroom Per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('bedrooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['bedrooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['bedrooms'] / df_test[col]\n",
    "    \n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_train[col].fillna(0, inplace = True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_test[col].fillna(0, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 220) (23856, 219)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Tabulet per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v18q1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v18q1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v18q1'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### phone per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('qmobilephone', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['qmobilephone'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['qmobilephone'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### rez_esc(Years behind in school) per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rez_esc', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rez_esc'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rez_esc'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc_age'] = df_train['rez_esc'] / df_train['age']\n",
    "df_train['rez_esc_escolari'] = df_train['rez_esc'] / df_train['escolari']\n",
    "\n",
    "df_test['rez_esc_age'] = df_test['rez_esc'] / df_test['age']\n",
    "df_test['rez_esc_escolari'] = df_test['rez_esc'] / df_test['escolari']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Rich features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tabulet_x_qmobilephone'] = df_train['v18q1'] * df_train['qmobilephone']\n",
    "df_test['tabulet_x_qmobilephone'] = df_test['v18q1'] * df_test['qmobilephone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wall, roof, floor - > 이진 변수인데, 각각의 특성 내 값을 곱하면서 새로운 특성을 만들수 있음\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "# wall and floor\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "# roof and floor\n",
    "for col1 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        for col3 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 322) (23856, 321)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### electirictiy 와 energy features -- energy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['public', 'planpri', 'noelec', 'coopele']:\n",
    "    for col2 in ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### toilet 과 rubbish disposal features 합치기 - other_infra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "    for col2 in ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### toilet and water provision features -- water features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['abastaguadentro', 'abastaguafuera', 'abastaguano']:\n",
    "    for col2 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 383) (23856, 382)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### education + area = education_Zone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['area1', 'area2']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Mix region and Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Multiply television / mobilephone / computer / tabulet / refrigerator -> electornics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['electronics'] = df_train['computer'] * df_train['mobilephone'] * df_train['television'] * df_train['v18q'] * df_train['refrig']\n",
    "df_test['electronics'] = df_test['computer'] * df_test['mobilephone'] * df_test['television'] * df_test['v18q'] * df_test['refrig']\n",
    "\n",
    "df_train['no_appliances'] = df_train['refrig'] + df_train['computer'] + df_train['television'] + df_train['mobilephone']\n",
    "df_test['no_appliances'] = df_test['refrig'] + df_test['computer'] + df_test['television'] + df_test['mobilephone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Mix wall material of roof, floor, wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "for col1 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "    for col1 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]        \n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        for col3 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 733) (23856, 732)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Remove feature with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elimbasu5\n",
      "new_planpri_x_energcocinar1\n",
      "new_planpri_x_energcocinar2\n",
      "new_planpri_x_energcocinar3\n",
      "new_planpri_x_energcocinar4\n",
      "new_noelec_x_energcocinar2\n",
      "new_sanitario1_x_elimbasu4\n",
      "new_sanitario1_x_elimbasu5\n",
      "new_sanitario1_x_elimbasu6\n",
      "new_sanitario2_x_elimbasu4\n",
      "new_sanitario2_x_elimbasu5\n",
      "new_sanitario2_x_elimbasu6\n",
      "new_sanitario3_x_elimbasu5\n",
      "new_sanitario5_x_elimbasu4\n",
      "new_sanitario5_x_elimbasu5\n",
      "new_sanitario5_x_elimbasu6\n",
      "new_sanitario6_x_elimbasu2\n",
      "new_sanitario6_x_elimbasu4\n",
      "new_sanitario6_x_elimbasu5\n",
      "new_sanitario6_x_elimbasu6\n",
      "new_abastaguafuera_x_sanitario6\n",
      "new_abastaguano_x_sanitario2\n",
      "new_abastaguano_x_sanitario6\n",
      "new_paredblolad_x_pisonatur\n",
      "new_paredblolad_x_pisonotiene\n",
      "new_paredzocalo_x_pisoother\n",
      "new_paredzocalo_x_pisonatur\n",
      "new_paredpreb_x_pisonatur\n",
      "new_pareddes_x_pisoother\n",
      "new_pareddes_x_pisonatur\n",
      "new_paredmad_x_pisoother\n",
      "new_paredmad_x_pisonatur\n",
      "new_paredzinc_x_pisoother\n",
      "new_paredzinc_x_pisonatur\n",
      "new_paredfibras_x_pisoother\n",
      "new_paredfibras_x_pisonatur\n",
      "new_paredfibras_x_pisonotiene\n",
      "new_paredfibras_x_pisomadera\n",
      "new_paredother_x_pisoother\n",
      "new_paredother_x_pisonatur\n",
      "new_paredother_x_pisonotiene\n",
      "new_paredother_x_pisomadera\n",
      "new_techocane_x_pisomadera\n",
      "new_techootro_x_pisomadera\n",
      "new_paredzocalo_x_techoentrepiso\n",
      "new_paredzocalo_x_techocane\n",
      "new_paredzocalo_x_techootro\n",
      "new_paredpreb_x_techootro\n",
      "new_pareddes_x_techoentrepiso\n",
      "new_pareddes_x_techocane\n",
      "new_pareddes_x_techootro\n",
      "new_paredmad_x_techocane\n",
      "new_paredmad_x_techootro\n",
      "new_paredzinc_x_techoentrepiso\n",
      "new_paredzinc_x_techocane\n",
      "new_paredzinc_x_techootro\n",
      "new_paredfibras_x_techoentrepiso\n",
      "new_paredfibras_x_techootro\n",
      "new_paredother_x_techoentrepiso\n",
      "new_paredother_x_techocane\n",
      "new_paredother_x_techootro\n",
      "new_paredblolad_x_pisocemento_x_techocane\n",
      "new_paredblolad_x_pisocemento_x_techootro\n",
      "new_paredblolad_x_pisoother_x_techoentrepiso\n",
      "new_paredblolad_x_pisoother_x_techocane\n",
      "new_paredblolad_x_pisoother_x_techootro\n",
      "new_paredblolad_x_pisonatur_x_techozinc\n",
      "new_paredblolad_x_pisonatur_x_techoentrepiso\n",
      "new_paredblolad_x_pisonatur_x_techocane\n",
      "new_paredblolad_x_pisonatur_x_techootro\n",
      "new_paredblolad_x_pisonotiene_x_techozinc\n",
      "new_paredblolad_x_pisonotiene_x_techoentrepiso\n",
      "new_paredblolad_x_pisonotiene_x_techocane\n",
      "new_paredblolad_x_pisonotiene_x_techootro\n",
      "new_paredblolad_x_pisomadera_x_techocane\n",
      "new_paredblolad_x_pisomadera_x_techootro\n",
      "new_paredzocalo_x_pisomoscer_x_techoentrepiso\n",
      "new_paredzocalo_x_pisomoscer_x_techocane\n",
      "new_paredzocalo_x_pisomoscer_x_techootro\n",
      "new_paredzocalo_x_pisocemento_x_techoentrepiso\n",
      "new_paredzocalo_x_pisocemento_x_techocane\n",
      "new_paredzocalo_x_pisocemento_x_techootro\n",
      "new_paredzocalo_x_pisoother_x_techozinc\n",
      "new_paredzocalo_x_pisoother_x_techoentrepiso\n",
      "new_paredzocalo_x_pisoother_x_techocane\n",
      "new_paredzocalo_x_pisoother_x_techootro\n",
      "new_paredzocalo_x_pisonatur_x_techozinc\n",
      "new_paredzocalo_x_pisonatur_x_techoentrepiso\n",
      "new_paredzocalo_x_pisonatur_x_techocane\n",
      "new_paredzocalo_x_pisonatur_x_techootro\n",
      "new_paredzocalo_x_pisonotiene_x_techoentrepiso\n",
      "new_paredzocalo_x_pisonotiene_x_techocane\n",
      "new_paredzocalo_x_pisonotiene_x_techootro\n",
      "new_paredzocalo_x_pisomadera_x_techoentrepiso\n",
      "new_paredzocalo_x_pisomadera_x_techocane\n",
      "new_paredzocalo_x_pisomadera_x_techootro\n",
      "new_paredpreb_x_pisocemento_x_techoentrepiso\n",
      "new_paredpreb_x_pisocemento_x_techocane\n",
      "new_paredpreb_x_pisocemento_x_techootro\n",
      "new_paredpreb_x_pisoother_x_techoentrepiso\n",
      "new_paredpreb_x_pisoother_x_techocane\n",
      "new_paredpreb_x_pisoother_x_techootro\n",
      "new_paredpreb_x_pisonatur_x_techozinc\n",
      "new_paredpreb_x_pisonatur_x_techoentrepiso\n",
      "new_paredpreb_x_pisonatur_x_techocane\n",
      "new_paredpreb_x_pisonatur_x_techootro\n",
      "new_paredpreb_x_pisonotiene_x_techozinc\n",
      "new_paredpreb_x_pisonotiene_x_techoentrepiso\n",
      "new_paredpreb_x_pisonotiene_x_techocane\n",
      "new_paredpreb_x_pisonotiene_x_techootro\n",
      "new_paredpreb_x_pisomadera_x_techoentrepiso\n",
      "new_paredpreb_x_pisomadera_x_techocane\n",
      "new_paredpreb_x_pisomadera_x_techootro\n",
      "new_pareddes_x_pisomoscer_x_techozinc\n",
      "new_pareddes_x_pisomoscer_x_techoentrepiso\n",
      "new_pareddes_x_pisomoscer_x_techocane\n",
      "new_pareddes_x_pisomoscer_x_techootro\n",
      "new_pareddes_x_pisocemento_x_techoentrepiso\n",
      "new_pareddes_x_pisocemento_x_techocane\n",
      "new_pareddes_x_pisocemento_x_techootro\n",
      "new_pareddes_x_pisoother_x_techozinc\n",
      "new_pareddes_x_pisoother_x_techoentrepiso\n",
      "new_pareddes_x_pisoother_x_techocane\n",
      "new_pareddes_x_pisoother_x_techootro\n",
      "new_pareddes_x_pisonatur_x_techozinc\n",
      "new_pareddes_x_pisonatur_x_techoentrepiso\n",
      "new_pareddes_x_pisonatur_x_techocane\n",
      "new_pareddes_x_pisonatur_x_techootro\n",
      "new_pareddes_x_pisonotiene_x_techoentrepiso\n",
      "new_pareddes_x_pisonotiene_x_techocane\n",
      "new_pareddes_x_pisonotiene_x_techootro\n",
      "new_pareddes_x_pisomadera_x_techozinc\n",
      "new_pareddes_x_pisomadera_x_techoentrepiso\n",
      "new_pareddes_x_pisomadera_x_techocane\n",
      "new_pareddes_x_pisomadera_x_techootro\n",
      "new_paredmad_x_pisomoscer_x_techocane\n",
      "new_paredmad_x_pisomoscer_x_techootro\n",
      "new_paredmad_x_pisocemento_x_techoentrepiso\n",
      "new_paredmad_x_pisocemento_x_techocane\n",
      "new_paredmad_x_pisocemento_x_techootro\n",
      "new_paredmad_x_pisoother_x_techozinc\n",
      "new_paredmad_x_pisoother_x_techoentrepiso\n",
      "new_paredmad_x_pisoother_x_techocane\n",
      "new_paredmad_x_pisoother_x_techootro\n",
      "new_paredmad_x_pisonatur_x_techozinc\n",
      "new_paredmad_x_pisonatur_x_techoentrepiso\n",
      "new_paredmad_x_pisonatur_x_techocane\n",
      "new_paredmad_x_pisonatur_x_techootro\n",
      "new_paredmad_x_pisonotiene_x_techoentrepiso\n",
      "new_paredmad_x_pisonotiene_x_techocane\n",
      "new_paredmad_x_pisonotiene_x_techootro\n",
      "new_paredmad_x_pisomadera_x_techocane\n",
      "new_paredzinc_x_pisomoscer_x_techoentrepiso\n",
      "new_paredzinc_x_pisomoscer_x_techocane\n",
      "new_paredzinc_x_pisomoscer_x_techootro\n",
      "new_paredzinc_x_pisocemento_x_techoentrepiso\n",
      "new_paredzinc_x_pisocemento_x_techocane\n",
      "new_paredzinc_x_pisocemento_x_techootro\n",
      "new_paredzinc_x_pisoother_x_techozinc\n",
      "new_paredzinc_x_pisoother_x_techoentrepiso\n",
      "new_paredzinc_x_pisoother_x_techocane\n",
      "new_paredzinc_x_pisoother_x_techootro\n",
      "new_paredzinc_x_pisonatur_x_techozinc\n",
      "new_paredzinc_x_pisonatur_x_techoentrepiso\n",
      "new_paredzinc_x_pisonatur_x_techocane\n",
      "new_paredzinc_x_pisonatur_x_techootro\n",
      "new_paredzinc_x_pisonotiene_x_techoentrepiso\n",
      "new_paredzinc_x_pisonotiene_x_techocane\n",
      "new_paredzinc_x_pisonotiene_x_techootro\n",
      "new_paredzinc_x_pisomadera_x_techoentrepiso\n",
      "new_paredzinc_x_pisomadera_x_techocane\n",
      "new_paredzinc_x_pisomadera_x_techootro\n",
      "new_paredfibras_x_pisomoscer_x_techoentrepiso\n",
      "new_paredfibras_x_pisomoscer_x_techocane\n",
      "new_paredfibras_x_pisomoscer_x_techootro\n",
      "new_paredfibras_x_pisocemento_x_techoentrepiso\n",
      "new_paredfibras_x_pisocemento_x_techocane\n",
      "new_paredfibras_x_pisocemento_x_techootro\n",
      "new_paredfibras_x_pisoother_x_techozinc\n",
      "new_paredfibras_x_pisoother_x_techoentrepiso\n",
      "new_paredfibras_x_pisoother_x_techocane\n",
      "new_paredfibras_x_pisoother_x_techootro\n",
      "new_paredfibras_x_pisonatur_x_techozinc\n",
      "new_paredfibras_x_pisonatur_x_techoentrepiso\n",
      "new_paredfibras_x_pisonatur_x_techocane\n",
      "new_paredfibras_x_pisonatur_x_techootro\n",
      "new_paredfibras_x_pisonotiene_x_techozinc\n",
      "new_paredfibras_x_pisonotiene_x_techoentrepiso\n",
      "new_paredfibras_x_pisonotiene_x_techocane\n",
      "new_paredfibras_x_pisonotiene_x_techootro\n",
      "new_paredfibras_x_pisomadera_x_techozinc\n",
      "new_paredfibras_x_pisomadera_x_techoentrepiso\n",
      "new_paredfibras_x_pisomadera_x_techocane\n",
      "new_paredfibras_x_pisomadera_x_techootro\n",
      "new_paredother_x_pisomoscer_x_techozinc\n",
      "new_paredother_x_pisomoscer_x_techoentrepiso\n",
      "new_paredother_x_pisomoscer_x_techocane\n",
      "new_paredother_x_pisomoscer_x_techootro\n",
      "new_paredother_x_pisocemento_x_techoentrepiso\n",
      "new_paredother_x_pisocemento_x_techocane\n",
      "new_paredother_x_pisocemento_x_techootro\n",
      "new_paredother_x_pisoother_x_techozinc\n",
      "new_paredother_x_pisoother_x_techoentrepiso\n",
      "new_paredother_x_pisoother_x_techocane\n",
      "new_paredother_x_pisoother_x_techootro\n",
      "new_paredother_x_pisonatur_x_techozinc\n",
      "new_paredother_x_pisonatur_x_techoentrepiso\n",
      "new_paredother_x_pisonatur_x_techocane\n",
      "new_paredother_x_pisonatur_x_techootro\n",
      "new_paredother_x_pisonotiene_x_techozinc\n",
      "new_paredother_x_pisonotiene_x_techoentrepiso\n",
      "new_paredother_x_pisonotiene_x_techocane\n",
      "new_paredother_x_pisonotiene_x_techootro\n",
      "new_paredother_x_pisomadera_x_techozinc\n",
      "new_paredother_x_pisomadera_x_techoentrepiso\n",
      "new_paredother_x_pisomadera_x_techocane\n",
      "new_paredother_x_pisomadera_x_techootro\n"
     ]
    }
   ],
   "source": [
    "cols_with_only_one_value = []\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if col == 'Target':\n",
    "        continue\n",
    "    if df_train[col].value_counts().shape[0] == 1 or df_test[col].value_counts().shape[0] == 1:\n",
    "        print(col)\n",
    "        cols_with_only_one_value.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(cols_with_only_one_value, axis = 1, inplace = True)\n",
    "df_test.drop(cols_with_only_one_value, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['v2a1'].value_counts().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Check whether both train and test have same features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_train = np.array(sorted([col for col in df_train.columns if col != 'Target']))\n",
    "\n",
    "cols_test = np.array(sorted(df_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cols_train == cols_test).sum() == len(cols_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.4 aggregation features\n",
    "\n",
    "\n",
    "#### Aggregation for family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min(x):\n",
    "    return x.max() - x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:19<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows and 105 features\n",
      "new aggreagte test set has 7352 rows and 105 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agg_train = pd.DataFrame()\n",
    "agg_test = pd.DataFrame()\n",
    "\n",
    "for item in tqdm(family_size_features):\n",
    "    for i, function in enumerate(['mean', 'std', 'min', 'max', 'sum', 'count', max_min]):\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "        \n",
    "print('new aggregate train set has {} rows and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggreagte test set has {} rows and {} features'.format(agg_test.shape[0], agg_test.shape[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult\n",
      "hogar_adul\n",
      "hogar_mayor\n",
      "hogar_nin\n",
      "hogar_total\n",
      "r4h1\n",
      "r4h2\n",
      "r4h3\n",
      "r4m1\n",
      "r4m2\n",
      "r4m3\n",
      "r4t1\n",
      "r4t2\n",
      "r4t3\n",
      "hhsize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(family_size_features):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 39.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 199 features\n",
      "new aggregate test set has 7352 rows, and 199 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "\n",
    "\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['count', 'sum']:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        new_col = item + '_new1_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:10<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 208 features\n",
      "new aggregate test set has 7352 rows, and 208 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['escolari', 'age', 'escolari_age', 'dependency', 'bedrooms', 'overcrowding', 'rooms', 'qmobilephone', 'v18q1']\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['mean','std','min','max','sum', 'count', max_min]:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new2_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new2_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (9557, 724) test shape:  (23856, 723)\n"
     ]
    }
   ],
   "source": [
    "agg_test = agg_test.reset_index()\n",
    "agg_train = agg_train.reset_index()\n",
    "\n",
    "train_agg = pd.merge(df_train, agg_train, on = 'idhogar')\n",
    "test = pd.merge(df_test, agg_test, on = 'idhogar')\n",
    "\n",
    "train_agg.fillna(value = 0, inplace = True)\n",
    "test.fillna(value = 0, inplace = True)\n",
    "\n",
    "print('train shape: ', train_agg.shape, 'test shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 1006) test shape: (23856, 1005)\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "    \n",
    "for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_train.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n",
    "\n",
    "    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_test.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n",
    "\n",
    "    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "    \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [05:27<00:00, 46.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 3262) test shape: (23856, 3261)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "for function in tqdm(['mean','std','min','max','sum', 'count', max_min]):\n",
    "    for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "        group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_train.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_train][2:]\n",
    "\n",
    "        group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_test.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_test][2:]\n",
    "\n",
    "        train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "        test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "        \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_agg.query('parentesco1==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>new5_lugar6_idhogar_eviv1_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_eviv2_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_eviv3_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_refrig_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_television_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_mobilephone_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_area1_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_area2_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_v18q_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_edjef_&lt;function max_min at 0x000001B254773400&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_ec05b1a7b</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID_1284f8aad</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    0.0   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       0.0       0      8       0     1       1     0    0.0   \n",
       "5  ID_ec05b1a7b  180000.0       0      5       0     1       1     1    1.0   \n",
       "8  ID_1284f8aad  130000.0       1      2       0     1       1     0    0.0   \n",
       "\n",
       "   r4h1  ...  \\\n",
       "0     0  ...   \n",
       "1     0  ...   \n",
       "2     0  ...   \n",
       "5     0  ...   \n",
       "8     0  ...   \n",
       "\n",
       "   new5_lugar6_idhogar_eviv1_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_eviv2_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_eviv3_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_refrig_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                     \n",
       "1                                                  0                     \n",
       "2                                                  0                     \n",
       "5                                                  0                     \n",
       "8                                                  0                     \n",
       "\n",
       "   new5_lugar6_idhogar_television_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                         \n",
       "1                                                  0                         \n",
       "2                                                  0                         \n",
       "5                                                  0                         \n",
       "8                                                  0                         \n",
       "\n",
       "   new5_lugar6_idhogar_mobilephone_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "2                                                  0                          \n",
       "5                                                  0                          \n",
       "8                                                  0                          \n",
       "\n",
       "   new5_lugar6_idhogar_area1_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_area2_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_v18q_<function max_min at 0x000001B254773400>  \\\n",
       "0                                                  0                   \n",
       "1                                                  0                   \n",
       "2                                                  0                   \n",
       "5                                                  0                   \n",
       "8                                                  0                   \n",
       "\n",
       "   new5_lugar6_idhogar_edjef_<function max_min at 0x000001B254773400>  \n",
       "0                                                0.0                   \n",
       "1                                                0.0                   \n",
       "2                                                0.0                   \n",
       "5                                                0.0                   \n",
       "8                                                0.0                   \n",
       "\n",
       "[5 rows x 3262 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dependency'].replace(np.inf, 0 , inplace = True)\n",
    "test['dependency'].replace(np.inf, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['Id']]\n",
    "\n",
    "#Remove useless feature to reduce dimension\n",
    "train.drop(columns=['idhogar','Id', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "test.drop(columns=['idhogar','Id',  'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "\n",
    "correlation = train.corr()\n",
    "correlation = correlation['Target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_data size (2973, 3250) (23856, 3249)\n"
     ]
    }
   ],
   "source": [
    "print('final_data size', train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 positive feature: \n",
      "Target                                1.000000\n",
      "new5_lugar5_idhogar_edjef_max         0.334254\n",
      "new5_lugar1_idhogar_edjef_max         0.334254\n",
      "new5_lugar6_idhogar_edjef_max         0.334254\n",
      "new5_lugar2_idhogar_edjef_max         0.334254\n",
      "new5_lugar4_idhogar_edjef_max         0.334254\n",
      "new5_lugar3_idhogar_edjef_max         0.334254\n",
      "new5_lugar2_idhogar_edjef_mean        0.333873\n",
      "new5_lugar4_idhogar_edjef_mean        0.333873\n",
      "new5_lugar5_idhogar_edjef_mean        0.333873\n",
      "new5_lugar3_idhogar_edjef_mean        0.333873\n",
      "new5_lugar1_idhogar_edjef_mean        0.333873\n",
      "new5_lugar6_idhogar_edjef_mean        0.333873\n",
      "new5_lugar2_idhogar_edjef_min         0.333791\n",
      "edjef                                 0.333791\n",
      "new5_lugar5_idhogar_edjef_min         0.333791\n",
      "new5_lugar6_idhogar_edjef_min         0.333791\n",
      "new5_lugar1_idhogar_edjef_min         0.333791\n",
      "new5_lugar4_idhogar_edjef_min         0.333791\n",
      "new5_lugar3_idhogar_edjef_min         0.333791\n",
      "escolari                              0.333791\n",
      "meaneduc                              0.331489\n",
      "new5_lugar1_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar2_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar5_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar3_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar4_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar6_idhogar_instlevel8_max    0.317815\n",
      "phones-per-capita                     0.299026\n",
      "new5_lugar5_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar3_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar1_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar2_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar6_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar4_idhogar_instlevel8_std    0.298251\n",
      "new_epared3_x_eviv3                   0.298196\n",
      "cielorazo                             0.295249\n",
      "new4_lugar5_idhogar_instlevel8        0.294277\n",
      "new5_lugar5_idhogar_instlevel8_sum    0.294277\n",
      "new5_lugar1_idhogar_instlevel8_sum    0.294277\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The most 20 positive feature: \\n{correlation.head(40)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 negative feature: \n",
      "new4_lugar5_idhogar_instlevel2       -0.297868\n",
      "new5_lugar3_idhogar_instlevel2_sum   -0.297868\n",
      "new4_lugar1_idhogar_instlevel2       -0.297868\n",
      "new5_lugar4_idhogar_instlevel2_sum   -0.297868\n",
      "new5_lugar6_idhogar_instlevel2_sum   -0.297868\n",
      "new4_lugar4_idhogar_instlevel2       -0.297868\n",
      "new4_lugar3_idhogar_instlevel2       -0.297868\n",
      "new3_lugar3_idhogar_instlevel2       -0.297868\n",
      "new5_lugar2_idhogar_instlevel2_sum   -0.297868\n",
      "new3_lugar1_idhogar_instlevel2       -0.297868\n",
      "new3_lugar4_idhogar_instlevel2       -0.297868\n",
      "new3_lugar5_idhogar_instlevel2       -0.297868\n",
      "new5_lugar5_idhogar_instlevel2_sum   -0.297868\n",
      "new5_lugar1_idhogar_instlevel2_sum   -0.297868\n",
      "new4_lugar6_idhogar_instlevel2       -0.297868\n",
      "new4_lugar2_idhogar_instlevel2       -0.297868\n",
      "new3_lugar2_idhogar_instlevel2       -0.297868\n",
      "new3_lugar6_idhogar_instlevel2       -0.297868\n",
      "instlevel2_new1_sum                  -0.297868\n",
      "dependency                           -0.304563\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The most 20 negative feature: \\n{correlation.dropna().tail(20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4. Feature selection using shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in train.columns if train[col].value_counts().shape[0] == 2]\n",
    "\n",
    "object_features = ['edjefe', 'edjefa']\n",
    "\n",
    "categorical_feats = binary_cat_features + object_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(truth, predictions):\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)), -1).argmax(axis = 0)\n",
    "    f1 = f1_score(truth, pred_labels, average = 'macro')\n",
    "    return ('macroF1', f1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Target']\n",
    "train.drop(columns = ['Target'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_execution_time(start):\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"*\"*20, 'Execution ended in {:0>2}h {:0>2}hm {:05.2f}s'.format(int(hours), int(minutes), seconds), \"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_good_features_using_shap_LGB(params, SEED):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 5\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb, categorical_feature=categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        print_execution_time(start)\n",
    "\n",
    "    feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "\n",
    "    return feat_importance_df_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 1 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.29333\ttraining's macroF1: 0.434509\tvalid_1's multi_logloss: 1.26053\tvalid_1's macroF1: 0.392308\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 1.38149\ttraining's macroF1: 0.394477\tvalid_1's multi_logloss: 1.37903\tvalid_1's macroF1: 0.399543\n",
      "******************** Execution ended in 00h 00hm 11.47s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.29267\ttraining's macroF1: 0.461175\tvalid_1's multi_logloss: 1.25807\tvalid_1's macroF1: 0.375667\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's multi_logloss: 1.3791\ttraining's macroF1: 0.440075\tvalid_1's multi_logloss: 1.37608\tvalid_1's macroF1: 0.392414\n",
      "******************** Execution ended in 00h 00hm 13.98s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.2962\ttraining's macroF1: 0.451186\tvalid_1's multi_logloss: 1.25676\tvalid_1's macroF1: 0.411448\n",
      "[1000]\ttraining's multi_logloss: 1.23882\ttraining's macroF1: 0.456521\tvalid_1's multi_logloss: 1.18257\tvalid_1's macroF1: 0.406452\n",
      "Early stopping, best iteration is:\n",
      "[571]\ttraining's multi_logloss: 1.28636\ttraining's macroF1: 0.45637\tvalid_1's multi_logloss: 1.24378\tvalid_1's macroF1: 0.424443\n",
      "******************** Execution ended in 00h 00hm 28.48s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.29463\ttraining's macroF1: 0.453152\tvalid_1's multi_logloss: 1.26199\tvalid_1's macroF1: 0.381554\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's multi_logloss: 1.37773\ttraining's macroF1: 0.418335\tvalid_1's multi_logloss: 1.37423\tvalid_1's macroF1: 0.397758\n",
      "******************** Execution ended in 00h 00hm 14.56s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.29241\ttraining's macroF1: 0.449117\tvalid_1's multi_logloss: 1.26628\tvalid_1's macroF1: 0.391909\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's multi_logloss: 1.33312\ttraining's macroF1: 0.442393\tvalid_1's multi_logloss: 1.31643\tvalid_1's macroF1: 0.416292\n",
      "******************** Execution ended in 00h 00hm 19.81s ********************\n",
      "######################################## 2 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02751\ttraining's macroF1: 0.549127\tvalid_1's multi_logloss: 1.03006\tvalid_1's macroF1: 0.415175\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's multi_logloss: 1.15677\ttraining's macroF1: 0.501186\tvalid_1's multi_logloss: 1.1044\tvalid_1's macroF1: 0.440535\n",
      "******************** Execution ended in 00h 00hm 20.92s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01908\ttraining's macroF1: 0.541972\tvalid_1's multi_logloss: 1.07415\tvalid_1's macroF1: 0.40807\n",
      "[1000]\ttraining's multi_logloss: 0.918726\ttraining's macroF1: 0.585021\tvalid_1's multi_logloss: 1.06122\tvalid_1's macroF1: 0.399543\n",
      "Early stopping, best iteration is:\n",
      "[720]\ttraining's multi_logloss: 0.967485\ttraining's macroF1: 0.567169\tvalid_1's multi_logloss: 1.06557\tvalid_1's macroF1: 0.418649\n",
      "******************** Execution ended in 00h 00hm 31.30s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03008\ttraining's macroF1: 0.540692\tvalid_1's multi_logloss: 1.04991\tvalid_1's macroF1: 0.456927\n",
      "[1000]\ttraining's multi_logloss: 0.925082\ttraining's macroF1: 0.592859\tvalid_1's multi_logloss: 1.02748\tvalid_1's macroF1: 0.459399\n",
      "Early stopping, best iteration is:\n",
      "[988]\ttraining's multi_logloss: 0.927042\ttraining's macroF1: 0.591454\tvalid_1's multi_logloss: 1.02751\tvalid_1's macroF1: 0.466542\n",
      "******************** Execution ended in 00h 00hm 35.64s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03109\ttraining's macroF1: 0.552832\tvalid_1's multi_logloss: 1.10012\tvalid_1's macroF1: 0.404092\n",
      "[1000]\ttraining's multi_logloss: 0.927904\ttraining's macroF1: 0.592351\tvalid_1's multi_logloss: 1.08408\tvalid_1's macroF1: 0.411351\n",
      "Early stopping, best iteration is:\n",
      "[607]\ttraining's multi_logloss: 1.00343\ttraining's macroF1: 0.555299\tvalid_1's multi_logloss: 1.09487\tvalid_1's macroF1: 0.423945\n",
      "******************** Execution ended in 00h 00hm 30.31s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02813\ttraining's macroF1: 0.532534\tvalid_1's multi_logloss: 1.04727\tvalid_1's macroF1: 0.394401\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's multi_logloss: 1.208\ttraining's macroF1: 0.489586\tvalid_1's multi_logloss: 1.17198\tvalid_1's macroF1: 0.410001\n",
      "******************** Execution ended in 00h 00hm 17.99s ********************\n",
      "######################################## 3 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03544\ttraining's macroF1: 0.53733\tvalid_1's multi_logloss: 1.09861\tvalid_1's macroF1: 0.391767\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's multi_logloss: 1.12965\ttraining's macroF1: 0.496668\tvalid_1's multi_logloss: 1.13481\tvalid_1's macroF1: 0.40596\n",
      "******************** Execution ended in 00h 00hm 15.67s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.0401\ttraining's macroF1: 0.524077\tvalid_1's multi_logloss: 1.01734\tvalid_1's macroF1: 0.423606\n",
      "[1000]\ttraining's multi_logloss: 0.949254\ttraining's macroF1: 0.554714\tvalid_1's multi_logloss: 0.996053\tvalid_1's macroF1: 0.429732\n",
      "[1500]\ttraining's multi_logloss: 0.888531\ttraining's macroF1: 0.601201\tvalid_1's multi_logloss: 0.985215\tvalid_1's macroF1: 0.443055\n",
      "[2000]\ttraining's multi_logloss: 0.841373\ttraining's macroF1: 0.620693\tvalid_1's multi_logloss: 0.981659\tvalid_1's macroF1: 0.441683\n",
      "Early stopping, best iteration is:\n",
      "[1517]\ttraining's multi_logloss: 0.886893\ttraining's macroF1: 0.600435\tvalid_1's multi_logloss: 0.984243\tvalid_1's macroF1: 0.444717\n",
      "******************** Execution ended in 00h 00hm 41.65s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03958\ttraining's macroF1: 0.545416\tvalid_1's multi_logloss: 1.08634\tvalid_1's macroF1: 0.382126\n",
      "Early stopping, best iteration is:\n",
      "[379]\ttraining's multi_logloss: 1.073\ttraining's macroF1: 0.529513\tvalid_1's multi_logloss: 1.09504\tvalid_1's macroF1: 0.39439\n",
      "******************** Execution ended in 00h 00hm 17.71s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03711\ttraining's macroF1: 0.546466\tvalid_1's multi_logloss: 1.06177\tvalid_1's macroF1: 0.402352\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttraining's multi_logloss: 1.05624\ttraining's macroF1: 0.536838\tvalid_1's multi_logloss: 1.06601\tvalid_1's macroF1: 0.415215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Execution ended in 00h 00hm 18.46s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.04153\ttraining's macroF1: 0.5235\tvalid_1's multi_logloss: 1.05629\tvalid_1's macroF1: 0.401931\n",
      "Early stopping, best iteration is:\n",
      "[361]\ttraining's multi_logloss: 1.08015\ttraining's macroF1: 0.510043\tvalid_1's multi_logloss: 1.07079\tvalid_1's macroF1: 0.422001\n",
      "******************** Execution ended in 00h 00hm 17.27s ********************\n",
      "######################################## 4 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.2495\ttraining's macroF1: 0.475114\tvalid_1's multi_logloss: 1.23824\tvalid_1's macroF1: 0.338673\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's multi_logloss: 1.38521\ttraining's macroF1: 0.440163\tvalid_1's multi_logloss: 1.38498\tvalid_1's macroF1: 0.359123\n",
      "******************** Execution ended in 00h 00hm 15.29s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.25199\ttraining's macroF1: 0.48095\tvalid_1's multi_logloss: 1.23424\tvalid_1's macroF1: 0.395703\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttraining's multi_logloss: 1.3361\ttraining's macroF1: 0.460428\tvalid_1's multi_logloss: 1.32534\tvalid_1's macroF1: 0.409791\n",
      "******************** Execution ended in 00h 00hm 19.34s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.25288\ttraining's macroF1: 0.474054\tvalid_1's multi_logloss: 1.22756\tvalid_1's macroF1: 0.397485\n",
      "[1000]\ttraining's multi_logloss: 1.1725\ttraining's macroF1: 0.504924\tvalid_1's multi_logloss: 1.15244\tvalid_1's macroF1: 0.402282\n",
      "[1500]\ttraining's multi_logloss: 1.11565\ttraining's macroF1: 0.518661\tvalid_1's multi_logloss: 1.11022\tvalid_1's macroF1: 0.408699\n",
      "[2000]\ttraining's multi_logloss: 1.07311\ttraining's macroF1: 0.530262\tvalid_1's multi_logloss: 1.08589\tvalid_1's macroF1: 0.416154\n",
      "[2500]\ttraining's multi_logloss: 1.0395\ttraining's macroF1: 0.542459\tvalid_1's multi_logloss: 1.07114\tvalid_1's macroF1: 0.414808\n",
      "Early stopping, best iteration is:\n",
      "[2376]\ttraining's multi_logloss: 1.04723\ttraining's macroF1: 0.540088\tvalid_1's multi_logloss: 1.07396\tvalid_1's macroF1: 0.420383\n",
      "******************** Execution ended in 00h 01hm 18.02s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.25677\ttraining's macroF1: 0.478929\tvalid_1's multi_logloss: 1.21513\tvalid_1's macroF1: 0.382565\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's multi_logloss: 1.38594\ttraining's macroF1: 0.437658\tvalid_1's multi_logloss: 1.38579\tvalid_1's macroF1: 0.438448\n",
      "******************** Execution ended in 00h 00hm 16.04s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.26137\ttraining's macroF1: 0.474334\tvalid_1's multi_logloss: 1.23767\tvalid_1's macroF1: 0.376078\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's multi_logloss: 1.38464\ttraining's macroF1: 0.435567\tvalid_1's multi_logloss: 1.38405\tvalid_1's macroF1: 0.383038\n",
      "******************** Execution ended in 00h 00hm 15.90s ********************\n",
      "######################################## 5 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.875048\ttraining's macroF1: 0.626231\tvalid_1's multi_logloss: 1.05262\tvalid_1's macroF1: 0.433722\n",
      "[1000]\ttraining's multi_logloss: 0.735679\ttraining's macroF1: 0.704678\tvalid_1's multi_logloss: 1.04714\tvalid_1's macroF1: 0.429994\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's multi_logloss: 0.869809\ttraining's macroF1: 0.627896\tvalid_1's multi_logloss: 1.05298\tvalid_1's macroF1: 0.443671\n",
      "******************** Execution ended in 00h 00hm 29.12s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.878446\ttraining's macroF1: 0.619619\tvalid_1's multi_logloss: 1.02516\tvalid_1's macroF1: 0.398519\n",
      "[1000]\ttraining's multi_logloss: 0.73874\ttraining's macroF1: 0.698529\tvalid_1's multi_logloss: 1.02476\tvalid_1's macroF1: 0.408663\n",
      "Early stopping, best iteration is:\n",
      "[743]\ttraining's multi_logloss: 0.800605\ttraining's macroF1: 0.665385\tvalid_1's multi_logloss: 1.02242\tvalid_1's macroF1: 0.41773\n",
      "******************** Execution ended in 00h 00hm 37.83s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.860424\ttraining's macroF1: 0.616014\tvalid_1's multi_logloss: 1.01932\tvalid_1's macroF1: 0.398978\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's multi_logloss: 1.11687\ttraining's macroF1: 0.521089\tvalid_1's multi_logloss: 1.10449\tvalid_1's macroF1: 0.421807\n",
      "******************** Execution ended in 00h 00hm 18.58s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.861504\ttraining's macroF1: 0.629063\tvalid_1's multi_logloss: 1.07063\tvalid_1's macroF1: 0.408271\n",
      "Early stopping, best iteration is:\n",
      "[303]\ttraining's multi_logloss: 0.948734\ttraining's macroF1: 0.585198\tvalid_1's multi_logloss: 1.07413\tvalid_1's macroF1: 0.415203\n",
      "******************** Execution ended in 00h 00hm 25.02s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.878109\ttraining's macroF1: 0.624733\tvalid_1's multi_logloss: 1.01904\tvalid_1's macroF1: 0.444238\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's multi_logloss: 0.944434\ttraining's macroF1: 0.594644\tvalid_1's multi_logloss: 1.0301\tvalid_1's macroF1: 0.455947\n",
      "******************** Execution ended in 00h 00hm 25.05s ********************\n",
      "######################################## 6 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.953349\ttraining's macroF1: 0.591841\tvalid_1's multi_logloss: 1.04193\tvalid_1's macroF1: 0.406456\n",
      "[1000]\ttraining's multi_logloss: 0.824637\ttraining's macroF1: 0.650105\tvalid_1's multi_logloss: 1.03352\tvalid_1's macroF1: 0.409186\n",
      "Early stopping, best iteration is:\n",
      "[753]\ttraining's multi_logloss: 0.879493\ttraining's macroF1: 0.626985\tvalid_1's multi_logloss: 1.03597\tvalid_1's macroF1: 0.423002\n",
      "******************** Execution ended in 00h 00hm 29.79s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.963938\ttraining's macroF1: 0.590233\tvalid_1's multi_logloss: 1.03813\tvalid_1's macroF1: 0.424692\n",
      "Early stopping, best iteration is:\n",
      "[410]\ttraining's multi_logloss: 0.996635\ttraining's macroF1: 0.577165\tvalid_1's multi_logloss: 1.04468\tvalid_1's macroF1: 0.442627\n",
      "******************** Execution ended in 00h 00hm 21.47s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.956514\ttraining's macroF1: 0.581385\tvalid_1's multi_logloss: 1.03896\tvalid_1's macroF1: 0.420451\n",
      "[1000]\ttraining's multi_logloss: 0.826383\ttraining's macroF1: 0.654341\tvalid_1's multi_logloss: 1.02896\tvalid_1's macroF1: 0.416368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's multi_logloss: 0.91827\ttraining's macroF1: 0.602732\tvalid_1's multi_logloss: 1.03433\tvalid_1's macroF1: 0.430506\n",
      "******************** Execution ended in 00h 00hm 27.23s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.957736\ttraining's macroF1: 0.580131\tvalid_1's multi_logloss: 1.01023\tvalid_1's macroF1: 0.416323\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttraining's multi_logloss: 1.00975\ttraining's macroF1: 0.556564\tvalid_1's multi_logloss: 1.02342\tvalid_1's macroF1: 0.433253\n",
      "******************** Execution ended in 00h 00hm 21.77s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.951086\ttraining's macroF1: 0.585451\tvalid_1's multi_logloss: 1.06466\tvalid_1's macroF1: 0.41689\n",
      "[1000]\ttraining's multi_logloss: 0.825518\ttraining's macroF1: 0.647262\tvalid_1's multi_logloss: 1.0506\tvalid_1's macroF1: 0.43435\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's multi_logloss: 0.893727\ttraining's macroF1: 0.616757\tvalid_1's multi_logloss: 1.05651\tvalid_1's macroF1: 0.436505\n",
      "******************** Execution ended in 00h 00hm 26.65s ********************\n",
      "######################################## 7 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.86624\ttraining's macroF1: 0.63572\tvalid_1's multi_logloss: 1.02781\tvalid_1's macroF1: 0.428613\n",
      "[1000]\ttraining's multi_logloss: 0.709401\ttraining's macroF1: 0.71317\tvalid_1's multi_logloss: 1.00714\tvalid_1's macroF1: 0.42395\n",
      "Early stopping, best iteration is:\n",
      "[538]\ttraining's multi_logloss: 0.850819\ttraining's macroF1: 0.642234\tvalid_1's multi_logloss: 1.0257\tvalid_1's macroF1: 0.437373\n",
      "******************** Execution ended in 00h 00hm 30.14s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.857817\ttraining's macroF1: 0.653141\tvalid_1's multi_logloss: 1.03043\tvalid_1's macroF1: 0.407391\n",
      "Early stopping, best iteration is:\n",
      "[264]\ttraining's multi_logloss: 0.978688\ttraining's macroF1: 0.577561\tvalid_1's multi_logloss: 1.05213\tvalid_1's macroF1: 0.414328\n",
      "******************** Execution ended in 00h 00hm 24.41s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.849188\ttraining's macroF1: 0.634484\tvalid_1's multi_logloss: 1.02767\tvalid_1's macroF1: 0.415182\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's multi_logloss: 1.06746\ttraining's macroF1: 0.549949\tvalid_1's multi_logloss: 1.09281\tvalid_1's macroF1: 0.425176\n",
      "******************** Execution ended in 00h 00hm 19.74s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.854518\ttraining's macroF1: 0.637299\tvalid_1's multi_logloss: 1.03708\tvalid_1's macroF1: 0.394324\n",
      "[1000]\ttraining's multi_logloss: 0.701584\ttraining's macroF1: 0.717149\tvalid_1's multi_logloss: 1.02273\tvalid_1's macroF1: 0.418319\n",
      "[1500]\ttraining's multi_logloss: 0.606306\ttraining's macroF1: 0.767006\tvalid_1's multi_logloss: 1.01449\tvalid_1's macroF1: 0.431591\n",
      "Early stopping, best iteration is:\n",
      "[1344]\ttraining's multi_logloss: 0.632074\ttraining's macroF1: 0.754363\tvalid_1's multi_logloss: 1.01667\tvalid_1's macroF1: 0.43438\n",
      "******************** Execution ended in 00h 00hm 50.14s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.854716\ttraining's macroF1: 0.641177\tvalid_1's multi_logloss: 1.0252\tvalid_1's macroF1: 0.392496\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's multi_logloss: 1.10239\ttraining's macroF1: 0.557109\tvalid_1's multi_logloss: 1.11086\tvalid_1's macroF1: 0.421059\n",
      "******************** Execution ended in 00h 00hm 19.71s ********************\n",
      "######################################## 8 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.13485\ttraining's macroF1: 0.545932\tvalid_1's multi_logloss: 1.11509\tvalid_1's macroF1: 0.417749\n",
      "[1000]\ttraining's multi_logloss: 1.02058\ttraining's macroF1: 0.579154\tvalid_1's multi_logloss: 1.0392\tvalid_1's macroF1: 0.421103\n",
      "Early stopping, best iteration is:\n",
      "[681]\ttraining's multi_logloss: 1.08569\ttraining's macroF1: 0.559899\tvalid_1's multi_logloss: 1.07782\tvalid_1's macroF1: 0.43354\n",
      "******************** Execution ended in 00h 00hm 35.93s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1265\ttraining's macroF1: 0.545866\tvalid_1's multi_logloss: 1.16464\tvalid_1's macroF1: 0.399299\n",
      "Early stopping, best iteration is:\n",
      "[388]\ttraining's multi_logloss: 1.1651\ttraining's macroF1: 0.541836\tvalid_1's multi_logloss: 1.19182\tvalid_1's macroF1: 0.403998\n",
      "******************** Execution ended in 00h 00hm 30.33s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12926\ttraining's macroF1: 0.540726\tvalid_1's multi_logloss: 1.12332\tvalid_1's macroF1: 0.419916\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttraining's multi_logloss: 1.23665\ttraining's macroF1: 0.518873\tvalid_1's multi_logloss: 1.21614\tvalid_1's macroF1: 0.430237\n",
      "******************** Execution ended in 00h 00hm 23.31s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12833\ttraining's macroF1: 0.534478\tvalid_1's multi_logloss: 1.1571\tvalid_1's macroF1: 0.351242\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's multi_logloss: 1.38272\ttraining's macroF1: 0.460687\tvalid_1's multi_logloss: 1.38235\tvalid_1's macroF1: 0.370645\n",
      "******************** Execution ended in 00h 00hm 16.05s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.13757\ttraining's macroF1: 0.525382\tvalid_1's multi_logloss: 1.11715\tvalid_1's macroF1: 0.413645\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's multi_logloss: 1.38191\ttraining's macroF1: 0.453489\tvalid_1's multi_logloss: 1.38055\tvalid_1's macroF1: 0.426993\n",
      "******************** Execution ended in 00h 00hm 16.51s ********************\n",
      "######################################## 9 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.831415\ttraining's macroF1: 0.649239\tvalid_1's multi_logloss: 1.04849\tvalid_1's macroF1: 0.396396\n",
      "Early stopping, best iteration is:\n",
      "[455]\ttraining's multi_logloss: 0.850792\ttraining's macroF1: 0.635805\tvalid_1's multi_logloss: 1.05054\tvalid_1's macroF1: 0.406918\n",
      "******************** Execution ended in 00h 00hm 26.94s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.83656\ttraining's macroF1: 0.656886\tvalid_1's multi_logloss: 1.00868\tvalid_1's macroF1: 0.414427\n",
      "Early stopping, best iteration is:\n",
      "[498]\ttraining's multi_logloss: 0.837384\ttraining's macroF1: 0.656653\tvalid_1's multi_logloss: 1.00867\tvalid_1's macroF1: 0.417246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Execution ended in 00h 00hm 30.50s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.852676\ttraining's macroF1: 0.643622\tvalid_1's multi_logloss: 0.978902\tvalid_1's macroF1: 0.435584\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's multi_logloss: 1.37323\ttraining's macroF1: 0.451658\tvalid_1's multi_logloss: 1.36838\tvalid_1's macroF1: 0.44576\n",
      "******************** Execution ended in 00h 00hm 14.69s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.846765\ttraining's macroF1: 0.651693\tvalid_1's multi_logloss: 1.05387\tvalid_1's macroF1: 0.417309\n",
      "Early stopping, best iteration is:\n",
      "[290]\ttraining's multi_logloss: 0.954594\ttraining's macroF1: 0.599856\tvalid_1's multi_logloss: 1.06658\tvalid_1's macroF1: 0.427538\n",
      "******************** Execution ended in 00h 00hm 23.81s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.853493\ttraining's macroF1: 0.644291\tvalid_1's multi_logloss: 1.04768\tvalid_1's macroF1: 0.406642\n",
      "[1000]\ttraining's multi_logloss: 0.69625\ttraining's macroF1: 0.716396\tvalid_1's multi_logloss: 1.02527\tvalid_1's macroF1: 0.420728\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttraining's multi_logloss: 0.734817\ttraining's macroF1: 0.700101\tvalid_1's multi_logloss: 1.03054\tvalid_1's macroF1: 0.424462\n",
      "******************** Execution ended in 00h 00hm 41.04s ********************\n",
      "######################################## 10 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.967041\ttraining's macroF1: 0.571475\tvalid_1's multi_logloss: 1.04772\tvalid_1's macroF1: 0.412504\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttraining's multi_logloss: 1.0131\ttraining's macroF1: 0.550624\tvalid_1's multi_logloss: 1.05428\tvalid_1's macroF1: 0.428768\n",
      "******************** Execution ended in 00h 00hm 21.88s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.986367\ttraining's macroF1: 0.553793\tvalid_1's multi_logloss: 1.00792\tvalid_1's macroF1: 0.450058\n",
      "[1000]\ttraining's multi_logloss: 0.877163\ttraining's macroF1: 0.61779\tvalid_1's multi_logloss: 0.990376\tvalid_1's macroF1: 0.452719\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's multi_logloss: 0.942539\ttraining's macroF1: 0.578915\tvalid_1's multi_logloss: 0.999941\tvalid_1's macroF1: 0.463675\n",
      "******************** Execution ended in 00h 00hm 28.61s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.977735\ttraining's macroF1: 0.587633\tvalid_1's multi_logloss: 1.02946\tvalid_1's macroF1: 0.41338\n",
      "Early stopping, best iteration is:\n",
      "[325]\ttraining's multi_logloss: 1.03957\ttraining's macroF1: 0.553822\tvalid_1's multi_logloss: 1.04096\tvalid_1's macroF1: 0.434535\n",
      "******************** Execution ended in 00h 00hm 20.98s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.956606\ttraining's macroF1: 0.566332\tvalid_1's multi_logloss: 1.07677\tvalid_1's macroF1: 0.376498\n",
      "Early stopping, best iteration is:\n",
      "[284]\ttraining's multi_logloss: 1.03845\ttraining's macroF1: 0.535564\tvalid_1's multi_logloss: 1.08879\tvalid_1's macroF1: 0.386489\n",
      "******************** Execution ended in 00h 00hm 20.90s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.962788\ttraining's macroF1: 0.571146\tvalid_1's multi_logloss: 1.06977\tvalid_1's macroF1: 0.375566\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's multi_logloss: 1.29382\ttraining's macroF1: 0.471716\tvalid_1's multi_logloss: 1.27524\tvalid_1's macroF1: 0.387893\n",
      "******************** Execution ended in 00h 00hm 14.75s ********************\n",
      "######################################## 11 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18598\ttraining's macroF1: 0.611091\tvalid_1's multi_logloss: 1.20289\tvalid_1's macroF1: 0.392699\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's multi_logloss: 1.37056\ttraining's macroF1: 0.567362\tvalid_1's multi_logloss: 1.3703\tvalid_1's macroF1: 0.414206\n",
      "******************** Execution ended in 00h 00hm 20.60s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18489\ttraining's macroF1: 0.634881\tvalid_1's multi_logloss: 1.21493\tvalid_1's macroF1: 0.395796\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's multi_logloss: 1.34778\ttraining's macroF1: 0.590102\tvalid_1's multi_logloss: 1.34959\tvalid_1's macroF1: 0.412136\n",
      "******************** Execution ended in 00h 00hm 23.21s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18329\ttraining's macroF1: 0.625902\tvalid_1's multi_logloss: 1.20201\tvalid_1's macroF1: 0.379771\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's multi_logloss: 1.35654\ttraining's macroF1: 0.588385\tvalid_1's multi_logloss: 1.35563\tvalid_1's macroF1: 0.405971\n",
      "******************** Execution ended in 00h 00hm 22.32s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.17851\ttraining's macroF1: 0.600679\tvalid_1's multi_logloss: 1.22206\tvalid_1's macroF1: 0.352633\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's multi_logloss: 1.3796\ttraining's macroF1: 0.54993\tvalid_1's multi_logloss: 1.37995\tvalid_1's macroF1: 0.366733\n",
      "******************** Execution ended in 00h 00hm 19.86s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18627\ttraining's macroF1: 0.624263\tvalid_1's multi_logloss: 1.1862\tvalid_1's macroF1: 0.426523\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's multi_logloss: 1.3647\ttraining's macroF1: 0.585301\tvalid_1's multi_logloss: 1.36211\tvalid_1's macroF1: 0.445745\n",
      "******************** Execution ended in 00h 00hm 21.28s ********************\n",
      "######################################## 12 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.523873\ttraining's macroF1: 0.821679\tvalid_1's multi_logloss: 0.974113\tvalid_1's macroF1: 0.408888\n",
      "[1000]\ttraining's multi_logloss: 0.353308\ttraining's macroF1: 0.883404\tvalid_1's multi_logloss: 0.968403\tvalid_1's macroF1: 0.411701\n",
      "Early stopping, best iteration is:\n",
      "[522]\ttraining's multi_logloss: 0.511947\ttraining's macroF1: 0.825257\tvalid_1's multi_logloss: 0.973249\tvalid_1's macroF1: 0.420725\n",
      "******************** Execution ended in 00h 00hm 39.41s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.524291\ttraining's macroF1: 0.819298\tvalid_1's multi_logloss: 0.974967\tvalid_1's macroF1: 0.401256\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 1.24865\ttraining's macroF1: 0.599214\tvalid_1's multi_logloss: 1.25162\tvalid_1's macroF1: 0.409793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Execution ended in 00h 00hm 19.51s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.525121\ttraining's macroF1: 0.831955\tvalid_1's multi_logloss: 0.977475\tvalid_1's macroF1: 0.401031\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's multi_logloss: 1.01693\ttraining's macroF1: 0.668915\tvalid_1's multi_logloss: 1.10827\tvalid_1's macroF1: 0.437938\n",
      "******************** Execution ended in 00h 00hm 22.24s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.526178\ttraining's macroF1: 0.827003\tvalid_1's multi_logloss: 0.948465\tvalid_1's macroF1: 0.438522\n",
      "Early stopping, best iteration is:\n",
      "[265]\ttraining's multi_logloss: 0.711536\ttraining's macroF1: 0.765326\tvalid_1's multi_logloss: 0.978541\tvalid_1's macroF1: 0.451425\n",
      "******************** Execution ended in 00h 00hm 29.89s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.518496\ttraining's macroF1: 0.824558\tvalid_1's multi_logloss: 1.01054\tvalid_1's macroF1: 0.399929\n",
      "Early stopping, best iteration is:\n",
      "[404]\ttraining's multi_logloss: 0.577643\ttraining's macroF1: 0.803518\tvalid_1's multi_logloss: 1.01388\tvalid_1's macroF1: 0.410506\n",
      "******************** Execution ended in 00h 00hm 35.11s ********************\n",
      "######################################## 13 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12853\ttraining's macroF1: 0.497624\tvalid_1's multi_logloss: 1.12979\tvalid_1's macroF1: 0.39063\n",
      "[1000]\ttraining's multi_logloss: 1.04844\ttraining's macroF1: 0.526394\tvalid_1's multi_logloss: 1.09834\tvalid_1's macroF1: 0.389833\n",
      "Early stopping, best iteration is:\n",
      "[753]\ttraining's multi_logloss: 1.08142\ttraining's macroF1: 0.509179\tvalid_1's multi_logloss: 1.10667\tvalid_1's macroF1: 0.403896\n",
      "******************** Execution ended in 00h 00hm 31.11s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1271\ttraining's macroF1: 0.489602\tvalid_1's multi_logloss: 1.09997\tvalid_1's macroF1: 0.409231\n",
      "[1000]\ttraining's multi_logloss: 1.04607\ttraining's macroF1: 0.511772\tvalid_1's multi_logloss: 1.05889\tvalid_1's macroF1: 0.422129\n",
      "Early stopping, best iteration is:\n",
      "[954]\ttraining's multi_logloss: 1.05158\ttraining's macroF1: 0.510677\tvalid_1's multi_logloss: 1.05958\tvalid_1's macroF1: 0.432216\n",
      "******************** Execution ended in 00h 00hm 36.03s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12704\ttraining's macroF1: 0.492545\tvalid_1's multi_logloss: 1.11876\tvalid_1's macroF1: 0.406265\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's multi_logloss: 1.13187\ttraining's macroF1: 0.487918\tvalid_1's multi_logloss: 1.12184\tvalid_1's macroF1: 0.411384\n",
      "******************** Execution ended in 00h 00hm 24.67s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.13075\ttraining's macroF1: 0.488169\tvalid_1's multi_logloss: 1.06552\tvalid_1's macroF1: 0.425381\n",
      "Early stopping, best iteration is:\n",
      "[408]\ttraining's multi_logloss: 1.15478\ttraining's macroF1: 0.490898\tvalid_1's multi_logloss: 1.08451\tvalid_1's macroF1: 0.43703\n",
      "******************** Execution ended in 00h 00hm 23.16s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12451\ttraining's macroF1: 0.493502\tvalid_1's multi_logloss: 1.10431\tvalid_1's macroF1: 0.383263\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttraining's multi_logloss: 1.14191\ttraining's macroF1: 0.487265\tvalid_1's multi_logloss: 1.11556\tvalid_1's macroF1: 0.411275\n",
      "******************** Execution ended in 00h 00hm 23.81s ********************\n",
      "######################################## 14 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.767604\ttraining's macroF1: 0.686882\tvalid_1's multi_logloss: 1.07167\tvalid_1's macroF1: 0.356824\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's multi_logloss: 0.979042\ttraining's macroF1: 0.59706\tvalid_1's multi_logloss: 1.07171\tvalid_1's macroF1: 0.371613\n",
      "******************** Execution ended in 00h 00hm 20.93s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.792883\ttraining's macroF1: 0.697599\tvalid_1's multi_logloss: 0.984285\tvalid_1's macroF1: 0.421088\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's multi_logloss: 1.1613\ttraining's macroF1: 0.554807\tvalid_1's multi_logloss: 1.14164\tvalid_1's macroF1: 0.443947\n",
      "******************** Execution ended in 00h 00hm 18.09s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.787879\ttraining's macroF1: 0.68823\tvalid_1's multi_logloss: 1.05585\tvalid_1's macroF1: 0.418751\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 1.304\ttraining's macroF1: 0.516828\tvalid_1's multi_logloss: 1.29422\tvalid_1's macroF1: 0.435738\n",
      "******************** Execution ended in 00h 00hm 16.52s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.7822\ttraining's macroF1: 0.693172\tvalid_1's multi_logloss: 0.9994\tvalid_1's macroF1: 0.40811\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's multi_logloss: 1.07321\ttraining's macroF1: 0.573412\tvalid_1's multi_logloss: 1.08199\tvalid_1's macroF1: 0.42956\n",
      "******************** Execution ended in 00h 00hm 19.25s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.780712\ttraining's macroF1: 0.677841\tvalid_1's multi_logloss: 0.974023\tvalid_1's macroF1: 0.429295\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's multi_logloss: 0.984899\ttraining's macroF1: 0.595151\tvalid_1's multi_logloss: 1.01486\tvalid_1's macroF1: 0.452078\n",
      "******************** Execution ended in 00h 00hm 21.05s ********************\n",
      "######################################## 15 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.67978\ttraining's macroF1: 0.738261\tvalid_1's multi_logloss: 0.978825\tvalid_1's macroF1: 0.401892\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's multi_logloss: 0.907991\ttraining's macroF1: 0.647481\tvalid_1's multi_logloss: 1.02445\tvalid_1's macroF1: 0.421338\n",
      "******************** Execution ended in 00h 00hm 30.66s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.663348\ttraining's macroF1: 0.7589\tvalid_1's multi_logloss: 1.08507\tvalid_1's macroF1: 0.382475\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's multi_logloss: 0.673612\ttraining's macroF1: 0.753276\tvalid_1's multi_logloss: 1.08652\tvalid_1's macroF1: 0.390645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Execution ended in 00h 00hm 41.16s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.67992\ttraining's macroF1: 0.757396\tvalid_1's multi_logloss: 1.00562\tvalid_1's macroF1: 0.415324\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's multi_logloss: 1.0715\ttraining's macroF1: 0.609033\tvalid_1's multi_logloss: 1.11214\tvalid_1's macroF1: 0.432777\n",
      "******************** Execution ended in 00h 00hm 26.18s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.68924\ttraining's macroF1: 0.754932\tvalid_1's multi_logloss: 0.987847\tvalid_1's macroF1: 0.431817\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's multi_logloss: 1.06031\ttraining's macroF1: 0.610049\tvalid_1's multi_logloss: 1.1115\tvalid_1's macroF1: 0.434878\n",
      "******************** Execution ended in 00h 00hm 26.09s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.684778\ttraining's macroF1: 0.753108\tvalid_1's multi_logloss: 0.969977\tvalid_1's macroF1: 0.411005\n",
      "[1000]\ttraining's multi_logloss: 0.509816\ttraining's macroF1: 0.821631\tvalid_1's multi_logloss: 0.948265\tvalid_1's macroF1: 0.405392\n",
      "Early stopping, best iteration is:\n",
      "[608]\ttraining's multi_logloss: 0.633539\ttraining's macroF1: 0.772366\tvalid_1's multi_logloss: 0.962435\tvalid_1's macroF1: 0.424571\n",
      "******************** Execution ended in 00h 00hm 45.88s ********************\n",
      "######################################## 16 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.726111\ttraining's macroF1: 0.733117\tvalid_1's multi_logloss: 0.947519\tvalid_1's macroF1: 0.442424\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's multi_logloss: 0.757841\ttraining's macroF1: 0.718836\tvalid_1's multi_logloss: 0.953413\tvalid_1's macroF1: 0.446535\n",
      "******************** Execution ended in 00h 00hm 36.58s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.691365\ttraining's macroF1: 0.740233\tvalid_1's multi_logloss: 1.02118\tvalid_1's macroF1: 0.403252\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's multi_logloss: 0.756953\ttraining's macroF1: 0.714202\tvalid_1's multi_logloss: 1.02329\tvalid_1's macroF1: 0.423978\n",
      "******************** Execution ended in 00h 00hm 33.31s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.723493\ttraining's macroF1: 0.725842\tvalid_1's multi_logloss: 1.00882\tvalid_1's macroF1: 0.43542\n",
      "[1000]\ttraining's multi_logloss: 0.523467\ttraining's macroF1: 0.819037\tvalid_1's multi_logloss: 0.984786\tvalid_1's macroF1: 0.443243\n",
      "[1500]\ttraining's multi_logloss: 0.40497\ttraining's macroF1: 0.861607\tvalid_1's multi_logloss: 0.985378\tvalid_1's macroF1: 0.435171\n",
      "Early stopping, best iteration is:\n",
      "[1101]\ttraining's multi_logloss: 0.494953\ttraining's macroF1: 0.833919\tvalid_1's multi_logloss: 0.984614\tvalid_1's macroF1: 0.450113\n",
      "******************** Execution ended in 00h 00hm 58.12s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.703376\ttraining's macroF1: 0.755941\tvalid_1's multi_logloss: 0.999468\tvalid_1's macroF1: 0.432578\n",
      "[1000]\ttraining's multi_logloss: 0.504902\ttraining's macroF1: 0.83334\tvalid_1's multi_logloss: 0.98781\tvalid_1's macroF1: 0.446502\n",
      "Early stopping, best iteration is:\n",
      "[933]\ttraining's multi_logloss: 0.524686\ttraining's macroF1: 0.825917\tvalid_1's multi_logloss: 0.989405\tvalid_1's macroF1: 0.457074\n",
      "******************** Execution ended in 00h 00hm 54.25s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.717284\ttraining's macroF1: 0.721969\tvalid_1's multi_logloss: 1.01748\tvalid_1's macroF1: 0.401448\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-206-595ac4085970>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m               \u001b[1;34m'min_child_weight'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m              }\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtemp_shap_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_good_features_using_shap_LGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mtotal_shap_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtotal_shap_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_shap_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-205-84c75fbb9427>\u001b[0m in \u001b[0;36mextract_good_features_using_shap_LGB\u001b[1;34m(params, SEED)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb, categorical_feature=categorical_feats,\n\u001b[1;32m---> 34\u001b[1;33m                 early_stopping_rounds=500, verbose=500)\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mshap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mfold_importance_df\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    806\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_shap_df  = pd.DataFrame()\n",
    "NUM_ITERATIONS = 50\n",
    "for SEED in range(NUM_ITERATIONS):\n",
    "    print('#'*40, '{} of {} iterations'.format(SEED+1, NUM_ITERATIONS), '#' * 40)\n",
    "    params = {'max_depth': np.random.choice([5, 6, 7, 8, 10, 12, -1]),\n",
    "             'learning_rate': np.random.rand() * 0.02,\n",
    "              'colsample_bytree': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'subsample': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'min_split_gain': np.random.rand() * 0.2,\n",
    "              'num_leaves': np.random.choice([32, 48, 64]),\n",
    "              'reg_alpha': np.random.rand() * 2,\n",
    "              'reg_lambda': np.random.rand() *2,\n",
    "              'bagging_freq': np.random.randint(4) +1,\n",
    "              'min_child_weight': np.random.randint(100) + 20\n",
    "             }\n",
    "    temp_shap_df = extract_good_features_using_shap_LGB(params, SEED)\n",
    "    total_shap_df = pd.concat([total_shap_df, temp_shap_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sorted_df = total_shap_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "feat_imp_sorted_df = total_shap_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n",
    "features_top_shap = shap_sorted_df['feature'][:500]\n",
    "features_top_feat_imp = feat_imp_sorted_df['feature'][:500]\n",
    "top_features = pd.Series(features_top_shap.tolist() + features_top_feat_imp.tolist())\n",
    "top_features = top_features.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4. Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train[top_features].copy()\n",
    "new_test = test[top_feautures].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new_train shape: ', new_train.shape, 'new_test shape: ', new_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorical_feats = [col for col in top_features if col in categorical_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_OOF(params, categorical_feats, N_FOLDs, SEED=1989):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 10\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "    predicts_result = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(new_train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = new_train.iloc[train_index], new_train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb,categorical_feature=new_categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        predicts_result.append(clf.predict(new_test))\n",
    "        print_execution_time(start)\n",
    "    return predicts_result, feat_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 6,\n",
    "         'learning_rate': 0.002,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_split_gain': 0.02,\n",
    "          'num_leaves': 48,\n",
    "          'reg_alpha': 0.04,\n",
    "          'reg_lambda': 0.073,\n",
    "          'bagging_freq': 2,\n",
    "          'min_child_weight': 40\n",
    "         }\n",
    "\n",
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "predicts_result, feat_importance_df = LGB_OOF(params, new_categorical_feats, N_Folds, SEED=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (20, 20))\n",
    "\n",
    "feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending = False).reset_index()\n",
    "\n",
    "num_features = 50\n",
    "sns.barplot(x=feat_importance_df_shap.shap_values[:num_features], y = feat_importance_df_shap.feature[:num_features], ax = ax[0])\n",
    "ax[0].set_title('Feature importance based on shap values')\n",
    "\n",
    "feat_importance_df = feat_importance_df.groupby('feature').mean().sort_values('feat_imp', ascending = False).reset_index()\n",
    "\n",
    "num_features= 50\n",
    "sns.barplot(x = feat_importance_df.shap_values[:num_features], y = feat_importance_df.feature[:num_features], ax=ax[1])\n",
    "\n",
    "ax[1].set_title('Feature importance based on feature importance from lgbm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predictions_result).mean(axis = 0).round().astype(int)\n",
    "\n",
    "# submission.to_csv('submission_with_new_feature_set.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_param = None\n",
    "lowest_cv = 1000\n",
    "total_iteration = 100\n",
    "\n",
    "for i in range(total_iteration):\n",
    "    print('-'*20, 'For {} of {} iterations'.format(i+1, total_iteration), '-'*20)\n",
    "    learning_rate = np.random.rand() * 0.02\n",
    "    n_folds = 3\n",
    "    \n",
    "    num_class = len(np.unique(y))\n",
    "    \n",
    "    params = {}\n",
    "    params['application'] = 'multiclass'\n",
    "    params['metric'] = 'multi_logloss'\n",
    "    params['num_class'] = num_class\n",
    "    params['class_weight'] = 'balanced'\n",
    "    params['num_leaves'] = np.random.randint(24, 48)\n",
    "    params['max_depth'] = np.random.randint(5, 8)\n",
    "    params['min_child_weight'] = np.random.randint(5, 50)\n",
    "    params['min_split_gain'] = np.random.rand() * 0.09\n",
    "    params['colsample_bytree'] = np.random.rand() * (0.9 - 0.1) + 0.1\n",
    "    params['subsample'] = np.random.rand() * (1 - 0.8) + 0.8\n",
    "    params['bagging_freq'] = np.random.randint(1, 5)\n",
    "    params['bagging_seed'] = np.random.randint(1, 5)\n",
    "    params['reg_alpha'] = np.random.rand() * 2\n",
    "    params['reg_lambda'] = np.random.rand() * 2\n",
    "    params['learning_rate'] = np.random.rand() * 0.02\n",
    "    params['seed']  =1989\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

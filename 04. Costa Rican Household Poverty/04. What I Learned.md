## 04. What I Learned

> 캐글 커널 커리큘럼을 통해 배운 것을 정리한 것입니다.
>
> 네번째 캐글 커널은 [costa Rican Household poverty level](https://www.kaggle.com/c/costa-rican-household-poverty-prediction)입니다.
>
> 다중 분류

<br>

### 0. 배경 이해

- 가정의 가난 수준 예측

<br>

### 1. [첫번째 커널](https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough)

> [본인이 공부한 내용]([https://github.com/donge-can/kaggle_practice/blob/master/04.%20Costa%20Rican%20Household%20Poverty/04.%20Costa%20Rican%20Household%20Poverty_pilsa_01.ipynb](https://github.com/donge-can/kaggle_practice/blob/master/04. Costa Rican Household Poverty/04. Costa Rican Household Poverty_pilsa_01.ipynb))
>
> 다중공산성 등 변수간의 상관관계의 중요성을 다시금 확인

<br>

#### 1.1 `RFECV`

- Recursive Feature Elimination with Cross Validation
- Feature Importance가 작은 순으로 Feature를 제거하면서 Cross Validation score 측정(교차 검정 성능)

- CV를 사용해, 재귀적으로 특성 제거

<br>

#### 1.2 Built-in magic commands

- 주피터 노트북 내에서 사용하는 Magic

```python
%%capture --no-display
```

- [참고](https://ipython.readthedocs.io/en/stable/interactive/magics.html)

#### 1.3 성능 지표

- `Macro F1`

<br>

#### 1.4 hyperopt

<br>

#### 1.5 SHAP

- SHapley Additive exPlanations
  -  A, B, C Feature가 있다고 할 때, A, B, C가 Target 값에 미치는 영향도를 100이라고 합시다. 이때 B를 제거했을 때, A와 C가 Target 값에 미치는 영향도가 80이라면, B의 영향도 (다른 말로 하면 중요도)는 20이 됩니다. 이런 식으로 각 feature마다의 영향도를 측정해주는 것이 SHAP입니다. [(Reference2)](https://shap.readthedocs.io/en/latest/)
  - 참고로, SHAP에서 구한 중요도와 *clf.feature_importances_*에서 구한 중요도는 서로 다릅니다. 중요도를 구하는 식이 각기 다르기 때문입니다. 따라서 SHAP로 구한 TOP 500개의 feature와 *clf.feature_importances_*로 구한 TOP 500개의 feature를 합한 뒤 unique 값만 추출했습니다. 그러면 538개의 feature가 구해집니다. 3,200개가량의 feature를 538개로 줄인 겁니다.
  - [출처]([https://bkshin.tistory.com/entry/%EC%BA%90%EA%B8%80-6-Costa-Rican-Household-Poverty-Level-Prediction](https://bkshin.tistory.com/entry/캐글-6-Costa-Rican-Household-Poverty-Level-Prediction))

### 2. [두번째 커널](https://www.kaggle.com/youhanlee/3250feats-532-feats-using-shap-lb-0-436)

> [본인이 공부한 내용]([https://github.com/donge-can/kaggle_practice/blob/master/04.%20Costa%20Rican%20Household%20Poverty/04.%20Costa%20Rican%20Household%20Poverty_pilsa_02.ipynb](https://github.com/donge-can/kaggle_practice/blob/master/04. Costa Rican Household Poverty/04. Costa Rican Household Poverty_pilsa_02.ipynb))

<br>

#### 2.1 tqdm

- 상태 진행률 시각적으로 표현

<br>

### 3. [세번째  커널](https://www.kaggle.com/skooch/xgboost)

> [본인이 공부한 내용]([https://github.com/donge-can/kaggle_practice/blob/master/04.%20Costa%20Rican%20Household%20Poverty/04.%20Costa%20Rican%20Household%20Poverty_pilsa_03.ipynb](https://github.com/donge-can/kaggle_practice/blob/master/04. Costa Rican Household Poverty/04. Costa Rican Household Poverty_pilsa_03.ipynb))

<br>

#### 3.1 np.isin()

<br>

#### 3.2 clone

```python
from sklearn.base import clone
```

- model 만 복사하는 함수
- 데이터는 복사하지 않음

```python
for epoch in range(1000):
    sgd_reg.fit(X_train_poly_scaled, y_predict)
    
    y_val_predict = sgd_reg.predict(X_val_poly_scaled)
    val_error = mean_squared_error(y_predict, y_val_predict)
    if val_error <minimum_val_error:
        minimum_val_error = val_error
        best_epoch =epoch
        
        best_model = clone(sgd_reg)
```

- [참고]([https://hoony-gunputer.tistory.com/entry/%ED%95%B8%EC%A6%88%EC%98%A8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-4%EA%B0%95-%EB%AA%A8%EB%8D%B8%ED%95%99%EC%8A%B5-2%ED%8E%B8](https://hoony-gunputer.tistory.com/entry/핸즈온-머신러닝-4강-모델학습-2편)) 


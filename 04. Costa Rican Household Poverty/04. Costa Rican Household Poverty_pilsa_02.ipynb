{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 커널 : https://www.kaggle.com/youhanlee/3250feats-532-feats-using-shap-lb-0-436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(font_scale=2.2)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import featuretools as ft\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/user/Desktop/kaggle_data/04. costa-rican-household-poverty-prediction/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1. Check datasets\n",
    "#### 1.1 Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path+'train.csv')\n",
    "df_test = pd.read_csv(path+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (9557, 143)    df_test shape:  (23856, 142)\n"
     ]
    }
   ],
   "source": [
    "print('df_train shape:', df_train.shape, '  ', 'df_test shape: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
       "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
       "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
       "0     0  ...          100    1849               1        100             0   \n",
       "1     0  ...          144    4489               1        144             0   \n",
       "2     0  ...          121    8464               1          0             0   \n",
       "3     0  ...           81     289              16        121             4   \n",
       "4     0  ...          121    1369              16        121             4   \n",
       "\n",
       "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
       "0         1.000000            0.0      100.0   1849       4  \n",
       "1         1.000000           64.0      144.0   4489       4  \n",
       "2         0.250000           64.0      121.0   8464       4  \n",
       "3         1.777778            1.0      121.0    289       4  \n",
       "4         1.777778            1.0      121.0   1369       4  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_2f6873615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1c78846d2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>256</td>\n",
       "      <td>1681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_e5442cf6a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>289</td>\n",
       "      <td>1681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_a8db26a79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>256</td>\n",
       "      <td>3481</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256.00</td>\n",
       "      <td>3481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_a62966799</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>121</td>\n",
       "      <td>324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>64.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_2f6873615       NaN       0      5       0     1       1     0    NaN   \n",
       "1  ID_1c78846d2       NaN       0      5       0     1       1     0    NaN   \n",
       "2  ID_e5442cf6a       NaN       0      5       0     1       1     0    NaN   \n",
       "3  ID_a8db26a79       NaN       0     14       0     1       1     1    1.0   \n",
       "4  ID_a62966799  175000.0       0      4       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  age  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  \\\n",
       "0     1  ...    4            0      16               9          0   \n",
       "1     1  ...   41          256    1681               9          0   \n",
       "2     1  ...   41          289    1681               9          0   \n",
       "3     0  ...   59          256    3481               1        256   \n",
       "4     0  ...   18          121     324               1          0   \n",
       "\n",
       "   SQBhogar_nin  SQBovercrowding  SQBdependency  SQBmeaned  agesq  \n",
       "0             1             2.25           0.25     272.25     16  \n",
       "1             1             2.25           0.25     272.25   1681  \n",
       "2             1             2.25           0.25     272.25   1681  \n",
       "3             0             1.00           0.00     256.00   3481  \n",
       "4             1             0.25          64.00        NaN    324  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns=='adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n",
      "v2a1\n",
      "hacdor\n",
      "rooms\n",
      "hacapo\n",
      "v14a\n",
      "refrig\n",
      "v18q\n",
      "v18q1\n",
      "r4h1\n",
      "r4h2\n",
      "r4h3\n",
      "r4m1\n",
      "r4m2\n",
      "r4m3\n",
      "r4t1\n",
      "r4t2\n",
      "r4t3\n",
      "tamhog\n",
      "tamviv\n",
      "escolari\n",
      "rez_esc\n",
      "hhsize\n",
      "paredblolad\n",
      "paredzocalo\n",
      "paredpreb\n",
      "pareddes\n",
      "paredmad\n",
      "paredzinc\n",
      "paredfibras\n",
      "paredother\n",
      "pisomoscer\n",
      "pisocemento\n",
      "pisoother\n",
      "pisonatur\n",
      "pisonotiene\n",
      "pisomadera\n",
      "techozinc\n",
      "techoentrepiso\n",
      "techocane\n",
      "techootro\n",
      "cielorazo\n",
      "abastaguadentro\n",
      "abastaguafuera\n",
      "abastaguano\n",
      "public\n",
      "planpri\n",
      "noelec\n",
      "coopele\n",
      "sanitario1\n",
      "sanitario2\n",
      "sanitario3\n",
      "sanitario5\n",
      "sanitario6\n",
      "energcocinar1\n",
      "energcocinar2\n",
      "energcocinar3\n",
      "energcocinar4\n",
      "elimbasu1\n",
      "elimbasu2\n",
      "elimbasu3\n",
      "elimbasu4\n",
      "elimbasu5\n",
      "elimbasu6\n",
      "epared1\n",
      "epared2\n",
      "epared3\n",
      "etecho1\n",
      "etecho2\n",
      "etecho3\n",
      "eviv1\n",
      "eviv2\n",
      "eviv3\n",
      "dis\n",
      "male\n",
      "female\n",
      "estadocivil1\n",
      "estadocivil2\n",
      "estadocivil3\n",
      "estadocivil4\n",
      "estadocivil5\n",
      "estadocivil6\n",
      "estadocivil7\n",
      "parentesco1\n",
      "parentesco2\n",
      "parentesco3\n",
      "parentesco4\n",
      "parentesco5\n",
      "parentesco6\n",
      "parentesco7\n",
      "parentesco8\n",
      "parentesco9\n",
      "parentesco10\n",
      "parentesco11\n",
      "parentesco12\n",
      "idhogar\n",
      "hogar_nin\n",
      "hogar_adul\n",
      "hogar_mayor\n",
      "hogar_total\n",
      "dependency\n",
      "edjefe\n",
      "edjefa\n",
      "meaneduc\n",
      "instlevel1\n",
      "instlevel2\n",
      "instlevel3\n",
      "instlevel4\n",
      "instlevel5\n",
      "instlevel6\n",
      "instlevel7\n",
      "instlevel8\n",
      "instlevel9\n",
      "bedrooms\n",
      "overcrowding\n",
      "tipovivi1\n",
      "tipovivi2\n",
      "tipovivi3\n",
      "tipovivi4\n",
      "tipovivi5\n",
      "computer\n",
      "television\n",
      "mobilephone\n",
      "qmobilephone\n",
      "lugar1\n",
      "lugar2\n",
      "lugar3\n",
      "lugar4\n",
      "lugar5\n",
      "lugar6\n",
      "area1\n",
      "area2\n",
      "age\n",
      "SQBescolari\n",
      "SQBage\n",
      "SQBhogar_total\n",
      "SQBedjefe\n",
      "SQBhogar_nin\n",
      "SQBovercrowding\n",
      "SQBdependency\n",
      "SQBmeaned\n",
      "agesq\n"
     ]
    }
   ],
   "source": [
    "for i in df_test.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2 Make description df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "#### 1.3 Check Null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rez_esc</th>\n",
       "      <td>7928</td>\n",
       "      <td>82.954902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v18q1</th>\n",
       "      <td>7342</td>\n",
       "      <td>76.823271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2a1</th>\n",
       "      <td>6860</td>\n",
       "      <td>71.779847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaneduc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQBmeaned</th>\n",
       "      <td>5</td>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techozinc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techoentrepiso</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techocane</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techootro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cielorazo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguadentro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguafuera</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguano</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planpri</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noelec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coopele</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total    Percent\n",
       "rez_esc           7928  82.954902\n",
       "v18q1             7342  76.823271\n",
       "v2a1              6860  71.779847\n",
       "meaneduc             5   0.052318\n",
       "SQBmeaned            5   0.052318\n",
       "techozinc            0   0.000000\n",
       "techoentrepiso       0   0.000000\n",
       "techocane            0   0.000000\n",
       "techootro            0   0.000000\n",
       "cielorazo            0   0.000000\n",
       "abastaguadentro      0   0.000000\n",
       "sanitario3           0   0.000000\n",
       "abastaguafuera       0   0.000000\n",
       "abastaguano          0   0.000000\n",
       "public               0   0.000000\n",
       "planpri              0   0.000000\n",
       "noelec               0   0.000000\n",
       "coopele              0   0.000000\n",
       "sanitario1           0   0.000000\n",
       "sanitario2           0   0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending = False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending = False)\n",
    "missing_df = pd.concat([total, percent], axis =1, keys = ['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.4 Fill Missing values\n",
    "- edjefe : 남자 교육 기간\n",
    "- edjefa : 여자 교육 기간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefa\"] = df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefe\"] = df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefa\"] = df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefe\"] = df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with 4\n",
    "df_train.loc[df_train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_train.loc[df_train['edjefe'] == \"yes\", \"edjefe\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_test.loc[df_test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# create feature with max education of either head of household\n",
    "df_train['edjef'] = np.max(df_train[['edjefa','edjefe']], axis=1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa','edjefe']], axis=1)\n",
    "\n",
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n",
    "# if there is no water we'll assume they do not\n",
    "df_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"v14a\"] = 0\n",
    "df_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "df_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"v14a\"] = 0\n",
    "df_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**reaz_esz, SQBmeaned**\n",
    "- `rez_esc` : years behind in school-> filled with 0\n",
    "- `SQBmeaned` : square of the mean years of education of adults in the household ages, Age squared - > same with rez_esc -> filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc'].fillna(0, inplace = True)\n",
    "df_test['rez_esc'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SQBmeaned'].fillna(0, inplace = True)\n",
    "df_test['SQBmeaned'].fillna(0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**meaneduc**\n",
    "\n",
    "- meaneduc : avearge years of education for adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['meaneduc'].fillna(0, inplace = True)\n",
    "df_test['meaneduc'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**v18q1**\n",
    "\n",
    "- number of tablets household own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7342\n",
       "1    2215\n",
       "Name: v18q, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.v18q.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1586\n",
       "2.0     444\n",
       "3.0     129\n",
       "4.0      37\n",
       "5.0      13\n",
       "6.0       6\n",
       "Name: v18q1, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['v18q'] == 1, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: v18q1, dtype: int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['v18q1'] == 0, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v18q1'].fillna(0, inplace = True)\n",
    "df_test['v18q1'].fillna(0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**tipovivi3**\n",
    "\n",
    "- rent or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7821\n",
       "1    1736\n",
       "Name: tipovivi3, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['tipovivi3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 1, 'v2a1'], label = 'Monthly rent paymetn of household(rented =1)')\n",
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] ==0, 'v2a1'], label = 'Montly rent payment of household (rent =0)')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v2a1'].fillna(0, inplace = True)\n",
    "df_test['v2a1'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edjef</th>\n",
       "      <td>9557</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coopele</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noelec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planpri</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguano</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguafuera</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguadentro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cielorazo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techootro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techocane</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techoentrepiso</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techozinc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energcocinar1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total  Percent\n",
       "edjef             9557    100.0\n",
       "Target               0      0.0\n",
       "sanitario3           0      0.0\n",
       "sanitario2           0      0.0\n",
       "sanitario1           0      0.0\n",
       "coopele              0      0.0\n",
       "noelec               0      0.0\n",
       "planpri              0      0.0\n",
       "public               0      0.0\n",
       "abastaguano          0      0.0\n",
       "abastaguafuera       0      0.0\n",
       "abastaguadentro      0      0.0\n",
       "cielorazo            0      0.0\n",
       "techootro            0      0.0\n",
       "techocane            0      0.0\n",
       "techoentrepiso       0      0.0\n",
       "techozinc            0      0.0\n",
       "sanitario5           0      0.0\n",
       "sanitario6           0      0.0\n",
       "energcocinar1        0      0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending = False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending = False)\n",
    "\n",
    "missing_df = pd.concat([total, percent], axis = 1, keys = ['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edjef</th>\n",
       "      <td>23856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguano</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coopele</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noelec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planpri</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguafuera</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abastaguadentro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cielorazo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techootro</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techocane</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techoentrepiso</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techozinc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitario6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pisonotiene</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elimbasu5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total  Percent\n",
       "edjef            23856    100.0\n",
       "abastaguano          0      0.0\n",
       "sanitario2           0      0.0\n",
       "sanitario1           0      0.0\n",
       "coopele              0      0.0\n",
       "noelec               0      0.0\n",
       "planpri              0      0.0\n",
       "public               0      0.0\n",
       "abastaguafuera       0      0.0\n",
       "sanitario5           0      0.0\n",
       "abastaguadentro      0      0.0\n",
       "cielorazo            0      0.0\n",
       "techootro            0      0.0\n",
       "techocane            0      0.0\n",
       "techoentrepiso       0      0.0\n",
       "techozinc            0      0.0\n",
       "sanitario3           0      0.0\n",
       "sanitario6           0      0.0\n",
       "pisonotiene          0      0.0\n",
       "elimbasu5            0      0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_test.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_test.isnull().sum() / df_test.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2. Feature Engineering\n",
    "\n",
    "#### 2.1 Object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_object = [col for col in df_train.columns if df_train[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_object = []\n",
    "for col in df_train.select_dtypes('object'):\n",
    "    features_object.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['Id', 'idhogar', 'dependency', 'edjefe', 'edjefa']"
      ],
      "text/plain": [
       "['Id', 'idhogar', 'dependency', 'edjefe', 'edjefa']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**dependency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['dependency'] = np.sqrt(df_train['SQBdependency'])\n",
    "df_test['dependency'] = np.sqrt(df_test['SQBdependency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**edjefe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefe(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df_train['edjefe'] = df_train['edjefe'].apply(replace_edjefe).astype(float)\n",
    "df_test['edjefe'] = df_test['edjefe'].apply(replace_edjefe).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**edjefa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefa(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df_train['edjefa'] = df_train['edjefa'].apply(replace_edjefa).astype(float)\n",
    "df_test['edjefa'] = df_test['edjefa'].apply(replace_edjefa).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['edjef'] = np.max(df_train[['edjefa', 'edjefe']], axis = 1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa', 'edjefe']], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**roof and electricity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['roof_waste_material'] = np.nan\n",
    "df_test['roof_waste_material'] = np.nan\n",
    "df_train['electricity_other'] = np.nan\n",
    "df_test['electricity_other'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_roof_exception(x):\n",
    "    if (x['techozinc'] ==0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def fill_no_electricity(x):\n",
    "    if (x['public'] ==0) and(x['planpri'] ==0) and (x['noelec'] ==0) and(x['coopele'] ==0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['roof_waste_material'] = df_train.apply(lambda x : fill_roof_exception(x), axis =1)\n",
    "df_test['roof_waste_material'] = df_test.apply(lambda x : fill_roof_exception(x), axis =1)\n",
    "\n",
    "df_train['electricity_other'] = df_train.apply(lambda x : fill_no_electricity(x), axis =1)\n",
    "df_test['electricity_other'] = df_test.apply(lambda x : fill_no_electricity(x), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.2 Extract cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in df_train.columns if df_train[col].value_counts().shape[0] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.3 Make new features using continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [col for col in df_train.columns if col not in binary_cat_features]\n",
    "continuous_features = [col for col in continuous_features if col not in features_object]\n",
    "continuous_features = [col for col in continuous_features if col not in ['Id', 'Target', 'idhogar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 continuous features\n"
     ]
    }
   ],
   "source": [
    "print('There are {} continuous features'.format(len(continuous_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0     2792\n",
       "11.0    1150\n",
       "9.0      723\n",
       "8.0      474\n",
       "15.0     473\n",
       "3.0      459\n",
       "0.0      435\n",
       "7.0      413\n",
       "4.0      400\n",
       "5.0      398\n",
       "14.0     328\n",
       "17.0     278\n",
       "2.0      278\n",
       "16.0     247\n",
       "10.0     207\n",
       "12.0     185\n",
       "13.0     155\n",
       "1.0       65\n",
       "21.0      48\n",
       "18.0      22\n",
       "19.0      18\n",
       "20.0       9\n",
       "Name: edjef, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['edjef'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `hhsize` 와 `tamhog` 이 똑같은 의미라고 판단해, tamhog 지움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('tamhog', axis = 1, inplace = True)\n",
    "df_test.drop('tamhog', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Family features\n",
    "- hogar_nin, hogar_adul, hogar_mayor, hogar_total, r4h1, r4h2, r4h3, r4m1, r4m2, r4m3, r4t1, r4t2, r4t3, tmbhog, tamvid, rez_esc, escolari\n",
    "\n",
    "**Family size features (substract, ratio)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['adult'] = df_train['hogar_adul'] - df_train['hogar_mayor']\n",
    "\n",
    "df_train['dependency_count'] = df_train['hogar_nin'] + df_train['hogar_mayor']\n",
    "\n",
    "df_train['dependency'] = df_train['dependency_count'] / df_train['adult']\n",
    "\n",
    "df_train['child_percent'] = df_train['hogar_nin'] / df_train['hogar_total']\n",
    "\n",
    "df_train['elder_percent'] = df_train['hogar_mayor'] / df_train['hogar_total']\n",
    "\n",
    "df_train['adult_percent'] = df_train['hogar_adul'] / df_train['hogar_total']\n",
    "\n",
    "df_train['males_younger_12_years_percent'] = df_train['r4h1'] / df_train['hogar_total']\n",
    "\n",
    "df_train['males_older_12_years_percent'] = df_train['r4h2'] / df_train['hogar_total']\n",
    "\n",
    "df_train['males_percent'] = df_train['r4h3'] / df_train['hogar_total']\n",
    "\n",
    "df_train['females_younger_12_years_percent'] = df_train['r4m1'] / df_train['hogar_total']\n",
    "\n",
    "df_train['females_older_12_years_percent'] = df_train['r4m2'] / df_train['hogar_total']\n",
    "\n",
    "df_train['females_percent'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "\n",
    "df_train['persons_younger_12_years_percent'] = df_train['r4t1'] / df_train['hogar_total']\n",
    "\n",
    "df_train['persons_older_12_years_percent'] = df_train['r4t2'] / df_train['hogar_total']\n",
    "\n",
    "df_train['persons_percent'] = df_train['r4t3'] / df_train['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['adult'] = df_test['hogar_adul'] - df_test['hogar_mayor']\n",
    "\n",
    "df_test['dependency_count'] = df_test['hogar_nin'] + df_test['hogar_mayor']\n",
    "\n",
    "df_test['dependency'] = df_test['dependency_count'] / df_test['adult']\n",
    "\n",
    "df_test['child_percent'] = df_test['hogar_nin'] / df_test['hogar_total']\n",
    "\n",
    "df_test['elder_percent'] = df_test['hogar_mayor'] / df_test['hogar_total']\n",
    "\n",
    "df_test['adult_percent'] = df_test['hogar_adul'] / df_test['hogar_total']\n",
    "\n",
    "df_test['males_younger_12_years_percent'] = df_test['r4h1'] / df_test['hogar_total']\n",
    "\n",
    "df_test['males_older_12_years_percent'] = df_test['r4h2'] / df_test['hogar_total']\n",
    "\n",
    "df_test['males_percent'] = df_test['r4h3'] / df_test['hogar_total']\n",
    "\n",
    "df_test['females_younger_12_years_percent'] = df_test['r4m1'] / df_test['hogar_total']\n",
    "\n",
    "df_test['females_older_12_years_percent'] = df_test['r4m2'] / df_test['hogar_total']\n",
    "\n",
    "df_test['females_percent'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "\n",
    "df_test['persons_younger_12_years_percent'] = df_test['r4t1'] / df_test['hogar_total']\n",
    "\n",
    "df_test['persons_older_12_years_percent'] = df_test['r4t2'] / df_test['hogar_total']\n",
    "\n",
    "df_test['persons_percent'] = df_test['r4t3'] / df_test['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['males_younger_12_years_in_household_size'] = df_train['r4h1'] / df_train['hhsize']\n",
    "df_train['males_older_12_years_in_household_size'] = df_train['r4h2'] / df_train['hhsize']\n",
    "df_train['males_in_household_size'] = df_train['r4h3'] / df_train['hhsize']\n",
    "df_train['females_younger_12_years_in_household_size'] = df_train['r4m1'] / df_train['hhsize']\n",
    "df_train['females_older_12_years_in_household_size'] = df_train['r4m2'] / df_train['hhsize']\n",
    "df_train['females_in_household_size'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "df_train['persons_younger_12_years_in_household_size'] = df_train['r4t1'] / df_train['hhsize']\n",
    "df_train['persons_older_12_years_in_household_size'] = df_train['r4t2'] / df_train['hhsize']\n",
    "df_train['persons_in_household_size'] = df_train['r4t3'] / df_train['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['males_younger_12_years_in_household_size'] = df_test['r4h1'] / df_test['hhsize']\n",
    "df_test['males_older_12_years_in_household_size'] = df_test['r4h2'] / df_test['hhsize']\n",
    "df_test['males_in_household_size'] = df_test['r4h3'] / df_test['hhsize']\n",
    "df_test['females_younger_12_years_in_household_size'] = df_test['r4m1'] / df_test['hhsize']\n",
    "df_test['females_older_12_years_in_household_size'] = df_test['r4m2'] / df_test['hhsize']\n",
    "df_test['females_in_household_size'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "df_test['persons_younger_12_years_in_household_size'] = df_test['r4t1'] / df_test['hhsize']\n",
    "df_test['persons_older_12_years_in_household_size'] = df_test['r4t2'] / df_test['hhsize']\n",
    "df_test['persons_in_household_size'] = df_test['r4t3'] / df_test['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['overcrowding_room_and_bedroom'] = (df_train['hacdor'] + df_train['hacapo'])/2\n",
    "df_test['overcrowding_room_and_bedroom'] = (df_test['hacdor'] + df_test['hacapo'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['escolari_age'] = df_train['escolari']/df_train['age']\n",
    "df_test['escolari_age'] = df_test['escolari']/df_test['age']\n",
    "\n",
    "df_train['age_12_19'] = df_train['hogar_nin'] - df_train['r4t1']\n",
    "df_test['age_12_19'] = df_test['hogar_nin'] - df_test['r4t1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['phones-per-capita'] = df_train['qmobilephone'] / df_train['tamviv']\n",
    "df_train['tablets-per-capita'] = df_train['v18q1'] / df_train['tamviv']\n",
    "df_train['rooms-per-capita'] = df_train['rooms'] / df_train['tamviv']\n",
    "df_train['rent-per-capita'] = df_train['v2a1'] / df_train['tamviv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['phones-per-capita'] = df_test['qmobilephone'] / df_test['tamviv']\n",
    "df_test['tablets-per-capita'] = df_test['v18q1'] / df_test['tamviv']\n",
    "df_test['rooms-per-capita'] = df_test['rooms'] / df_test['tamviv']\n",
    "df_test['rent-per-capita'] = df_test['v2a1'] / df_test['tamviv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9509"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train['hogar_total'] == df_train['r4t3']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Rent per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size_features = ['adult', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total', 'r4h1', \n",
    "                        'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'hhsize']\n",
    "new_feats = []\n",
    "\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v2a1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v2a1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v2a1'] / df_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['new_v2a1_per_adult', 'new_v2a1_per_hogar_adul', 'new_v2a1_per_hogar_mayor', 'new_v2a1_per_hogar_nin', 'new_v2a1_per_hogar_total', 'new_v2a1_per_r4h1', 'new_v2a1_per_r4h2', 'new_v2a1_per_r4h3', 'new_v2a1_per_r4m1', 'new_v2a1_per_r4m2', 'new_v2a1_per_r4m3', 'new_v2a1_per_r4t1', 'new_v2a1_per_r4t2', 'new_v2a1_per_r4t3', 'new_v2a1_per_hhsize']"
      ],
      "text/plain": [
       "['new_v2a1_per_adult',\n",
       " 'new_v2a1_per_hogar_adul',\n",
       " 'new_v2a1_per_hogar_mayor',\n",
       " 'new_v2a1_per_hogar_nin',\n",
       " 'new_v2a1_per_hogar_total',\n",
       " 'new_v2a1_per_r4h1',\n",
       " 'new_v2a1_per_r4h2',\n",
       " 'new_v2a1_per_r4h3',\n",
       " 'new_v2a1_per_r4m1',\n",
       " 'new_v2a1_per_r4m2',\n",
       " 'new_v2a1_per_r4m3',\n",
       " 'new_v2a1_per_r4t1',\n",
       " 'new_v2a1_per_r4t2',\n",
       " 'new_v2a1_per_r4t3',\n",
       " 'new_v2a1_per_hhsize']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_train[col].fillna(0, inplace = True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_test[col].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Room per familly features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rooms'] / df_test[col]\n",
    "    \n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_train[col].fillna(0, inplace = True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_test[col].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Bedroom Per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('bedrooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['bedrooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['bedrooms'] / df_test[col]\n",
    "    \n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_train[col].fillna(0, inplace = True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace = True)\n",
    "    df_test[col].fillna(0, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 220) (23856, 219)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Tabulet per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v18q1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v18q1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v18q1'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### phone per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('qmobilephone', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['qmobilephone'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['qmobilephone'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### rez_esc(Years behind in school) per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rez_esc', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rez_esc'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rez_esc'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc_age'] = df_train['rez_esc'] / df_train['age']\n",
    "df_train['rez_esc_escolari'] = df_train['rez_esc'] / df_train['escolari']\n",
    "\n",
    "df_test['rez_esc_age'] = df_test['rez_esc'] / df_test['age']\n",
    "df_test['rez_esc_escolari'] = df_test['rez_esc'] / df_test['escolari']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Rich features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tabulet_x_qmobilephone'] = df_train['v18q1'] * df_train['qmobilephone']\n",
    "df_test['tabulet_x_qmobilephone'] = df_test['v18q1'] * df_test['qmobilephone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wall, roof, floor - > 이진 변수인데, 각각의 특성 내 값을 곱하면서 새로운 특성을 만들수 있음\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "# wall and floor\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "# roof and floor\n",
    "for col1 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        for col3 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 322) (23856, 321)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### electirictiy 와 energy features -- energy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['public', 'planpri', 'noelec', 'coopele']:\n",
    "    for col2 in ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### toilet 과 rubbish disposal features 합치기 - other_infra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "    for col2 in ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### toilet and water provision features -- water features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['abastaguadentro', 'abastaguafuera', 'abastaguano']:\n",
    "    for col2 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 383) (23856, 382)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### education + area = education_Zone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['area1', 'area2']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Mix region and Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Multiply television / mobilephone / computer / tabulet / refrigerator -> electornics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['electronics'] = df_train['computer'] * df_train['mobilephone'] * df_train['television'] * df_train['v18q'] * df_train['refrig']\n",
    "df_test['electronics'] = df_test['computer'] * df_test['mobilephone'] * df_test['television'] * df_test['v18q'] * df_test['refrig']\n",
    "\n",
    "df_train['no_appliances'] = df_train['refrig'] + df_train['computer'] + df_train['television'] + df_train['mobilephone']\n",
    "df_test['no_appliances'] = df_test['refrig'] + df_test['computer'] + df_test['television'] + df_test['mobilephone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Mix wall material of roof, floor, wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "for col1 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "    for col1 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]        \n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        for col3 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 733) (23856, 732)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Remove feature with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elimbasu5\n",
      "new_planpri_x_energcocinar1\n",
      "new_planpri_x_energcocinar2\n",
      "new_planpri_x_energcocinar3\n",
      "new_planpri_x_energcocinar4\n",
      "new_noelec_x_energcocinar2\n",
      "new_sanitario1_x_elimbasu4\n",
      "new_sanitario1_x_elimbasu5\n",
      "new_sanitario1_x_elimbasu6\n",
      "new_sanitario2_x_elimbasu4\n",
      "new_sanitario2_x_elimbasu5\n",
      "new_sanitario2_x_elimbasu6\n",
      "new_sanitario3_x_elimbasu5\n",
      "new_sanitario5_x_elimbasu4\n",
      "new_sanitario5_x_elimbasu5\n",
      "new_sanitario5_x_elimbasu6\n",
      "new_sanitario6_x_elimbasu2\n",
      "new_sanitario6_x_elimbasu4\n",
      "new_sanitario6_x_elimbasu5\n",
      "new_sanitario6_x_elimbasu6\n",
      "new_abastaguafuera_x_sanitario6\n",
      "new_abastaguano_x_sanitario2\n",
      "new_abastaguano_x_sanitario6\n",
      "new_paredblolad_x_pisonatur\n",
      "new_paredblolad_x_pisonotiene\n",
      "new_paredzocalo_x_pisoother\n",
      "new_paredzocalo_x_pisonatur\n",
      "new_paredpreb_x_pisonatur\n",
      "new_pareddes_x_pisoother\n",
      "new_pareddes_x_pisonatur\n",
      "new_paredmad_x_pisoother\n",
      "new_paredmad_x_pisonatur\n",
      "new_paredzinc_x_pisoother\n",
      "new_paredzinc_x_pisonatur\n",
      "new_paredfibras_x_pisoother\n",
      "new_paredfibras_x_pisonatur\n",
      "new_paredfibras_x_pisonotiene\n",
      "new_paredfibras_x_pisomadera\n",
      "new_paredother_x_pisoother\n",
      "new_paredother_x_pisonatur\n",
      "new_paredother_x_pisonotiene\n",
      "new_paredother_x_pisomadera\n",
      "new_techocane_x_pisomadera\n",
      "new_techootro_x_pisomadera\n",
      "new_paredzocalo_x_techoentrepiso\n",
      "new_paredzocalo_x_techocane\n",
      "new_paredzocalo_x_techootro\n",
      "new_paredpreb_x_techootro\n",
      "new_pareddes_x_techoentrepiso\n",
      "new_pareddes_x_techocane\n",
      "new_pareddes_x_techootro\n",
      "new_paredmad_x_techocane\n",
      "new_paredmad_x_techootro\n",
      "new_paredzinc_x_techoentrepiso\n",
      "new_paredzinc_x_techocane\n",
      "new_paredzinc_x_techootro\n",
      "new_paredfibras_x_techoentrepiso\n",
      "new_paredfibras_x_techootro\n",
      "new_paredother_x_techoentrepiso\n",
      "new_paredother_x_techocane\n",
      "new_paredother_x_techootro\n",
      "new_paredblolad_x_pisocemento_x_techocane\n",
      "new_paredblolad_x_pisocemento_x_techootro\n",
      "new_paredblolad_x_pisoother_x_techoentrepiso\n",
      "new_paredblolad_x_pisoother_x_techocane\n",
      "new_paredblolad_x_pisoother_x_techootro\n",
      "new_paredblolad_x_pisonatur_x_techozinc\n",
      "new_paredblolad_x_pisonatur_x_techoentrepiso\n",
      "new_paredblolad_x_pisonatur_x_techocane\n",
      "new_paredblolad_x_pisonatur_x_techootro\n",
      "new_paredblolad_x_pisonotiene_x_techozinc\n",
      "new_paredblolad_x_pisonotiene_x_techoentrepiso\n",
      "new_paredblolad_x_pisonotiene_x_techocane\n",
      "new_paredblolad_x_pisonotiene_x_techootro\n",
      "new_paredblolad_x_pisomadera_x_techocane\n",
      "new_paredblolad_x_pisomadera_x_techootro\n",
      "new_paredzocalo_x_pisomoscer_x_techoentrepiso\n",
      "new_paredzocalo_x_pisomoscer_x_techocane\n",
      "new_paredzocalo_x_pisomoscer_x_techootro\n",
      "new_paredzocalo_x_pisocemento_x_techoentrepiso\n",
      "new_paredzocalo_x_pisocemento_x_techocane\n",
      "new_paredzocalo_x_pisocemento_x_techootro\n",
      "new_paredzocalo_x_pisoother_x_techozinc\n",
      "new_paredzocalo_x_pisoother_x_techoentrepiso\n",
      "new_paredzocalo_x_pisoother_x_techocane\n",
      "new_paredzocalo_x_pisoother_x_techootro\n",
      "new_paredzocalo_x_pisonatur_x_techozinc\n",
      "new_paredzocalo_x_pisonatur_x_techoentrepiso\n",
      "new_paredzocalo_x_pisonatur_x_techocane\n",
      "new_paredzocalo_x_pisonatur_x_techootro\n",
      "new_paredzocalo_x_pisonotiene_x_techoentrepiso\n",
      "new_paredzocalo_x_pisonotiene_x_techocane\n",
      "new_paredzocalo_x_pisonotiene_x_techootro\n",
      "new_paredzocalo_x_pisomadera_x_techoentrepiso\n",
      "new_paredzocalo_x_pisomadera_x_techocane\n",
      "new_paredzocalo_x_pisomadera_x_techootro\n",
      "new_paredpreb_x_pisocemento_x_techoentrepiso\n",
      "new_paredpreb_x_pisocemento_x_techocane\n",
      "new_paredpreb_x_pisocemento_x_techootro\n",
      "new_paredpreb_x_pisoother_x_techoentrepiso\n",
      "new_paredpreb_x_pisoother_x_techocane\n",
      "new_paredpreb_x_pisoother_x_techootro\n",
      "new_paredpreb_x_pisonatur_x_techozinc\n",
      "new_paredpreb_x_pisonatur_x_techoentrepiso\n",
      "new_paredpreb_x_pisonatur_x_techocane\n",
      "new_paredpreb_x_pisonatur_x_techootro\n",
      "new_paredpreb_x_pisonotiene_x_techozinc\n",
      "new_paredpreb_x_pisonotiene_x_techoentrepiso\n",
      "new_paredpreb_x_pisonotiene_x_techocane\n",
      "new_paredpreb_x_pisonotiene_x_techootro\n",
      "new_paredpreb_x_pisomadera_x_techoentrepiso\n",
      "new_paredpreb_x_pisomadera_x_techocane\n",
      "new_paredpreb_x_pisomadera_x_techootro\n",
      "new_pareddes_x_pisomoscer_x_techozinc\n",
      "new_pareddes_x_pisomoscer_x_techoentrepiso\n",
      "new_pareddes_x_pisomoscer_x_techocane\n",
      "new_pareddes_x_pisomoscer_x_techootro\n",
      "new_pareddes_x_pisocemento_x_techoentrepiso\n",
      "new_pareddes_x_pisocemento_x_techocane\n",
      "new_pareddes_x_pisocemento_x_techootro\n",
      "new_pareddes_x_pisoother_x_techozinc\n",
      "new_pareddes_x_pisoother_x_techoentrepiso\n",
      "new_pareddes_x_pisoother_x_techocane\n",
      "new_pareddes_x_pisoother_x_techootro\n",
      "new_pareddes_x_pisonatur_x_techozinc\n",
      "new_pareddes_x_pisonatur_x_techoentrepiso\n",
      "new_pareddes_x_pisonatur_x_techocane\n",
      "new_pareddes_x_pisonatur_x_techootro\n",
      "new_pareddes_x_pisonotiene_x_techoentrepiso\n",
      "new_pareddes_x_pisonotiene_x_techocane\n",
      "new_pareddes_x_pisonotiene_x_techootro\n",
      "new_pareddes_x_pisomadera_x_techozinc\n",
      "new_pareddes_x_pisomadera_x_techoentrepiso\n",
      "new_pareddes_x_pisomadera_x_techocane\n",
      "new_pareddes_x_pisomadera_x_techootro\n",
      "new_paredmad_x_pisomoscer_x_techocane\n",
      "new_paredmad_x_pisomoscer_x_techootro\n",
      "new_paredmad_x_pisocemento_x_techoentrepiso\n",
      "new_paredmad_x_pisocemento_x_techocane\n",
      "new_paredmad_x_pisocemento_x_techootro\n",
      "new_paredmad_x_pisoother_x_techozinc\n",
      "new_paredmad_x_pisoother_x_techoentrepiso\n",
      "new_paredmad_x_pisoother_x_techocane\n",
      "new_paredmad_x_pisoother_x_techootro\n",
      "new_paredmad_x_pisonatur_x_techozinc\n",
      "new_paredmad_x_pisonatur_x_techoentrepiso\n",
      "new_paredmad_x_pisonatur_x_techocane\n",
      "new_paredmad_x_pisonatur_x_techootro\n",
      "new_paredmad_x_pisonotiene_x_techoentrepiso\n",
      "new_paredmad_x_pisonotiene_x_techocane\n",
      "new_paredmad_x_pisonotiene_x_techootro\n",
      "new_paredmad_x_pisomadera_x_techocane\n",
      "new_paredzinc_x_pisomoscer_x_techoentrepiso\n",
      "new_paredzinc_x_pisomoscer_x_techocane\n",
      "new_paredzinc_x_pisomoscer_x_techootro\n",
      "new_paredzinc_x_pisocemento_x_techoentrepiso\n",
      "new_paredzinc_x_pisocemento_x_techocane\n",
      "new_paredzinc_x_pisocemento_x_techootro\n",
      "new_paredzinc_x_pisoother_x_techozinc\n",
      "new_paredzinc_x_pisoother_x_techoentrepiso\n",
      "new_paredzinc_x_pisoother_x_techocane\n",
      "new_paredzinc_x_pisoother_x_techootro\n",
      "new_paredzinc_x_pisonatur_x_techozinc\n",
      "new_paredzinc_x_pisonatur_x_techoentrepiso\n",
      "new_paredzinc_x_pisonatur_x_techocane\n",
      "new_paredzinc_x_pisonatur_x_techootro\n",
      "new_paredzinc_x_pisonotiene_x_techoentrepiso\n",
      "new_paredzinc_x_pisonotiene_x_techocane\n",
      "new_paredzinc_x_pisonotiene_x_techootro\n",
      "new_paredzinc_x_pisomadera_x_techoentrepiso\n",
      "new_paredzinc_x_pisomadera_x_techocane\n",
      "new_paredzinc_x_pisomadera_x_techootro\n",
      "new_paredfibras_x_pisomoscer_x_techoentrepiso\n",
      "new_paredfibras_x_pisomoscer_x_techocane\n",
      "new_paredfibras_x_pisomoscer_x_techootro\n",
      "new_paredfibras_x_pisocemento_x_techoentrepiso\n",
      "new_paredfibras_x_pisocemento_x_techocane\n",
      "new_paredfibras_x_pisocemento_x_techootro\n",
      "new_paredfibras_x_pisoother_x_techozinc\n",
      "new_paredfibras_x_pisoother_x_techoentrepiso\n",
      "new_paredfibras_x_pisoother_x_techocane\n",
      "new_paredfibras_x_pisoother_x_techootro\n",
      "new_paredfibras_x_pisonatur_x_techozinc\n",
      "new_paredfibras_x_pisonatur_x_techoentrepiso\n",
      "new_paredfibras_x_pisonatur_x_techocane\n",
      "new_paredfibras_x_pisonatur_x_techootro\n",
      "new_paredfibras_x_pisonotiene_x_techozinc\n",
      "new_paredfibras_x_pisonotiene_x_techoentrepiso\n",
      "new_paredfibras_x_pisonotiene_x_techocane\n",
      "new_paredfibras_x_pisonotiene_x_techootro\n",
      "new_paredfibras_x_pisomadera_x_techozinc\n",
      "new_paredfibras_x_pisomadera_x_techoentrepiso\n",
      "new_paredfibras_x_pisomadera_x_techocane\n",
      "new_paredfibras_x_pisomadera_x_techootro\n",
      "new_paredother_x_pisomoscer_x_techozinc\n",
      "new_paredother_x_pisomoscer_x_techoentrepiso\n",
      "new_paredother_x_pisomoscer_x_techocane\n",
      "new_paredother_x_pisomoscer_x_techootro\n",
      "new_paredother_x_pisocemento_x_techoentrepiso\n",
      "new_paredother_x_pisocemento_x_techocane\n",
      "new_paredother_x_pisocemento_x_techootro\n",
      "new_paredother_x_pisoother_x_techozinc\n",
      "new_paredother_x_pisoother_x_techoentrepiso\n",
      "new_paredother_x_pisoother_x_techocane\n",
      "new_paredother_x_pisoother_x_techootro\n",
      "new_paredother_x_pisonatur_x_techozinc\n",
      "new_paredother_x_pisonatur_x_techoentrepiso\n",
      "new_paredother_x_pisonatur_x_techocane\n",
      "new_paredother_x_pisonatur_x_techootro\n",
      "new_paredother_x_pisonotiene_x_techozinc\n",
      "new_paredother_x_pisonotiene_x_techoentrepiso\n",
      "new_paredother_x_pisonotiene_x_techocane\n",
      "new_paredother_x_pisonotiene_x_techootro\n",
      "new_paredother_x_pisomadera_x_techozinc\n",
      "new_paredother_x_pisomadera_x_techoentrepiso\n",
      "new_paredother_x_pisomadera_x_techocane\n",
      "new_paredother_x_pisomadera_x_techootro\n"
     ]
    }
   ],
   "source": [
    "cols_with_only_one_value = []\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if col == 'Target':\n",
    "        continue\n",
    "    if df_train[col].value_counts().shape[0] == 1 or df_test[col].value_counts().shape[0] == 1:\n",
    "        print(col)\n",
    "        cols_with_only_one_value.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(cols_with_only_one_value, axis = 1, inplace = True)\n",
    "df_test.drop(cols_with_only_one_value, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['v2a1'].value_counts().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Check whether both train and test have same features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_train = np.array(sorted([col for col in df_train.columns if col != 'Target']))\n",
    "\n",
    "cols_test = np.array(sorted(df_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cols_train == cols_test).sum() == len(cols_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.4 aggregation features\n",
    "\n",
    "\n",
    "#### Aggregation for family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min(x):\n",
    "    return x.max() - x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:18<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows and 105 features\n",
      "new aggreagte test set has 7352 rows and 105 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agg_train = pd.DataFrame()\n",
    "agg_test = pd.DataFrame()\n",
    "\n",
    "for item in tqdm(family_size_features):\n",
    "    for i, function in enumerate(['mean', 'std', 'min', 'max', 'sum', 'count', max_min]):\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "        \n",
    "print('new aggregate train set has {} rows and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggreagte test set has {} rows and {} features'.format(agg_test.shape[0], agg_test.shape[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 15051.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult\n",
      "hogar_adul\n",
      "hogar_mayor\n",
      "hogar_nin\n",
      "hogar_total\n",
      "r4h1\n",
      "r4h2\n",
      "r4h3\n",
      "r4m1\n",
      "r4m2\n",
      "r4m3\n",
      "r4t1\n",
      "r4t2\n",
      "r4t3\n",
      "hhsize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(family_size_features):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:01<00:00, 44.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 199 features\n",
      "new aggregate test set has 7352 rows, and 199 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "\n",
    "\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['count', 'sum']:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        new_col = item + '_new1_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 208 features\n",
      "new aggregate test set has 7352 rows, and 208 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['escolari', 'age', 'escolari_age', 'dependency', 'bedrooms', 'overcrowding', 'rooms', 'qmobilephone', 'v18q1']\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['mean','std','min','max','sum', 'count', max_min]:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new2_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new2_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (9557, 724) test shape:  (23856, 723)\n"
     ]
    }
   ],
   "source": [
    "agg_test = agg_test.reset_index()\n",
    "agg_train = agg_train.reset_index()\n",
    "\n",
    "train_agg = pd.merge(df_train, agg_train, on = 'idhogar')\n",
    "test = pd.merge(df_test, agg_test, on = 'idhogar')\n",
    "\n",
    "train_agg.fillna(value = 0, inplace = True)\n",
    "test.fillna(value = 0, inplace = True)\n",
    "\n",
    "print('train shape: ', train_agg.shape, 'test shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 1006) test shape: (23856, 1005)\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "    \n",
    "for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_train.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n",
    "\n",
    "    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_test.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n",
    "\n",
    "    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "    \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [05:51<00:00, 50.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 2980) test shape: (23856, 2979)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "for function in tqdm(['mean','std','min','max','sum', 'count', max_min]):\n",
    "    for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "        group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_train.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_train][2:]\n",
    "\n",
    "        group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_test.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_test][2:]\n",
    "\n",
    "        train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "        test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "        \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_agg.query('parentesco1==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>new5_lugar6_idhogar_eviv1_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_eviv2_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_eviv3_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_refrig_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_television_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_mobilephone_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_area1_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_area2_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_v18q_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "      <th>new5_lugar6_idhogar_edjef_&lt;function max_min at 0x000002DA69EE12F0&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_ec05b1a7b</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID_1284f8aad</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2980 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    0.0   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       0.0       0      8       0     1       1     0    0.0   \n",
       "5  ID_ec05b1a7b  180000.0       0      5       0     1       1     1    1.0   \n",
       "8  ID_1284f8aad  130000.0       1      2       0     1       1     0    0.0   \n",
       "\n",
       "   r4h1  ...  \\\n",
       "0     0  ...   \n",
       "1     0  ...   \n",
       "2     0  ...   \n",
       "5     0  ...   \n",
       "8     0  ...   \n",
       "\n",
       "   new5_lugar6_idhogar_eviv1_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_eviv2_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_eviv3_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_refrig_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                     \n",
       "1                                                  0                     \n",
       "2                                                  0                     \n",
       "5                                                  0                     \n",
       "8                                                  0                     \n",
       "\n",
       "   new5_lugar6_idhogar_television_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                         \n",
       "1                                                  0                         \n",
       "2                                                  0                         \n",
       "5                                                  0                         \n",
       "8                                                  0                         \n",
       "\n",
       "   new5_lugar6_idhogar_mobilephone_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "2                                                  0                          \n",
       "5                                                  0                          \n",
       "8                                                  0                          \n",
       "\n",
       "   new5_lugar6_idhogar_area1_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_area2_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "8                                                  0                    \n",
       "\n",
       "   new5_lugar6_idhogar_v18q_<function max_min at 0x000002DA69EE12F0>  \\\n",
       "0                                                  0                   \n",
       "1                                                  0                   \n",
       "2                                                  0                   \n",
       "5                                                  0                   \n",
       "8                                                  0                   \n",
       "\n",
       "   new5_lugar6_idhogar_edjef_<function max_min at 0x000002DA69EE12F0>  \n",
       "0                                                0.0                   \n",
       "1                                                0.0                   \n",
       "2                                                0.0                   \n",
       "5                                                0.0                   \n",
       "8                                                0.0                   \n",
       "\n",
       "[5 rows x 2980 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dependency'].replace(np.inf, 0 , inplace = True)\n",
    "test['dependency'].replace(np.inf, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['Id']]\n",
    "\n",
    "#Remove useless feature to reduce dimension\n",
    "train.drop(columns=['idhogar','Id', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "test.drop(columns=['idhogar','Id',  'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "\n",
    "correlation = train.corr()\n",
    "correlation = correlation['Target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_data size (2973, 2968) (23856, 2967)\n"
     ]
    }
   ],
   "source": [
    "print('final_data size', train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 positive feature: \n",
      "Target                                1.000000\n",
      "new5_lugar3_idhogar_edjef_max         0.334254\n",
      "new5_lugar5_idhogar_edjef_max         0.334254\n",
      "new5_lugar2_idhogar_edjef_max         0.334254\n",
      "new5_lugar1_idhogar_edjef_max         0.334254\n",
      "new5_lugar4_idhogar_edjef_max         0.334254\n",
      "new5_lugar6_idhogar_edjef_max         0.334254\n",
      "new5_lugar3_idhogar_edjef_mean        0.333873\n",
      "new5_lugar1_idhogar_edjef_mean        0.333873\n",
      "new5_lugar6_idhogar_edjef_mean        0.333873\n",
      "new5_lugar2_idhogar_edjef_mean        0.333873\n",
      "new5_lugar4_idhogar_edjef_mean        0.333873\n",
      "new5_lugar5_idhogar_edjef_mean        0.333873\n",
      "escolari                              0.333791\n",
      "new5_lugar1_idhogar_edjef_min         0.333791\n",
      "new5_lugar5_idhogar_edjef_min         0.333791\n",
      "new5_lugar2_idhogar_edjef_min         0.333791\n",
      "new5_lugar4_idhogar_edjef_min         0.333791\n",
      "new5_lugar6_idhogar_edjef_min         0.333791\n",
      "new5_lugar3_idhogar_edjef_min         0.333791\n",
      "edjef                                 0.333791\n",
      "meaneduc                              0.331489\n",
      "new5_lugar3_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar6_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar4_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar1_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar2_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar5_idhogar_instlevel8_max    0.317815\n",
      "phones-per-capita                     0.299026\n",
      "new5_lugar5_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar2_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar1_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar4_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar3_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar6_idhogar_instlevel8_std    0.298251\n",
      "new_epared3_x_eviv3                   0.298196\n",
      "cielorazo                             0.295249\n",
      "instlevel8_new1_sum                   0.294277\n",
      "new3_lugar3_idhogar_instlevel8        0.294277\n",
      "new3_lugar5_idhogar_instlevel8        0.294277\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The most 20 positive feature: \\n{correlation.head(40)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 negative feature: \n",
      "new5_lugar3_idhogar_instlevel1_sum   -0.271204\n",
      "new3_lugar4_idhogar_instlevel1       -0.271204\n",
      "new5_lugar2_idhogar_instlevel1_sum   -0.271204\n",
      "new5_lugar6_idhogar_instlevel1_sum   -0.271204\n",
      "new3_lugar1_idhogar_instlevel1       -0.271204\n",
      "dependency_count                     -0.283908\n",
      "new5_lugar6_idhogar_instlevel2_sum   -0.297868\n",
      "new3_lugar6_idhogar_instlevel2       -0.297868\n",
      "new5_lugar5_idhogar_instlevel2_sum   -0.297868\n",
      "instlevel2_new1_sum                  -0.297868\n",
      "new5_lugar4_idhogar_instlevel2_sum   -0.297868\n",
      "new3_lugar1_idhogar_instlevel2       -0.297868\n",
      "new5_lugar3_idhogar_instlevel2_sum   -0.297868\n",
      "new3_lugar2_idhogar_instlevel2       -0.297868\n",
      "new5_lugar2_idhogar_instlevel2_sum   -0.297868\n",
      "new3_lugar4_idhogar_instlevel2       -0.297868\n",
      "new5_lugar1_idhogar_instlevel2_sum   -0.297868\n",
      "new3_lugar3_idhogar_instlevel2       -0.297868\n",
      "new3_lugar5_idhogar_instlevel2       -0.297868\n",
      "dependency                           -0.304563\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The most 20 negative feature: \\n{correlation.dropna().tail(20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4. Feature selection using shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in train.columns if train[col].value_counts().shape[0] == 2]\n",
    "\n",
    "object_features = ['edjefe', 'edjefa']\n",
    "\n",
    "categorical_feats = binary_cat_features + object_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(truth, predictions):\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)), -1).argmax(axis = 0)\n",
    "    f1 = f1_score(truth, pred_labels, average = 'macro')\n",
    "    return ('macroF1', f1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Target']\n",
    "train.drop(columns = ['Target'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_execution_time(start):\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"*\"*20, 'Execution ended in {:0>2}h {:0>2}hm {:05.2f}s'.format(int(hours), int(minutes), seconds), \"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_good_features_using_shap_LGB(params, SEED):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 5\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb, categorical_feature=categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        print_execution_time(start)\n",
    "\n",
    "    feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "\n",
    "    return feat_importance_df_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 1 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07899\ttraining's macroF1: 0.503939\tvalid_1's multi_logloss: 1.0645\tvalid_1's macroF1: 0.382898\n",
      "[1000]\ttraining's multi_logloss: 0.994047\ttraining's macroF1: 0.544153\tvalid_1's multi_logloss: 1.04278\tvalid_1's macroF1: 0.396418\n",
      "[1500]\ttraining's multi_logloss: 0.937831\ttraining's macroF1: 0.58102\tvalid_1's multi_logloss: 1.03557\tvalid_1's macroF1: 0.393298\n",
      "[2000]\ttraining's multi_logloss: 0.894624\ttraining's macroF1: 0.610233\tvalid_1's multi_logloss: 1.03424\tvalid_1's macroF1: 0.407753\n",
      "Early stopping, best iteration is:\n",
      "[1833]\ttraining's multi_logloss: 0.908185\ttraining's macroF1: 0.600549\tvalid_1's multi_logloss: 1.03479\tvalid_1's macroF1: 0.408648\n",
      "******************** Execution ended in 00h 01hm 00.73s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07954\ttraining's macroF1: 0.509991\tvalid_1's multi_logloss: 1.05905\tvalid_1's macroF1: 0.411721\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's multi_logloss: 1.19862\ttraining's macroF1: 0.465958\tvalid_1's multi_logloss: 1.14223\tvalid_1's macroF1: 0.414992\n",
      "******************** Execution ended in 00h 00hm 19.48s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07786\ttraining's macroF1: 0.511689\tvalid_1's multi_logloss: 1.08878\tvalid_1's macroF1: 0.401525\n",
      "[1000]\ttraining's multi_logloss: 0.991524\ttraining's macroF1: 0.561973\tvalid_1's multi_logloss: 1.07008\tvalid_1's macroF1: 0.423861\n",
      "Early stopping, best iteration is:\n",
      "[825]\ttraining's multi_logloss: 1.0163\ttraining's macroF1: 0.546702\tvalid_1's multi_logloss: 1.07281\tvalid_1's macroF1: 0.428764\n",
      "******************** Execution ended in 00h 00hm 38.98s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.06414\ttraining's macroF1: 0.516195\tvalid_1's multi_logloss: 1.09637\tvalid_1's macroF1: 0.388313\n",
      "Early stopping, best iteration is:\n",
      "[427]\ttraining's multi_logloss: 1.08321\ttraining's macroF1: 0.508255\tvalid_1's multi_logloss: 1.10194\tvalid_1's macroF1: 0.396375\n",
      "******************** Execution ended in 00h 00hm 25.20s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07504\ttraining's macroF1: 0.515227\tvalid_1's multi_logloss: 1.0854\tvalid_1's macroF1: 0.384004\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's multi_logloss: 1.12052\ttraining's macroF1: 0.494024\tvalid_1's multi_logloss: 1.10367\tvalid_1's macroF1: 0.396059\n",
      "******************** Execution ended in 00h 00hm 23.11s ********************\n",
      "######################################## 2 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.651123\ttraining's macroF1: 0.773269\tvalid_1's multi_logloss: 0.957428\tvalid_1's macroF1: 0.424247\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's multi_logloss: 1.15179\ttraining's macroF1: 0.609661\tvalid_1's multi_logloss: 1.15335\tvalid_1's macroF1: 0.442182\n",
      "******************** Execution ended in 00h 00hm 21.34s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.659168\ttraining's macroF1: 0.77738\tvalid_1's multi_logloss: 0.971732\tvalid_1's macroF1: 0.415012\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's multi_logloss: 1.18218\ttraining's macroF1: 0.605849\tvalid_1's multi_logloss: 1.18543\tvalid_1's macroF1: 0.448341\n",
      "******************** Execution ended in 00h 00hm 18.22s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.654847\ttraining's macroF1: 0.775847\tvalid_1's multi_logloss: 0.963735\tvalid_1's macroF1: 0.402341\n",
      "Early stopping, best iteration is:\n",
      "[366]\ttraining's multi_logloss: 0.743496\ttraining's macroF1: 0.740966\tvalid_1's multi_logloss: 0.977125\tvalid_1's macroF1: 0.423244\n",
      "******************** Execution ended in 00h 00hm 29.17s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.654177\ttraining's macroF1: 0.765484\tvalid_1's multi_logloss: 0.997515\tvalid_1's macroF1: 0.416686\n",
      "[1000]\ttraining's multi_logloss: 0.474649\ttraining's macroF1: 0.83399\tvalid_1's multi_logloss: 0.982747\tvalid_1's macroF1: 0.411973\n",
      "Early stopping, best iteration is:\n",
      "[729]\ttraining's multi_logloss: 0.55324\ttraining's macroF1: 0.80084\tvalid_1's multi_logloss: 0.984465\tvalid_1's macroF1: 0.429346\n",
      "******************** Execution ended in 00h 00hm 44.25s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.643886\ttraining's macroF1: 0.774821\tvalid_1's multi_logloss: 1.06866\tvalid_1's macroF1: 0.391911\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttraining's multi_logloss: 0.715633\ttraining's macroF1: 0.749578\tvalid_1's multi_logloss: 1.07352\tvalid_1's macroF1: 0.410716\n",
      "******************** Execution ended in 00h 00hm 31.17s ********************\n",
      "######################################## 3 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.943937\ttraining's macroF1: 0.61877\tvalid_1's multi_logloss: 1.03597\tvalid_1's macroF1: 0.40169\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's multi_logloss: 1.38201\ttraining's macroF1: 0.46624\tvalid_1's multi_logloss: 1.38076\tvalid_1's macroF1: 0.421964\n",
      "******************** Execution ended in 00h 00hm 19.32s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.935306\ttraining's macroF1: 0.614466\tvalid_1's multi_logloss: 1.03574\tvalid_1's macroF1: 0.365812\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's multi_logloss: 1.08891\ttraining's macroF1: 0.556343\tvalid_1's multi_logloss: 1.10786\tvalid_1's macroF1: 0.387975\n",
      "******************** Execution ended in 00h 00hm 29.07s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.937077\ttraining's macroF1: 0.615761\tvalid_1's multi_logloss: 1.06727\tvalid_1's macroF1: 0.394022\n",
      "Early stopping, best iteration is:\n",
      "[357]\ttraining's multi_logloss: 1.00747\ttraining's macroF1: 0.594191\tvalid_1's multi_logloss: 1.08854\tvalid_1's macroF1: 0.41744\n",
      "******************** Execution ended in 00h 00hm 32.50s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.935125\ttraining's macroF1: 0.617716\tvalid_1's multi_logloss: 1.08599\tvalid_1's macroF1: 0.391217\n",
      "[1000]\ttraining's multi_logloss: 0.781305\ttraining's macroF1: 0.689733\tvalid_1's multi_logloss: 1.06243\tvalid_1's macroF1: 0.40473\n",
      "[1500]\ttraining's multi_logloss: 0.684667\ttraining's macroF1: 0.734824\tvalid_1's multi_logloss: 1.04983\tvalid_1's macroF1: 0.397726\n",
      "Early stopping, best iteration is:\n",
      "[1229]\ttraining's multi_logloss: 0.732627\ttraining's macroF1: 0.713677\tvalid_1's multi_logloss: 1.05587\tvalid_1's macroF1: 0.409895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Execution ended in 00h 01hm 00.76s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.947881\ttraining's macroF1: 0.623347\tvalid_1's multi_logloss: 1.01718\tvalid_1's macroF1: 0.417192\n",
      "[1000]\ttraining's multi_logloss: 0.78962\ttraining's macroF1: 0.703344\tvalid_1's multi_logloss: 0.977984\tvalid_1's macroF1: 0.430026\n",
      "Early stopping, best iteration is:\n",
      "[830]\ttraining's multi_logloss: 0.833869\ttraining's macroF1: 0.684499\tvalid_1's multi_logloss: 0.985401\tvalid_1's macroF1: 0.443014\n",
      "******************** Execution ended in 00h 00hm 58.95s ********************\n",
      "######################################## 4 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00208\ttraining's macroF1: 0.555763\tvalid_1's multi_logloss: 1.10277\tvalid_1's macroF1: 0.372613\n",
      "[1000]\ttraining's multi_logloss: 0.89603\ttraining's macroF1: 0.610588\tvalid_1's multi_logloss: 1.10003\tvalid_1's macroF1: 0.382387\n",
      "Early stopping, best iteration is:\n",
      "[854]\ttraining's multi_logloss: 0.921441\ttraining's macroF1: 0.595274\tvalid_1's multi_logloss: 1.09871\tvalid_1's macroF1: 0.388518\n",
      "******************** Execution ended in 00h 00hm 29.08s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01925\ttraining's macroF1: 0.560963\tvalid_1's multi_logloss: 1.05226\tvalid_1's macroF1: 0.4412\n",
      "Early stopping, best iteration is:\n",
      "[442]\ttraining's multi_logloss: 1.03725\ttraining's macroF1: 0.554009\tvalid_1's multi_logloss: 1.05557\tvalid_1's macroF1: 0.453379\n",
      "******************** Execution ended in 00h 00hm 20.88s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01289\ttraining's macroF1: 0.550396\tvalid_1's multi_logloss: 1.04107\tvalid_1's macroF1: 0.402019\n",
      "Early stopping, best iteration is:\n",
      "[377]\ttraining's multi_logloss: 1.05205\ttraining's macroF1: 0.544041\tvalid_1's multi_logloss: 1.05483\tvalid_1's macroF1: 0.404674\n",
      "******************** Execution ended in 00h 00hm 18.00s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02787\ttraining's macroF1: 0.555526\tvalid_1's multi_logloss: 1.00475\tvalid_1's macroF1: 0.433534\n",
      "Early stopping, best iteration is:\n",
      "[457]\ttraining's multi_logloss: 1.04051\ttraining's macroF1: 0.54755\tvalid_1's multi_logloss: 1.01026\tvalid_1's macroF1: 0.443678\n",
      "******************** Execution ended in 00h 00hm 21.26s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.013\ttraining's macroF1: 0.549347\tvalid_1's multi_logloss: 1.07148\tvalid_1's macroF1: 0.397018\n",
      "[1000]\ttraining's multi_logloss: 0.909579\ttraining's macroF1: 0.602522\tvalid_1's multi_logloss: 1.05306\tvalid_1's macroF1: 0.401878\n",
      "[1500]\ttraining's multi_logloss: 0.841431\ttraining's macroF1: 0.641923\tvalid_1's multi_logloss: 1.04853\tvalid_1's macroF1: 0.410841\n",
      "[2000]\ttraining's multi_logloss: 0.78932\ttraining's macroF1: 0.663101\tvalid_1's multi_logloss: 1.04463\tvalid_1's macroF1: 0.412211\n",
      "Early stopping, best iteration is:\n",
      "[1700]\ttraining's multi_logloss: 0.818927\ttraining's macroF1: 0.64844\tvalid_1's multi_logloss: 1.04747\tvalid_1's macroF1: 0.418836\n",
      "******************** Execution ended in 00h 00hm 45.80s ********************\n",
      "######################################## 5 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.85599\ttraining's macroF1: 0.649233\tvalid_1's multi_logloss: 1.02125\tvalid_1's macroF1: 0.398104\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's multi_logloss: 1.36231\ttraining's macroF1: 0.470994\tvalid_1's multi_logloss: 1.3578\tvalid_1's macroF1: 0.410246\n",
      "******************** Execution ended in 00h 00hm 14.13s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.861026\ttraining's macroF1: 0.65679\tvalid_1's multi_logloss: 1.01189\tvalid_1's macroF1: 0.429312\n",
      "[1000]\ttraining's multi_logloss: 0.697223\ttraining's macroF1: 0.731226\tvalid_1's multi_logloss: 0.997146\tvalid_1's macroF1: 0.423675\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttraining's multi_logloss: 0.808392\ttraining's macroF1: 0.684051\tvalid_1's multi_logloss: 1.00418\tvalid_1's macroF1: 0.450558\n",
      "******************** Execution ended in 00h 00hm 31.77s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.840684\ttraining's macroF1: 0.67399\tvalid_1's multi_logloss: 1.05803\tvalid_1's macroF1: 0.382035\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's multi_logloss: 1.18109\ttraining's macroF1: 0.543833\tvalid_1's multi_logloss: 1.18385\tvalid_1's macroF1: 0.391748\n",
      "******************** Execution ended in 00h 00hm 15.62s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.855045\ttraining's macroF1: 0.666717\tvalid_1's multi_logloss: 0.9933\tvalid_1's macroF1: 0.421932\n",
      "[1000]\ttraining's multi_logloss: 0.691424\ttraining's macroF1: 0.739415\tvalid_1's multi_logloss: 0.986283\tvalid_1's macroF1: 0.434689\n",
      "Early stopping, best iteration is:\n",
      "[797]\ttraining's multi_logloss: 0.746405\ttraining's macroF1: 0.714077\tvalid_1's multi_logloss: 0.9852\tvalid_1's macroF1: 0.435911\n",
      "******************** Execution ended in 00h 00hm 32.93s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.859313\ttraining's macroF1: 0.671499\tvalid_1's multi_logloss: 0.99912\tvalid_1's macroF1: 0.452378\n",
      "[1000]\ttraining's multi_logloss: 0.694448\ttraining's macroF1: 0.741009\tvalid_1's multi_logloss: 0.976031\tvalid_1's macroF1: 0.454118\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's multi_logloss: 0.803497\ttraining's macroF1: 0.689011\tvalid_1's multi_logloss: 0.989238\tvalid_1's macroF1: 0.473956\n",
      "******************** Execution ended in 00h 00hm 30.83s ********************\n",
      "######################################## 6 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.805588\ttraining's macroF1: 0.707564\tvalid_1's multi_logloss: 1.01166\tvalid_1's macroF1: 0.437811\n",
      "[1000]\ttraining's multi_logloss: 0.626407\ttraining's macroF1: 0.770484\tvalid_1's multi_logloss: 0.992394\tvalid_1's macroF1: 0.425313\n",
      "Early stopping, best iteration is:\n",
      "[501]\ttraining's multi_logloss: 0.805067\ttraining's macroF1: 0.70873\tvalid_1's multi_logloss: 1.01148\tvalid_1's macroF1: 0.440541\n",
      "******************** Execution ended in 00h 00hm 31.66s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.80374\ttraining's macroF1: 0.696721\tvalid_1's multi_logloss: 1.00456\tvalid_1's macroF1: 0.426554\n",
      "[1000]\ttraining's multi_logloss: 0.624617\ttraining's macroF1: 0.778739\tvalid_1's multi_logloss: 0.977592\tvalid_1's macroF1: 0.426433\n",
      "Early stopping, best iteration is:\n",
      "[866]\ttraining's multi_logloss: 0.661958\ttraining's macroF1: 0.756831\tvalid_1's multi_logloss: 0.983332\tvalid_1's macroF1: 0.443189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Execution ended in 00h 00hm 48.84s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.800842\ttraining's macroF1: 0.689163\tvalid_1's multi_logloss: 1.02861\tvalid_1's macroF1: 0.401077\n",
      "[1000]\ttraining's multi_logloss: 0.623874\ttraining's macroF1: 0.764185\tvalid_1's multi_logloss: 1.00953\tvalid_1's macroF1: 0.412829\n",
      "[1500]\ttraining's multi_logloss: 0.52281\ttraining's macroF1: 0.808325\tvalid_1's multi_logloss: 0.999553\tvalid_1's macroF1: 0.41717\n",
      "Early stopping, best iteration is:\n",
      "[1236]\ttraining's multi_logloss: 0.570359\ttraining's macroF1: 0.789664\tvalid_1's multi_logloss: 1.00318\tvalid_1's macroF1: 0.425171\n",
      "******************** Execution ended in 00h 01hm 00.08s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.79441\ttraining's macroF1: 0.692349\tvalid_1's multi_logloss: 1.03337\tvalid_1's macroF1: 0.371124\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's multi_logloss: 1.37599\ttraining's macroF1: 0.469904\tvalid_1's multi_logloss: 1.37439\tvalid_1's macroF1: 0.39091\n",
      "******************** Execution ended in 00h 00hm 18.49s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.804349\ttraining's macroF1: 0.698342\tvalid_1's multi_logloss: 1.00904\tvalid_1's macroF1: 0.419358\n",
      "Early stopping, best iteration is:\n",
      "[372]\ttraining's multi_logloss: 0.877187\ttraining's macroF1: 0.665164\tvalid_1's multi_logloss: 1.02013\tvalid_1's macroF1: 0.442081\n",
      "******************** Execution ended in 00h 00hm 31.35s ********************\n",
      "######################################## 7 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.969685\ttraining's macroF1: 0.577402\tvalid_1's multi_logloss: 1.05667\tvalid_1's macroF1: 0.386817\n",
      "[1000]\ttraining's multi_logloss: 0.855381\ttraining's macroF1: 0.635244\tvalid_1's multi_logloss: 1.05449\tvalid_1's macroF1: 0.390237\n",
      "Early stopping, best iteration is:\n",
      "[572]\ttraining's multi_logloss: 0.948505\ttraining's macroF1: 0.585993\tvalid_1's multi_logloss: 1.05528\tvalid_1's macroF1: 0.401253\n",
      "******************** Execution ended in 00h 00hm 27.67s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.983429\ttraining's macroF1: 0.572614\tvalid_1's multi_logloss: 1.07168\tvalid_1's macroF1: 0.413289\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's multi_logloss: 1.18284\ttraining's macroF1: 0.496806\tvalid_1's multi_logloss: 1.17136\tvalid_1's macroF1: 0.440528\n",
      "******************** Execution ended in 00h 00hm 17.40s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.981376\ttraining's macroF1: 0.570258\tvalid_1's multi_logloss: 0.996004\tvalid_1's macroF1: 0.425165\n",
      "[1000]\ttraining's multi_logloss: 0.865556\ttraining's macroF1: 0.627886\tvalid_1's multi_logloss: 0.976977\tvalid_1's macroF1: 0.442176\n",
      "[1500]\ttraining's multi_logloss: 0.787391\ttraining's macroF1: 0.667279\tvalid_1's multi_logloss: 0.971113\tvalid_1's macroF1: 0.45168\n",
      "[2000]\ttraining's multi_logloss: 0.728458\ttraining's macroF1: 0.699522\tvalid_1's multi_logloss: 0.967566\tvalid_1's macroF1: 0.445311\n",
      "Early stopping, best iteration is:\n",
      "[1520]\ttraining's multi_logloss: 0.784632\ttraining's macroF1: 0.667045\tvalid_1's multi_logloss: 0.971314\tvalid_1's macroF1: 0.454721\n",
      "******************** Execution ended in 00h 00hm 50.29s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.977331\ttraining's macroF1: 0.569737\tvalid_1's multi_logloss: 1.03981\tvalid_1's macroF1: 0.456437\n",
      "[1000]\ttraining's multi_logloss: 0.865652\ttraining's macroF1: 0.622523\tvalid_1's multi_logloss: 1.02675\tvalid_1's macroF1: 0.44123\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttraining's multi_logloss: 0.969237\ttraining's macroF1: 0.574277\tvalid_1's multi_logloss: 1.03879\tvalid_1's macroF1: 0.458814\n",
      "******************** Execution ended in 00h 00hm 26.21s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.975946\ttraining's macroF1: 0.577678\tvalid_1's multi_logloss: 1.05907\tvalid_1's macroF1: 0.388899\n",
      "[1000]\ttraining's multi_logloss: 0.855899\ttraining's macroF1: 0.638324\tvalid_1's multi_logloss: 1.04417\tvalid_1's macroF1: 0.38643\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's multi_logloss: 0.919821\ttraining's macroF1: 0.606678\tvalid_1's multi_logloss: 1.04983\tvalid_1's macroF1: 0.396292\n",
      "******************** Execution ended in 00h 00hm 29.88s ********************\n",
      "######################################## 8 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.882207\ttraining's macroF1: 0.650116\tvalid_1's multi_logloss: 1.00675\tvalid_1's macroF1: 0.434423\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's multi_logloss: 0.984524\ttraining's macroF1: 0.609788\tvalid_1's multi_logloss: 1.03681\tvalid_1's macroF1: 0.454913\n",
      "******************** Execution ended in 00h 00hm 27.54s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.875942\ttraining's macroF1: 0.65608\tvalid_1's multi_logloss: 1.03663\tvalid_1's macroF1: 0.420524\n",
      "[1000]\ttraining's multi_logloss: 0.706789\ttraining's macroF1: 0.732442\tvalid_1's multi_logloss: 1.0209\tvalid_1's macroF1: 0.44024\n",
      "Early stopping, best iteration is:\n",
      "[985]\ttraining's multi_logloss: 0.710572\ttraining's macroF1: 0.731683\tvalid_1's multi_logloss: 1.02047\tvalid_1's macroF1: 0.44747\n",
      "******************** Execution ended in 00h 00hm 45.72s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.874282\ttraining's macroF1: 0.646324\tvalid_1's multi_logloss: 1.02359\tvalid_1's macroF1: 0.401762\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's multi_logloss: 1.36639\ttraining's macroF1: 0.506853\tvalid_1's multi_logloss: 1.36407\tvalid_1's macroF1: 0.408538\n",
      "******************** Execution ended in 00h 00hm 16.28s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.882234\ttraining's macroF1: 0.653547\tvalid_1's multi_logloss: 1.00521\tvalid_1's macroF1: 0.396857\n",
      "[1000]\ttraining's multi_logloss: 0.715221\ttraining's macroF1: 0.72945\tvalid_1's multi_logloss: 0.989914\tvalid_1's macroF1: 0.409703\n",
      "Early stopping, best iteration is:\n",
      "[947]\ttraining's multi_logloss: 0.72939\ttraining's macroF1: 0.721188\tvalid_1's multi_logloss: 0.990778\tvalid_1's macroF1: 0.418782\n",
      "******************** Execution ended in 00h 00hm 44.51s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.874985\ttraining's macroF1: 0.645937\tvalid_1's multi_logloss: 1.0519\tvalid_1's macroF1: 0.414193\n",
      "Early stopping, best iteration is:\n",
      "[204]\ttraining's multi_logloss: 1.05703\ttraining's macroF1: 0.583709\tvalid_1's multi_logloss: 1.10781\tvalid_1's macroF1: 0.431654\n",
      "******************** Execution ended in 00h 00hm 24.18s ********************\n",
      "######################################## 9 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.907874\ttraining's macroF1: 0.625005\tvalid_1's multi_logloss: 1.03612\tvalid_1's macroF1: 0.385616\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's multi_logloss: 1.3729\ttraining's macroF1: 0.462444\tvalid_1's multi_logloss: 1.36832\tvalid_1's macroF1: 0.416813\n",
      "******************** Execution ended in 00h 00hm 12.48s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.912842\ttraining's macroF1: 0.605659\tvalid_1's multi_logloss: 1.02744\tvalid_1's macroF1: 0.404209\n",
      "[1000]\ttraining's multi_logloss: 0.774382\ttraining's macroF1: 0.675223\tvalid_1's multi_logloss: 1.01882\tvalid_1's macroF1: 0.399878\n",
      "Early stopping, best iteration is:\n",
      "[581]\ttraining's multi_logloss: 0.88505\ttraining's macroF1: 0.614492\tvalid_1's multi_logloss: 1.0248\tvalid_1's macroF1: 0.417713\n",
      "******************** Execution ended in 00h 00hm 25.14s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.921863\ttraining's macroF1: 0.608371\tvalid_1's multi_logloss: 1.02773\tvalid_1's macroF1: 0.418642\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's multi_logloss: 1.0683\ttraining's macroF1: 0.556671\tvalid_1's multi_logloss: 1.07656\tvalid_1's macroF1: 0.430473\n",
      "******************** Execution ended in 00h 00hm 17.00s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.918571\ttraining's macroF1: 0.602046\tvalid_1's multi_logloss: 1.01522\tvalid_1's macroF1: 0.389297\n",
      "Early stopping, best iteration is:\n",
      "[454]\ttraining's multi_logloss: 0.93613\ttraining's macroF1: 0.591892\tvalid_1's multi_logloss: 1.0181\tvalid_1's macroF1: 0.39805\n",
      "******************** Execution ended in 00h 00hm 21.88s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.905699\ttraining's macroF1: 0.621804\tvalid_1's multi_logloss: 1.05142\tvalid_1's macroF1: 0.401123\n",
      "Early stopping, best iteration is:\n",
      "[351]\ttraining's multi_logloss: 0.967676\ttraining's macroF1: 0.591626\tvalid_1's multi_logloss: 1.05386\tvalid_1's macroF1: 0.413087\n",
      "******************** Execution ended in 00h 00hm 19.91s ********************\n",
      "######################################## 10 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.669299\ttraining's macroF1: 0.773652\tvalid_1's multi_logloss: 1.0402\tvalid_1's macroF1: 0.388565\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's multi_logloss: 1.06999\ttraining's macroF1: 0.640358\tvalid_1's multi_logloss: 1.13635\tvalid_1's macroF1: 0.411599\n",
      "******************** Execution ended in 00h 00hm 15.31s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.678398\ttraining's macroF1: 0.761443\tvalid_1's multi_logloss: 0.961321\tvalid_1's macroF1: 0.418263\n",
      "[1000]\ttraining's multi_logloss: 0.489027\ttraining's macroF1: 0.829837\tvalid_1's multi_logloss: 0.933001\tvalid_1's macroF1: 0.421754\n",
      "Early stopping, best iteration is:\n",
      "[643]\ttraining's multi_logloss: 0.607105\ttraining's macroF1: 0.787233\tvalid_1's multi_logloss: 0.948982\tvalid_1's macroF1: 0.42782\n",
      "******************** Execution ended in 00h 00hm 29.92s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.67587\ttraining's macroF1: 0.754728\tvalid_1's multi_logloss: 0.988001\tvalid_1's macroF1: 0.419697\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's multi_logloss: 1.3276\ttraining's macroF1: 0.547983\tvalid_1's multi_logloss: 1.32805\tvalid_1's macroF1: 0.441173\n",
      "******************** Execution ended in 00h 00hm 13.51s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.683689\ttraining's macroF1: 0.758376\tvalid_1's multi_logloss: 0.976788\tvalid_1's macroF1: 0.419539\n",
      "[1000]\ttraining's multi_logloss: 0.494189\ttraining's macroF1: 0.824987\tvalid_1's multi_logloss: 0.958643\tvalid_1's macroF1: 0.416923\n",
      "[1500]\ttraining's multi_logloss: 0.397364\ttraining's macroF1: 0.861238\tvalid_1's multi_logloss: 0.955584\tvalid_1's macroF1: 0.421604\n",
      "Early stopping, best iteration is:\n",
      "[1171]\ttraining's multi_logloss: 0.45346\ttraining's macroF1: 0.839363\tvalid_1's multi_logloss: 0.954396\tvalid_1's macroF1: 0.428543\n",
      "******************** Execution ended in 00h 00hm 47.77s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.673329\ttraining's macroF1: 0.777822\tvalid_1's multi_logloss: 0.953943\tvalid_1's macroF1: 0.439239\n",
      "Early stopping, best iteration is:\n",
      "[347]\ttraining's multi_logloss: 0.77418\ttraining's macroF1: 0.732433\tvalid_1's multi_logloss: 0.975793\tvalid_1's macroF1: 0.458306\n",
      "******************** Execution ended in 00h 00hm 22.53s ********************\n",
      "######################################## 11 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.826555\ttraining's macroF1: 0.654762\tvalid_1's multi_logloss: 1.00352\tvalid_1's macroF1: 0.42403\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's multi_logloss: 0.94075\ttraining's macroF1: 0.597507\tvalid_1's multi_logloss: 1.01836\tvalid_1's macroF1: 0.439839\n",
      "******************** Execution ended in 00h 00hm 20.77s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.814904\ttraining's macroF1: 0.653928\tvalid_1's multi_logloss: 1.05573\tvalid_1's macroF1: 0.375468\n",
      "Early stopping, best iteration is:\n",
      "[378]\ttraining's multi_logloss: 0.872048\ttraining's macroF1: 0.634059\tvalid_1's multi_logloss: 1.06104\tvalid_1's macroF1: 0.391427\n",
      "******************** Execution ended in 00h 00hm 23.47s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.835411\ttraining's macroF1: 0.648356\tvalid_1's multi_logloss: 1.00957\tvalid_1's macroF1: 0.415201\n",
      "[1000]\ttraining's multi_logloss: 0.675759\ttraining's macroF1: 0.728998\tvalid_1's multi_logloss: 0.991587\tvalid_1's macroF1: 0.438871\n",
      "Early stopping, best iteration is:\n",
      "[868]\ttraining's multi_logloss: 0.709503\ttraining's macroF1: 0.712184\tvalid_1's multi_logloss: 0.994838\tvalid_1's macroF1: 0.440131\n",
      "******************** Execution ended in 00h 00hm 34.62s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.825388\ttraining's macroF1: 0.660081\tvalid_1's multi_logloss: 1.00124\tvalid_1's macroF1: 0.433117\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's multi_logloss: 0.927309\ttraining's macroF1: 0.61098\tvalid_1's multi_logloss: 1.00991\tvalid_1's macroF1: 0.448361\n",
      "******************** Execution ended in 00h 00hm 22.09s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.819429\ttraining's macroF1: 0.659377\tvalid_1's multi_logloss: 1.04186\tvalid_1's macroF1: 0.3968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's multi_logloss: 0.970511\ttraining's macroF1: 0.58513\tvalid_1's multi_logloss: 1.06089\tvalid_1's macroF1: 0.415134\n",
      "******************** Execution ended in 00h 00hm 20.28s ********************\n",
      "######################################## 12 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.923806\ttraining's macroF1: 0.595159\tvalid_1's multi_logloss: 1.00721\tvalid_1's macroF1: 0.448697\n",
      "[1000]\ttraining's multi_logloss: 0.797576\ttraining's macroF1: 0.664625\tvalid_1's multi_logloss: 0.992576\tvalid_1's macroF1: 0.465812\n",
      "[1500]\ttraining's multi_logloss: 0.717057\ttraining's macroF1: 0.696009\tvalid_1's multi_logloss: 0.986978\tvalid_1's macroF1: 0.472141\n",
      "Early stopping, best iteration is:\n",
      "[1315]\ttraining's multi_logloss: 0.743759\ttraining's macroF1: 0.685862\tvalid_1's multi_logloss: 0.988255\tvalid_1's macroF1: 0.483085\n",
      "******************** Execution ended in 00h 00hm 41.62s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.895247\ttraining's macroF1: 0.611237\tvalid_1's multi_logloss: 1.08205\tvalid_1's macroF1: 0.36415\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's multi_logloss: 1.16034\ttraining's macroF1: 0.502014\tvalid_1's multi_logloss: 1.16637\tvalid_1's macroF1: 0.378325\n",
      "******************** Execution ended in 00h 00hm 14.93s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.910451\ttraining's macroF1: 0.601557\tvalid_1's multi_logloss: 1.04514\tvalid_1's macroF1: 0.421193\n",
      "[1000]\ttraining's multi_logloss: 0.787851\ttraining's macroF1: 0.670802\tvalid_1's multi_logloss: 1.03262\tvalid_1's macroF1: 0.41495\n",
      "Early stopping, best iteration is:\n",
      "[543]\ttraining's multi_logloss: 0.896996\ttraining's macroF1: 0.607934\tvalid_1's multi_logloss: 1.04345\tvalid_1's macroF1: 0.427125\n",
      "******************** Execution ended in 00h 00hm 25.20s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.914021\ttraining's macroF1: 0.603013\tvalid_1's multi_logloss: 1.05165\tvalid_1's macroF1: 0.405108\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's multi_logloss: 1.07752\ttraining's macroF1: 0.533419\tvalid_1's multi_logloss: 1.08604\tvalid_1's macroF1: 0.437876\n",
      "******************** Execution ended in 00h 00hm 16.79s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.914833\ttraining's macroF1: 0.59186\tvalid_1's multi_logloss: 1.00218\tvalid_1's macroF1: 0.393869\n",
      "[1000]\ttraining's multi_logloss: 0.790648\ttraining's macroF1: 0.661058\tvalid_1's multi_logloss: 0.993442\tvalid_1's macroF1: 0.394343\n",
      "Early stopping, best iteration is:\n",
      "[697]\ttraining's multi_logloss: 0.857505\ttraining's macroF1: 0.621437\tvalid_1's multi_logloss: 0.996\tvalid_1's macroF1: 0.402578\n",
      "******************** Execution ended in 00h 00hm 29.37s ********************\n",
      "######################################## 13 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.15127\ttraining's macroF1: 0.504282\tvalid_1's multi_logloss: 1.1038\tvalid_1's macroF1: 0.424624\n",
      "Early stopping, best iteration is:\n",
      "[309]\ttraining's multi_logloss: 1.21316\ttraining's macroF1: 0.477431\tvalid_1's multi_logloss: 1.16302\tvalid_1's macroF1: 0.436315\n",
      "******************** Execution ended in 00h 00hm 25.55s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.14731\ttraining's macroF1: 0.504879\tvalid_1's multi_logloss: 1.13005\tvalid_1's macroF1: 0.366085\n",
      "Early stopping, best iteration is:\n",
      "[456]\ttraining's multi_logloss: 1.15909\ttraining's macroF1: 0.497643\tvalid_1's multi_logloss: 1.13972\tvalid_1's macroF1: 0.381721\n",
      "******************** Execution ended in 00h 00hm 28.43s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.15673\ttraining's macroF1: 0.491206\tvalid_1's multi_logloss: 1.13562\tvalid_1's macroF1: 0.405378\n",
      "[1000]\ttraining's multi_logloss: 1.06171\ttraining's macroF1: 0.522346\tvalid_1's multi_logloss: 1.08211\tvalid_1's macroF1: 0.423493\n",
      "[1500]\ttraining's multi_logloss: 1.00455\ttraining's macroF1: 0.550938\tvalid_1's multi_logloss: 1.06509\tvalid_1's macroF1: 0.428672\n",
      "[2000]\ttraining's multi_logloss: 0.961047\ttraining's macroF1: 0.577782\tvalid_1's multi_logloss: 1.05836\tvalid_1's macroF1: 0.42769\n",
      "Early stopping, best iteration is:\n",
      "[1707]\ttraining's multi_logloss: 0.985166\ttraining's macroF1: 0.566598\tvalid_1's multi_logloss: 1.06177\tvalid_1's macroF1: 0.430818\n",
      "******************** Execution ended in 00h 01hm 07.91s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.14848\ttraining's macroF1: 0.495805\tvalid_1's multi_logloss: 1.13796\tvalid_1's macroF1: 0.378163\n",
      "[1000]\ttraining's multi_logloss: 1.05289\ttraining's macroF1: 0.530078\tvalid_1's multi_logloss: 1.08672\tvalid_1's macroF1: 0.39873\n",
      "Early stopping, best iteration is:\n",
      "[975]\ttraining's multi_logloss: 1.05634\ttraining's macroF1: 0.527433\tvalid_1's multi_logloss: 1.08825\tvalid_1's macroF1: 0.406024\n",
      "******************** Execution ended in 00h 00hm 43.21s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.14845\ttraining's macroF1: 0.50311\tvalid_1's multi_logloss: 1.1447\tvalid_1's macroF1: 0.376882\n",
      "[1000]\ttraining's multi_logloss: 1.0523\ttraining's macroF1: 0.534525\tvalid_1's multi_logloss: 1.09124\tvalid_1's macroF1: 0.384791\n",
      "Early stopping, best iteration is:\n",
      "[927]\ttraining's multi_logloss: 1.06282\ttraining's macroF1: 0.528698\tvalid_1's multi_logloss: 1.09561\tvalid_1's macroF1: 0.396154\n",
      "******************** Execution ended in 00h 00hm 41.97s ********************\n",
      "######################################## 14 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10056\ttraining's macroF1: 0.516899\tvalid_1's multi_logloss: 1.10102\tvalid_1's macroF1: 0.415043\n",
      "[1000]\ttraining's multi_logloss: 1.00891\ttraining's macroF1: 0.549772\tvalid_1's multi_logloss: 1.06676\tvalid_1's macroF1: 0.393506\n",
      "Early stopping, best iteration is:\n",
      "[524]\ttraining's multi_logloss: 1.09457\ttraining's macroF1: 0.517911\tvalid_1's multi_logloss: 1.0969\tvalid_1's macroF1: 0.424086\n",
      "******************** Execution ended in 00h 00hm 21.05s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10245\ttraining's macroF1: 0.524582\tvalid_1's multi_logloss: 1.07192\tvalid_1's macroF1: 0.39405\n",
      "[1000]\ttraining's multi_logloss: 1.00749\ttraining's macroF1: 0.56301\tvalid_1's multi_logloss: 1.03595\tvalid_1's macroF1: 0.401211\n",
      "Early stopping, best iteration is:\n",
      "[569]\ttraining's multi_logloss: 1.0849\ttraining's macroF1: 0.526282\tvalid_1's multi_logloss: 1.0622\tvalid_1's macroF1: 0.409924\n",
      "******************** Execution ended in 00h 00hm 21.82s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's multi_logloss: 1.10865\ttraining's macroF1: 0.499004\tvalid_1's multi_logloss: 1.08392\tvalid_1's macroF1: 0.406218\n",
      "[1000]\ttraining's multi_logloss: 1.01796\ttraining's macroF1: 0.538029\tvalid_1's multi_logloss: 1.04775\tvalid_1's macroF1: 0.423082\n",
      "[1500]\ttraining's multi_logloss: 0.960283\ttraining's macroF1: 0.560474\tvalid_1's multi_logloss: 1.03667\tvalid_1's macroF1: 0.444909\n",
      "Early stopping, best iteration is:\n",
      "[1320]\ttraining's multi_logloss: 0.979195\ttraining's macroF1: 0.552282\tvalid_1's multi_logloss: 1.03984\tvalid_1's macroF1: 0.451428\n",
      "******************** Execution ended in 00h 00hm 38.08s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10654\ttraining's macroF1: 0.522228\tvalid_1's multi_logloss: 1.08959\tvalid_1's macroF1: 0.417716\n",
      "Early stopping, best iteration is:\n",
      "[414]\ttraining's multi_logloss: 1.13071\ttraining's macroF1: 0.51152\tvalid_1's multi_logloss: 1.10849\tvalid_1's macroF1: 0.425003\n",
      "******************** Execution ended in 00h 00hm 18.99s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09733\ttraining's macroF1: 0.507592\tvalid_1's multi_logloss: 1.10857\tvalid_1's macroF1: 0.393678\n",
      "[1000]\ttraining's multi_logloss: 1.00362\ttraining's macroF1: 0.547422\tvalid_1's multi_logloss: 1.0794\tvalid_1's macroF1: 0.405295\n",
      "[1500]\ttraining's multi_logloss: 0.947364\ttraining's macroF1: 0.574617\tvalid_1's multi_logloss: 1.0732\tvalid_1's macroF1: 0.406617\n",
      "Early stopping, best iteration is:\n",
      "[1091]\ttraining's multi_logloss: 0.991767\ttraining's macroF1: 0.552983\tvalid_1's multi_logloss: 1.07759\tvalid_1's macroF1: 0.416852\n",
      "******************** Execution ended in 00h 00hm 31.10s ********************\n",
      "######################################## 15 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10024\ttraining's macroF1: 0.575018\tvalid_1's multi_logloss: 1.12218\tvalid_1's macroF1: 0.388823\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's multi_logloss: 1.33684\ttraining's macroF1: 0.504722\tvalid_1's multi_logloss: 1.33081\tvalid_1's macroF1: 0.403317\n",
      "******************** Execution ended in 00h 00hm 15.80s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10498\ttraining's macroF1: 0.560252\tvalid_1's multi_logloss: 1.12107\tvalid_1's macroF1: 0.424272\n",
      "[1000]\ttraining's multi_logloss: 0.975935\ttraining's macroF1: 0.60272\tvalid_1's multi_logloss: 1.05044\tvalid_1's macroF1: 0.432931\n",
      "[1500]\ttraining's multi_logloss: 0.893535\ttraining's macroF1: 0.632476\tvalid_1's multi_logloss: 1.02721\tvalid_1's macroF1: 0.428618\n",
      "Early stopping, best iteration is:\n",
      "[1051]\ttraining's multi_logloss: 0.966072\ttraining's macroF1: 0.60717\tvalid_1's multi_logloss: 1.04693\tvalid_1's macroF1: 0.440825\n",
      "******************** Execution ended in 00h 00hm 46.47s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10685\ttraining's macroF1: 0.567684\tvalid_1's multi_logloss: 1.14827\tvalid_1's macroF1: 0.399013\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's multi_logloss: 1.32323\ttraining's macroF1: 0.513868\tvalid_1's multi_logloss: 1.3224\tvalid_1's macroF1: 0.411133\n",
      "******************** Execution ended in 00h 00hm 16.41s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.11098\ttraining's macroF1: 0.556659\tvalid_1's multi_logloss: 1.09855\tvalid_1's macroF1: 0.415742\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's multi_logloss: 1.38141\ttraining's macroF1: 0.484761\tvalid_1's multi_logloss: 1.38008\tvalid_1's macroF1: 0.422143\n",
      "******************** Execution ended in 00h 00hm 15.38s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10865\ttraining's macroF1: 0.563065\tvalid_1's multi_logloss: 1.11069\tvalid_1's macroF1: 0.394991\n",
      "Early stopping, best iteration is:\n",
      "[250]\ttraining's multi_logloss: 1.21427\ttraining's macroF1: 0.540134\tvalid_1's multi_logloss: 1.19409\tvalid_1's macroF1: 0.416357\n",
      "******************** Execution ended in 00h 00hm 23.27s ********************\n",
      "######################################## 16 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.752482\ttraining's macroF1: 0.723689\tvalid_1's multi_logloss: 1.07843\tvalid_1's macroF1: 0.377019\n",
      "[1000]\ttraining's multi_logloss: 0.56484\ttraining's macroF1: 0.79054\tvalid_1's multi_logloss: 1.06606\tvalid_1's macroF1: 0.397579\n",
      "[1500]\ttraining's multi_logloss: 0.461995\ttraining's macroF1: 0.837464\tvalid_1's multi_logloss: 1.06161\tvalid_1's macroF1: 0.400003\n",
      "Early stopping, best iteration is:\n",
      "[1217]\ttraining's multi_logloss: 0.513405\ttraining's macroF1: 0.814819\tvalid_1's multi_logloss: 1.06156\tvalid_1's macroF1: 0.407058\n",
      "******************** Execution ended in 00h 01hm 00.65s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.764794\ttraining's macroF1: 0.727417\tvalid_1's multi_logloss: 1.01622\tvalid_1's macroF1: 0.416633\n",
      "[1000]\ttraining's multi_logloss: 0.573239\ttraining's macroF1: 0.800009\tvalid_1's multi_logloss: 0.992112\tvalid_1's macroF1: 0.428927\n",
      "[1500]\ttraining's multi_logloss: 0.467376\ttraining's macroF1: 0.834925\tvalid_1's multi_logloss: 0.983915\tvalid_1's macroF1: 0.407867\n",
      "Early stopping, best iteration is:\n",
      "[1027]\ttraining's multi_logloss: 0.566136\ttraining's macroF1: 0.800358\tvalid_1's multi_logloss: 0.991623\tvalid_1's macroF1: 0.431425\n",
      "******************** Execution ended in 00h 00hm 56.29s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.766473\ttraining's macroF1: 0.724681\tvalid_1's multi_logloss: 1.04042\tvalid_1's macroF1: 0.411663\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's multi_logloss: 0.899883\ttraining's macroF1: 0.679591\tvalid_1's multi_logloss: 1.06669\tvalid_1's macroF1: 0.423743\n",
      "******************** Execution ended in 00h 00hm 32.01s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.776299\ttraining's macroF1: 0.720664\tvalid_1's multi_logloss: 0.956466\tvalid_1's macroF1: 0.458366\n",
      "Early stopping, best iteration is:\n",
      "[438]\ttraining's multi_logloss: 0.812267\ttraining's macroF1: 0.704373\tvalid_1's multi_logloss: 0.963994\tvalid_1's macroF1: 0.465904\n",
      "******************** Execution ended in 00h 00hm 38.22s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.769617\ttraining's macroF1: 0.725908\tvalid_1's multi_logloss: 0.949942\tvalid_1's macroF1: 0.43088\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's multi_logloss: 1.36666\ttraining's macroF1: 0.531106\tvalid_1's multi_logloss: 1.36241\tvalid_1's macroF1: 0.461104\n",
      "******************** Execution ended in 00h 00hm 18.34s ********************\n",
      "######################################## 17 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's multi_logloss: 1.1981\ttraining's macroF1: 0.471589\tvalid_1's multi_logloss: 1.16204\tvalid_1's macroF1: 0.39048\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's multi_logloss: 1.29198\ttraining's macroF1: 0.443058\tvalid_1's multi_logloss: 1.26183\tvalid_1's macroF1: 0.40708\n",
      "******************** Execution ended in 00h 00hm 11.18s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.20676\ttraining's macroF1: 0.463173\tvalid_1's multi_logloss: 1.15429\tvalid_1's macroF1: 0.381695\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's multi_logloss: 1.3667\ttraining's macroF1: 0.4232\tvalid_1's multi_logloss: 1.3573\tvalid_1's macroF1: 0.40172\n",
      "******************** Execution ended in 00h 00hm 09.34s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.21064\ttraining's macroF1: 0.476097\tvalid_1's multi_logloss: 1.13417\tvalid_1's macroF1: 0.407819\n",
      "[1000]\ttraining's multi_logloss: 1.13793\ttraining's macroF1: 0.497164\tvalid_1's multi_logloss: 1.06136\tvalid_1's macroF1: 0.418654\n",
      "[1500]\ttraining's multi_logloss: 1.09516\ttraining's macroF1: 0.507863\tvalid_1's multi_logloss: 1.03815\tvalid_1's macroF1: 0.414372\n",
      "Early stopping, best iteration is:\n",
      "[1120]\ttraining's multi_logloss: 1.12588\ttraining's macroF1: 0.499262\tvalid_1's multi_logloss: 1.05365\tvalid_1's macroF1: 0.431641\n",
      "******************** Execution ended in 00h 00hm 29.69s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.20574\ttraining's macroF1: 0.468986\tvalid_1's multi_logloss: 1.16834\tvalid_1's macroF1: 0.365022\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 1.38093\ttraining's macroF1: 0.406624\tvalid_1's multi_logloss: 1.37869\tvalid_1's macroF1: 0.377515\n",
      "******************** Execution ended in 00h 00hm 09.07s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.20455\ttraining's macroF1: 0.461791\tvalid_1's multi_logloss: 1.18364\tvalid_1's macroF1: 0.377809\n",
      "[1000]\ttraining's multi_logloss: 1.13187\ttraining's macroF1: 0.4925\tvalid_1's multi_logloss: 1.13462\tvalid_1's macroF1: 0.383043\n",
      "Early stopping, best iteration is:\n",
      "[706]\ttraining's multi_logloss: 1.16866\ttraining's macroF1: 0.469198\tvalid_1's multi_logloss: 1.15645\tvalid_1's macroF1: 0.392862\n",
      "******************** Execution ended in 00h 00hm 18.21s ********************\n",
      "######################################## 18 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.776508\ttraining's macroF1: 0.696822\tvalid_1's multi_logloss: 0.964237\tvalid_1's macroF1: 0.439869\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's multi_logloss: 0.983863\ttraining's macroF1: 0.608765\tvalid_1's multi_logloss: 1.00823\tvalid_1's macroF1: 0.450687\n",
      "******************** Execution ended in 00h 00hm 17.33s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.767551\ttraining's macroF1: 0.710862\tvalid_1's multi_logloss: 1.04293\tvalid_1's macroF1: 0.414175\n",
      "[1000]\ttraining's multi_logloss: 0.597055\ttraining's macroF1: 0.782968\tvalid_1's multi_logloss: 1.03595\tvalid_1's macroF1: 0.406764\n",
      "Early stopping, best iteration is:\n",
      "[603]\ttraining's multi_logloss: 0.722359\ttraining's macroF1: 0.730141\tvalid_1's multi_logloss: 1.04024\tvalid_1's macroF1: 0.437117\n",
      "******************** Execution ended in 00h 00hm 28.05s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.778764\ttraining's macroF1: 0.70889\tvalid_1's multi_logloss: 0.984534\tvalid_1's macroF1: 0.401186\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's multi_logloss: 0.86272\ttraining's macroF1: 0.667838\tvalid_1's multi_logloss: 0.998373\tvalid_1's macroF1: 0.423097\n",
      "******************** Execution ended in 00h 00hm 20.56s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.770316\ttraining's macroF1: 0.695724\tvalid_1's multi_logloss: 1.01737\tvalid_1's macroF1: 0.396269\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's multi_logloss: 1.14744\ttraining's macroF1: 0.564934\tvalid_1's multi_logloss: 1.13498\tvalid_1's macroF1: 0.437319\n",
      "******************** Execution ended in 00h 00hm 15.81s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.776245\ttraining's macroF1: 0.700295\tvalid_1's multi_logloss: 1.02819\tvalid_1's macroF1: 0.421077\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's multi_logloss: 1.01217\ttraining's macroF1: 0.602499\tvalid_1's multi_logloss: 1.07011\tvalid_1's macroF1: 0.451994\n",
      "******************** Execution ended in 00h 00hm 16.28s ********************\n",
      "######################################## 19 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09563\ttraining's macroF1: 0.549778\tvalid_1's multi_logloss: 1.11402\tvalid_1's macroF1: 0.418659\n",
      "Early stopping, best iteration is:\n",
      "[442]\ttraining's multi_logloss: 1.11613\ttraining's macroF1: 0.545143\tvalid_1's multi_logloss: 1.1273\tvalid_1's macroF1: 0.429833\n",
      "******************** Execution ended in 00h 00hm 25.40s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09854\ttraining's macroF1: 0.551784\tvalid_1's multi_logloss: 1.11721\tvalid_1's macroF1: 0.402194\n",
      "[1000]\ttraining's multi_logloss: 0.975388\ttraining's macroF1: 0.586565\tvalid_1's multi_logloss: 1.05745\tvalid_1's macroF1: 0.39522\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's multi_logloss: 1.09384\ttraining's macroF1: 0.553214\tvalid_1's multi_logloss: 1.11407\tvalid_1's macroF1: 0.403403\n",
      "******************** Execution ended in 00h 00hm 29.91s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10229\ttraining's macroF1: 0.551946\tvalid_1's multi_logloss: 1.09406\tvalid_1's macroF1: 0.410426\n",
      "[1000]\ttraining's multi_logloss: 0.98102\ttraining's macroF1: 0.598158\tvalid_1's multi_logloss: 1.02394\tvalid_1's macroF1: 0.435349\n",
      "[1500]\ttraining's multi_logloss: 0.903404\ttraining's macroF1: 0.636281\tvalid_1's multi_logloss: 1.00284\tvalid_1's macroF1: 0.443333\n",
      "[2000]\ttraining's multi_logloss: 0.843613\ttraining's macroF1: 0.666346\tvalid_1's multi_logloss: 0.992635\tvalid_1's macroF1: 0.439976\n",
      "Early stopping, best iteration is:\n",
      "[1618]\ttraining's multi_logloss: 0.888191\ttraining's macroF1: 0.641778\tvalid_1's multi_logloss: 1.00039\tvalid_1's macroF1: 0.453259\n",
      "******************** Execution ended in 00h 00hm 54.86s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09542\ttraining's macroF1: 0.562162\tvalid_1's multi_logloss: 1.12726\tvalid_1's macroF1: 0.40489\n",
      "[1000]\ttraining's multi_logloss: 0.967432\ttraining's macroF1: 0.600947\tvalid_1's multi_logloss: 1.07385\tvalid_1's macroF1: 0.403037\n",
      "Early stopping, best iteration is:\n",
      "[591]\ttraining's multi_logloss: 1.06591\ttraining's macroF1: 0.573072\tvalid_1's multi_logloss: 1.11087\tvalid_1's macroF1: 0.41428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Execution ended in 00h 00hm 30.97s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10588\ttraining's macroF1: 0.556192\tvalid_1's multi_logloss: 1.10606\tvalid_1's macroF1: 0.436142\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's multi_logloss: 1.273\ttraining's macroF1: 0.507877\tvalid_1's multi_logloss: 1.25392\tvalid_1's macroF1: 0.456981\n",
      "******************** Execution ended in 00h 00hm 17.87s ********************\n",
      "######################################## 20 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.804207\ttraining's macroF1: 0.688736\tvalid_1's multi_logloss: 0.986446\tvalid_1's macroF1: 0.422416\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_logloss: 1.31228\ttraining's macroF1: 0.530143\tvalid_1's multi_logloss: 1.30327\tvalid_1's macroF1: 0.439947\n",
      "******************** Execution ended in 00h 00hm 16.70s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.796479\ttraining's macroF1: 0.714704\tvalid_1's multi_logloss: 1.03094\tvalid_1's macroF1: 0.40634\n",
      "[1000]\ttraining's multi_logloss: 0.613646\ttraining's macroF1: 0.780255\tvalid_1's multi_logloss: 1.00497\tvalid_1's macroF1: 0.416639\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's multi_logloss: 0.744422\ttraining's macroF1: 0.730563\tvalid_1's multi_logloss: 1.0216\tvalid_1's macroF1: 0.425809\n",
      "******************** Execution ended in 00h 00hm 32.77s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.800896\ttraining's macroF1: 0.699702\tvalid_1's multi_logloss: 1.00415\tvalid_1's macroF1: 0.409698\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's multi_logloss: 1.0772\ttraining's macroF1: 0.606316\tvalid_1's multi_logloss: 1.11408\tvalid_1's macroF1: 0.428393\n",
      "******************** Execution ended in 00h 00hm 18.68s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.795635\ttraining's macroF1: 0.701796\tvalid_1's multi_logloss: 1.00646\tvalid_1's macroF1: 0.432754\n",
      "[1000]\ttraining's multi_logloss: 0.613027\ttraining's macroF1: 0.780877\tvalid_1's multi_logloss: 0.979147\tvalid_1's macroF1: 0.433116\n",
      "Early stopping, best iteration is:\n",
      "[724]\ttraining's multi_logloss: 0.698967\ttraining's macroF1: 0.743493\tvalid_1's multi_logloss: 0.990447\tvalid_1's macroF1: 0.440737\n",
      "******************** Execution ended in 00h 00hm 35.67s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.794756\ttraining's macroF1: 0.711024\tvalid_1's multi_logloss: 1.02992\tvalid_1's macroF1: 0.40971\n",
      "[1000]\ttraining's multi_logloss: 0.610775\ttraining's macroF1: 0.779065\tvalid_1's multi_logloss: 1.01765\tvalid_1's macroF1: 0.405915\n",
      "Early stopping, best iteration is:\n",
      "[625]\ttraining's multi_logloss: 0.73639\ttraining's macroF1: 0.72998\tvalid_1's multi_logloss: 1.02426\tvalid_1's macroF1: 0.415671\n",
      "******************** Execution ended in 00h 00hm 33.38s ********************\n",
      "######################################## 21 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05464\ttraining's macroF1: 0.546837\tvalid_1's multi_logloss: 1.09755\tvalid_1's macroF1: 0.396013\n",
      "Early stopping, best iteration is:\n",
      "[214]\ttraining's multi_logloss: 1.17889\ttraining's macroF1: 0.507395\tvalid_1's multi_logloss: 1.17799\tvalid_1's macroF1: 0.41042\n",
      "******************** Execution ended in 00h 00hm 19.83s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.06511\ttraining's macroF1: 0.535151\tvalid_1's multi_logloss: 1.07646\tvalid_1's macroF1: 0.413259\n",
      "[1000]\ttraining's multi_logloss: 0.953241\ttraining's macroF1: 0.586944\tvalid_1's multi_logloss: 1.04272\tvalid_1's macroF1: 0.420684\n",
      "[1500]\ttraining's multi_logloss: 0.882665\ttraining's macroF1: 0.622252\tvalid_1's multi_logloss: 1.03563\tvalid_1's macroF1: 0.423984\n",
      "Early stopping, best iteration is:\n",
      "[1280]\ttraining's multi_logloss: 0.910803\ttraining's macroF1: 0.610838\tvalid_1's multi_logloss: 1.03749\tvalid_1's macroF1: 0.428388\n",
      "******************** Execution ended in 00h 00hm 54.44s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05476\ttraining's macroF1: 0.543024\tvalid_1's multi_logloss: 1.08993\tvalid_1's macroF1: 0.381279\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's multi_logloss: 1.37992\ttraining's macroF1: 0.437108\tvalid_1's multi_logloss: 1.3784\tvalid_1's macroF1: 0.399001\n",
      "******************** Execution ended in 00h 00hm 14.33s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07546\ttraining's macroF1: 0.540211\tvalid_1's multi_logloss: 1.06461\tvalid_1's macroF1: 0.411171\n",
      "[1000]\ttraining's multi_logloss: 0.966303\ttraining's macroF1: 0.579091\tvalid_1's multi_logloss: 1.01953\tvalid_1's macroF1: 0.412203\n",
      "Early stopping, best iteration is:\n",
      "[614]\ttraining's multi_logloss: 1.04382\ttraining's macroF1: 0.551007\tvalid_1's multi_logloss: 1.04682\tvalid_1's macroF1: 0.427031\n",
      "******************** Execution ended in 00h 00hm 27.63s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.06776\ttraining's macroF1: 0.541031\tvalid_1's multi_logloss: 1.07544\tvalid_1's macroF1: 0.403329\n",
      "Early stopping, best iteration is:\n",
      "[400]\ttraining's multi_logloss: 1.10043\ttraining's macroF1: 0.528404\tvalid_1's multi_logloss: 1.09481\tvalid_1's macroF1: 0.418113\n",
      "******************** Execution ended in 00h 00hm 24.75s ********************\n",
      "######################################## 22 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.999911\ttraining's macroF1: 0.567764\tvalid_1's multi_logloss: 1.06961\tvalid_1's macroF1: 0.365951\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's multi_logloss: 1.27538\ttraining's macroF1: 0.486459\tvalid_1's multi_logloss: 1.26089\tvalid_1's macroF1: 0.38759\n",
      "******************** Execution ended in 00h 00hm 13.19s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00444\ttraining's macroF1: 0.566099\tvalid_1's multi_logloss: 1.04409\tvalid_1's macroF1: 0.422351\n",
      "[1000]\ttraining's multi_logloss: 0.885005\ttraining's macroF1: 0.628012\tvalid_1's multi_logloss: 1.02277\tvalid_1's macroF1: 0.437962\n",
      "[1500]\ttraining's multi_logloss: 0.806778\ttraining's macroF1: 0.671373\tvalid_1's multi_logloss: 1.01693\tvalid_1's macroF1: 0.434803\n",
      "Early stopping, best iteration is:\n",
      "[1318]\ttraining's multi_logloss: 0.832406\ttraining's macroF1: 0.656733\tvalid_1's multi_logloss: 1.01897\tvalid_1's macroF1: 0.449055\n",
      "******************** Execution ended in 00h 00hm 39.79s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's multi_logloss: 0.999397\ttraining's macroF1: 0.56989\tvalid_1's multi_logloss: 1.06285\tvalid_1's macroF1: 0.399761\n",
      "[1000]\ttraining's multi_logloss: 0.879659\ttraining's macroF1: 0.627427\tvalid_1's multi_logloss: 1.03838\tvalid_1's macroF1: 0.425342\n",
      "[1500]\ttraining's multi_logloss: 0.801894\ttraining's macroF1: 0.671654\tvalid_1's multi_logloss: 1.02873\tvalid_1's macroF1: 0.413817\n",
      "Early stopping, best iteration is:\n",
      "[1081]\ttraining's multi_logloss: 0.865349\ttraining's macroF1: 0.631619\tvalid_1's multi_logloss: 1.03593\tvalid_1's macroF1: 0.429431\n",
      "******************** Execution ended in 00h 00hm 37.45s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00168\ttraining's macroF1: 0.579811\tvalid_1's multi_logloss: 1.04669\tvalid_1's macroF1: 0.433418\n",
      "[1000]\ttraining's multi_logloss: 0.882044\ttraining's macroF1: 0.631593\tvalid_1's multi_logloss: 1.02282\tvalid_1's macroF1: 0.45096\n",
      "[1500]\ttraining's multi_logloss: 0.805169\ttraining's macroF1: 0.670237\tvalid_1's multi_logloss: 1.01595\tvalid_1's macroF1: 0.45408\n",
      "[2000]\ttraining's multi_logloss: 0.747822\ttraining's macroF1: 0.694121\tvalid_1's multi_logloss: 1.01048\tvalid_1's macroF1: 0.459218\n",
      "Early stopping, best iteration is:\n",
      "[1946]\ttraining's multi_logloss: 0.753144\ttraining's macroF1: 0.688692\tvalid_1's multi_logloss: 1.01057\tvalid_1's macroF1: 0.461653\n",
      "******************** Execution ended in 00h 00hm 53.24s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00545\ttraining's macroF1: 0.574303\tvalid_1's multi_logloss: 1.04782\tvalid_1's macroF1: 0.41057\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's multi_logloss: 1.3627\ttraining's macroF1: 0.476393\tvalid_1's multi_logloss: 1.3534\tvalid_1's macroF1: 0.44661\n",
      "******************** Execution ended in 00h 00hm 12.43s ********************\n",
      "######################################## 23 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.948957\ttraining's macroF1: 0.683592\tvalid_1's multi_logloss: 1.05157\tvalid_1's macroF1: 0.44118\n",
      "[1000]\ttraining's multi_logloss: 0.774405\ttraining's macroF1: 0.736026\tvalid_1's multi_logloss: 1.00524\tvalid_1's macroF1: 0.431711\n",
      "Early stopping, best iteration is:\n",
      "[573]\ttraining's multi_logloss: 0.916243\ttraining's macroF1: 0.690135\tvalid_1's multi_logloss: 1.03931\tvalid_1's macroF1: 0.448199\n",
      "******************** Execution ended in 00h 00hm 41.88s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.946246\ttraining's macroF1: 0.665498\tvalid_1's multi_logloss: 1.04255\tvalid_1's macroF1: 0.397619\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's multi_logloss: 1.26937\ttraining's macroF1: 0.584308\tvalid_1's multi_logloss: 1.26834\tvalid_1's macroF1: 0.43817\n",
      "******************** Execution ended in 00h 00hm 24.11s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.939057\ttraining's macroF1: 0.661737\tvalid_1's multi_logloss: 1.06199\tvalid_1's macroF1: 0.371858\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's multi_logloss: 1.28623\ttraining's macroF1: 0.578878\tvalid_1's multi_logloss: 1.29046\tvalid_1's macroF1: 0.3936\n",
      "******************** Execution ended in 00h 00hm 22.50s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.95771\ttraining's macroF1: 0.649884\tvalid_1's multi_logloss: 1.02517\tvalid_1's macroF1: 0.42353\n",
      "[1000]\ttraining's multi_logloss: 0.786486\ttraining's macroF1: 0.715149\tvalid_1's multi_logloss: 0.964711\tvalid_1's macroF1: 0.430633\n",
      "[1500]\ttraining's multi_logloss: 0.676426\ttraining's macroF1: 0.747563\tvalid_1's multi_logloss: 0.943722\tvalid_1's macroF1: 0.442867\n",
      "[2000]\ttraining's multi_logloss: 0.593348\ttraining's macroF1: 0.781478\tvalid_1's multi_logloss: 0.929864\tvalid_1's macroF1: 0.457511\n",
      "Early stopping, best iteration is:\n",
      "[1868]\ttraining's multi_logloss: 0.613715\ttraining's macroF1: 0.772094\tvalid_1's multi_logloss: 0.932658\tvalid_1's macroF1: 0.460087\n",
      "******************** Execution ended in 00h 01hm 31.27s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.942466\ttraining's macroF1: 0.65477\tvalid_1's multi_logloss: 1.07265\tvalid_1's macroF1: 0.365919\n",
      "[1000]\ttraining's multi_logloss: 0.769678\ttraining's macroF1: 0.717499\tvalid_1's multi_logloss: 1.03012\tvalid_1's macroF1: 0.372972\n",
      "[1500]\ttraining's multi_logloss: 0.657931\ttraining's macroF1: 0.762025\tvalid_1's multi_logloss: 1.01852\tvalid_1's macroF1: 0.383005\n",
      "Early stopping, best iteration is:\n",
      "[1341]\ttraining's multi_logloss: 0.689478\ttraining's macroF1: 0.747562\tvalid_1's multi_logloss: 1.02199\tvalid_1's macroF1: 0.385714\n",
      "******************** Execution ended in 00h 01hm 11.18s ********************\n",
      "######################################## 24 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.595128\ttraining's macroF1: 0.798913\tvalid_1's multi_logloss: 1.00619\tvalid_1's macroF1: 0.424352\n",
      "[1000]\ttraining's multi_logloss: 0.418838\ttraining's macroF1: 0.857526\tvalid_1's multi_logloss: 0.985255\tvalid_1's macroF1: 0.4243\n",
      "[1500]\ttraining's multi_logloss: 0.335151\ttraining's macroF1: 0.886784\tvalid_1's multi_logloss: 0.980695\tvalid_1's macroF1: 0.429038\n",
      "Early stopping, best iteration is:\n",
      "[1308]\ttraining's multi_logloss: 0.36171\ttraining's macroF1: 0.877513\tvalid_1's multi_logloss: 0.983516\tvalid_1's macroF1: 0.445562\n",
      "******************** Execution ended in 00h 00hm 54.34s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.586747\ttraining's macroF1: 0.802706\tvalid_1's multi_logloss: 0.970541\tvalid_1's macroF1: 0.404842\n",
      "[1000]\ttraining's multi_logloss: 0.407638\ttraining's macroF1: 0.865697\tvalid_1's multi_logloss: 0.971402\tvalid_1's macroF1: 0.409526\n",
      "Early stopping, best iteration is:\n",
      "[658]\ttraining's multi_logloss: 0.511201\ttraining's macroF1: 0.829514\tvalid_1's multi_logloss: 0.966853\tvalid_1's macroF1: 0.420198\n",
      "******************** Execution ended in 00h 00hm 37.74s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.593958\ttraining's macroF1: 0.788409\tvalid_1's multi_logloss: 0.949542\tvalid_1's macroF1: 0.391306\n",
      "Early stopping, best iteration is:\n",
      "[146]\ttraining's multi_logloss: 0.933702\ttraining's macroF1: 0.664247\tvalid_1's multi_logloss: 1.0247\tvalid_1's macroF1: 0.422951\n",
      "******************** Execution ended in 00h 00hm 21.26s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.591186\ttraining's macroF1: 0.799015\tvalid_1's multi_logloss: 0.97729\tvalid_1's macroF1: 0.411951\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's multi_logloss: 0.926186\ttraining's macroF1: 0.690557\tvalid_1's multi_logloss: 1.03829\tvalid_1's macroF1: 0.424544\n",
      "******************** Execution ended in 00h 00hm 23.69s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.590594\ttraining's macroF1: 0.799609\tvalid_1's multi_logloss: 0.978865\tvalid_1's macroF1: 0.389775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[157]\ttraining's multi_logloss: 0.911763\ttraining's macroF1: 0.681108\tvalid_1's multi_logloss: 1.03359\tvalid_1's macroF1: 0.416189\n",
      "******************** Execution ended in 00h 00hm 21.85s ********************\n",
      "######################################## 25 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.16815\ttraining's macroF1: 0.616897\tvalid_1's multi_logloss: 1.17697\tvalid_1's macroF1: 0.410911\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's multi_logloss: 1.38267\ttraining's macroF1: 0.539178\tvalid_1's multi_logloss: 1.3822\tvalid_1's macroF1: 0.4179\n",
      "******************** Execution ended in 00h 00hm 16.71s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.16828\ttraining's macroF1: 0.624841\tvalid_1's multi_logloss: 1.19002\tvalid_1's macroF1: 0.377921\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's multi_logloss: 1.37478\ttraining's macroF1: 0.577349\tvalid_1's multi_logloss: 1.37411\tvalid_1's macroF1: 0.393508\n",
      "******************** Execution ended in 00h 00hm 18.25s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.16121\ttraining's macroF1: 0.599714\tvalid_1's multi_logloss: 1.19051\tvalid_1's macroF1: 0.371693\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's multi_logloss: 1.38378\ttraining's macroF1: 0.537269\tvalid_1's multi_logloss: 1.38379\tvalid_1's macroF1: 0.385429\n",
      "******************** Execution ended in 00h 00hm 18.11s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.16899\ttraining's macroF1: 0.611007\tvalid_1's multi_logloss: 1.18538\tvalid_1's macroF1: 0.408485\n",
      "[1000]\ttraining's multi_logloss: 1.04086\ttraining's macroF1: 0.641115\tvalid_1's multi_logloss: 1.09639\tvalid_1's macroF1: 0.433561\n",
      "[1500]\ttraining's multi_logloss: 0.952924\ttraining's macroF1: 0.665801\tvalid_1's multi_logloss: 1.04945\tvalid_1's macroF1: 0.43022\n",
      "Early stopping, best iteration is:\n",
      "[1139]\ttraining's multi_logloss: 1.01344\ttraining's macroF1: 0.644837\tvalid_1's multi_logloss: 1.08042\tvalid_1's macroF1: 0.434997\n",
      "******************** Execution ended in 00h 00hm 57.21s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.16164\ttraining's macroF1: 0.600512\tvalid_1's multi_logloss: 1.17798\tvalid_1's macroF1: 0.407952\n",
      "Early stopping, best iteration is:\n",
      "[291]\ttraining's multi_logloss: 1.23831\ttraining's macroF1: 0.584761\tvalid_1's multi_logloss: 1.2415\tvalid_1's macroF1: 0.419454\n",
      "******************** Execution ended in 00h 00hm 28.22s ********************\n",
      "######################################## 26 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.897718\ttraining's macroF1: 0.621266\tvalid_1's multi_logloss: 1.05424\tvalid_1's macroF1: 0.39137\n",
      "Early stopping, best iteration is:\n",
      "[286]\ttraining's multi_logloss: 1.00529\ttraining's macroF1: 0.58406\tvalid_1's multi_logloss: 1.07977\tvalid_1's macroF1: 0.406798\n",
      "******************** Execution ended in 00h 00hm 22.69s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.895542\ttraining's macroF1: 0.622585\tvalid_1's multi_logloss: 1.01528\tvalid_1's macroF1: 0.399637\n",
      "[1000]\ttraining's multi_logloss: 0.746341\ttraining's macroF1: 0.702275\tvalid_1's multi_logloss: 0.996638\tvalid_1's macroF1: 0.413725\n",
      "Early stopping, best iteration is:\n",
      "[964]\ttraining's multi_logloss: 0.754391\ttraining's macroF1: 0.696814\tvalid_1's multi_logloss: 0.997961\tvalid_1's macroF1: 0.418783\n",
      "******************** Execution ended in 00h 00hm 44.05s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.893851\ttraining's macroF1: 0.630535\tvalid_1's multi_logloss: 1.05614\tvalid_1's macroF1: 0.390423\n",
      "[1000]\ttraining's multi_logloss: 0.746845\ttraining's macroF1: 0.697003\tvalid_1's multi_logloss: 1.04556\tvalid_1's macroF1: 0.384647\n",
      "Early stopping, best iteration is:\n",
      "[607]\ttraining's multi_logloss: 0.854632\ttraining's macroF1: 0.648258\tvalid_1's multi_logloss: 1.05318\tvalid_1's macroF1: 0.396579\n",
      "******************** Execution ended in 00h 00hm 43.86s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.903648\ttraining's macroF1: 0.632867\tvalid_1's multi_logloss: 1.05361\tvalid_1's macroF1: 0.419393\n",
      "Early stopping, best iteration is:\n",
      "[329]\ttraining's multi_logloss: 0.982031\ttraining's macroF1: 0.59766\tvalid_1's multi_logloss: 1.07214\tvalid_1's macroF1: 0.427231\n",
      "******************** Execution ended in 00h 00hm 27.17s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.900103\ttraining's macroF1: 0.62966\tvalid_1's multi_logloss: 1.02022\tvalid_1's macroF1: 0.423215\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's multi_logloss: 1.21688\ttraining's macroF1: 0.514418\tvalid_1's multi_logloss: 1.20131\tvalid_1's macroF1: 0.437517\n",
      "******************** Execution ended in 00h 00hm 17.75s ********************\n",
      "######################################## 27 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.32267\ttraining's macroF1: 0.466201\tvalid_1's multi_logloss: 1.30886\tvalid_1's macroF1: 0.375632\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 1.38354\ttraining's macroF1: 0.442107\tvalid_1's multi_logloss: 1.38272\tvalid_1's macroF1: 0.396125\n",
      "******************** Execution ended in 00h 00hm 13.08s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.32404\ttraining's macroF1: 0.445912\tvalid_1's multi_logloss: 1.30876\tvalid_1's macroF1: 0.37575\n",
      "[1000]\ttraining's multi_logloss: 1.27672\ttraining's macroF1: 0.45302\tvalid_1's multi_logloss: 1.25502\tvalid_1's macroF1: 0.384662\n",
      "[1500]\ttraining's multi_logloss: 1.23785\ttraining's macroF1: 0.467046\tvalid_1's multi_logloss: 1.21414\tvalid_1's macroF1: 0.381593\n",
      "Early stopping, best iteration is:\n",
      "[1309]\ttraining's multi_logloss: 1.25192\ttraining's macroF1: 0.457752\tvalid_1's multi_logloss: 1.22876\tvalid_1's macroF1: 0.389631\n",
      "******************** Execution ended in 00h 00hm 50.42s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.32526\ttraining's macroF1: 0.423247\tvalid_1's multi_logloss: 1.29571\tvalid_1's macroF1: 0.402794\n",
      "[1000]\ttraining's multi_logloss: 1.27813\ttraining's macroF1: 0.447483\tvalid_1's multi_logloss: 1.23302\tvalid_1's macroF1: 0.41928\n",
      "[1500]\ttraining's multi_logloss: 1.23922\ttraining's macroF1: 0.46292\tvalid_1's multi_logloss: 1.18697\tvalid_1's macroF1: 0.434301\n",
      "Early stopping, best iteration is:\n",
      "[1456]\ttraining's multi_logloss: 1.24234\ttraining's macroF1: 0.462386\tvalid_1's multi_logloss: 1.19049\tvalid_1's macroF1: 0.437653\n",
      "******************** Execution ended in 00h 00hm 53.16s ********************\n",
      "============================== 4 of 5 folds ==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.32573\ttraining's macroF1: 0.451068\tvalid_1's multi_logloss: 1.31\tvalid_1's macroF1: 0.378463\n",
      "Early stopping, best iteration is:\n",
      "[184]\ttraining's multi_logloss: 1.36171\ttraining's macroF1: 0.443836\tvalid_1's multi_logloss: 1.35464\tvalid_1's macroF1: 0.381564\n",
      "******************** Execution ended in 00h 00hm 16.77s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.32545\ttraining's macroF1: 0.448743\tvalid_1's multi_logloss: 1.30921\tvalid_1's macroF1: 0.382498\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 1.38473\ttraining's macroF1: 0.441047\tvalid_1's multi_logloss: 1.38426\tvalid_1's macroF1: 0.403817\n",
      "******************** Execution ended in 00h 00hm 13.51s ********************\n",
      "######################################## 28 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00468\ttraining's macroF1: 0.557537\tvalid_1's multi_logloss: 1.02728\tvalid_1's macroF1: 0.438479\n",
      "[1000]\ttraining's multi_logloss: 0.882283\ttraining's macroF1: 0.620587\tvalid_1's multi_logloss: 0.997989\tvalid_1's macroF1: 0.439278\n",
      "Early stopping, best iteration is:\n",
      "[545]\ttraining's multi_logloss: 0.990435\ttraining's macroF1: 0.566302\tvalid_1's multi_logloss: 1.02189\tvalid_1's macroF1: 0.446793\n",
      "******************** Execution ended in 00h 00hm 29.22s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.987234\ttraining's macroF1: 0.582053\tvalid_1's multi_logloss: 1.06967\tvalid_1's macroF1: 0.390397\n",
      "[1000]\ttraining's multi_logloss: 0.863193\ttraining's macroF1: 0.643614\tvalid_1's multi_logloss: 1.05334\tvalid_1's macroF1: 0.395001\n",
      "[1500]\ttraining's multi_logloss: 0.781491\ttraining's macroF1: 0.678656\tvalid_1's multi_logloss: 1.05335\tvalid_1's macroF1: 0.406942\n",
      "[2000]\ttraining's multi_logloss: 0.720059\ttraining's macroF1: 0.70802\tvalid_1's multi_logloss: 1.05042\tvalid_1's macroF1: 0.413028\n",
      "[2500]\ttraining's multi_logloss: 0.670909\ttraining's macroF1: 0.726234\tvalid_1's multi_logloss: 1.0516\tvalid_1's macroF1: 0.413885\n",
      "Early stopping, best iteration is:\n",
      "[2119]\ttraining's multi_logloss: 0.707503\ttraining's macroF1: 0.713199\tvalid_1's multi_logloss: 1.04965\tvalid_1's macroF1: 0.414354\n",
      "******************** Execution ended in 00h 01hm 06.19s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00301\ttraining's macroF1: 0.57219\tvalid_1's multi_logloss: 1.00033\tvalid_1's macroF1: 0.454877\n",
      "Early stopping, best iteration is:\n",
      "[340]\ttraining's multi_logloss: 1.06647\ttraining's macroF1: 0.546375\tvalid_1's multi_logloss: 1.0331\tvalid_1's macroF1: 0.46677\n",
      "******************** Execution ended in 00h 00hm 26.40s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.995237\ttraining's macroF1: 0.572275\tvalid_1's multi_logloss: 1.03007\tvalid_1's macroF1: 0.41955\n",
      "[1000]\ttraining's multi_logloss: 0.870522\ttraining's macroF1: 0.640409\tvalid_1's multi_logloss: 1.00672\tvalid_1's macroF1: 0.421861\n",
      "[1500]\ttraining's multi_logloss: 0.789133\ttraining's macroF1: 0.67663\tvalid_1's multi_logloss: 1.00065\tvalid_1's macroF1: 0.425072\n",
      "Early stopping, best iteration is:\n",
      "[1136]\ttraining's multi_logloss: 0.846228\ttraining's macroF1: 0.649103\tvalid_1's multi_logloss: 1.00311\tvalid_1's macroF1: 0.433756\n",
      "******************** Execution ended in 00h 00hm 47.23s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.980666\ttraining's macroF1: 0.578153\tvalid_1's multi_logloss: 1.08786\tvalid_1's macroF1: 0.368157\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 1.36565\ttraining's macroF1: 0.473431\tvalid_1's multi_logloss: 1.36128\tvalid_1's macroF1: 0.39687\n",
      "******************** Execution ended in 00h 00hm 16.22s ********************\n",
      "######################################## 29 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05103\ttraining's macroF1: 0.56314\tvalid_1's multi_logloss: 1.06125\tvalid_1's macroF1: 0.445167\n",
      "[1000]\ttraining's multi_logloss: 0.922331\ttraining's macroF1: 0.613248\tvalid_1's multi_logloss: 1.02118\tvalid_1's macroF1: 0.448341\n",
      "[1500]\ttraining's multi_logloss: 0.8393\ttraining's macroF1: 0.651698\tvalid_1's multi_logloss: 1.01198\tvalid_1's macroF1: 0.441208\n",
      "Early stopping, best iteration is:\n",
      "[1100]\ttraining's multi_logloss: 0.903637\ttraining's macroF1: 0.618482\tvalid_1's multi_logloss: 1.01833\tvalid_1's macroF1: 0.4561\n",
      "******************** Execution ended in 00h 00hm 47.22s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02681\ttraining's macroF1: 0.572257\tvalid_1's multi_logloss: 1.08343\tvalid_1's macroF1: 0.397332\n",
      "[1000]\ttraining's multi_logloss: 0.898731\ttraining's macroF1: 0.622673\tvalid_1's multi_logloss: 1.05569\tvalid_1's macroF1: 0.410431\n",
      "[1500]\ttraining's multi_logloss: 0.815955\ttraining's macroF1: 0.67039\tvalid_1's multi_logloss: 1.05446\tvalid_1's macroF1: 0.414496\n",
      "Early stopping, best iteration is:\n",
      "[1101]\ttraining's multi_logloss: 0.879934\ttraining's macroF1: 0.635232\tvalid_1's multi_logloss: 1.05444\tvalid_1's macroF1: 0.420175\n",
      "******************** Execution ended in 00h 00hm 50.69s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03434\ttraining's macroF1: 0.566004\tvalid_1's multi_logloss: 1.08436\tvalid_1's macroF1: 0.385409\n",
      "[1000]\ttraining's multi_logloss: 0.908338\ttraining's macroF1: 0.618458\tvalid_1's multi_logloss: 1.04407\tvalid_1's macroF1: 0.394661\n",
      "Early stopping, best iteration is:\n",
      "[720]\ttraining's multi_logloss: 0.969207\ttraining's macroF1: 0.588573\tvalid_1's multi_logloss: 1.05763\tvalid_1's macroF1: 0.407882\n",
      "******************** Execution ended in 00h 00hm 38.26s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.04098\ttraining's macroF1: 0.549276\tvalid_1's multi_logloss: 1.02498\tvalid_1's macroF1: 0.431868\n",
      "Early stopping, best iteration is:\n",
      "[288]\ttraining's multi_logloss: 1.13168\ttraining's macroF1: 0.521758\tvalid_1's multi_logloss: 1.09343\tvalid_1's macroF1: 0.441568\n",
      "******************** Execution ended in 00h 00hm 24.50s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03587\ttraining's macroF1: 0.565991\tvalid_1's multi_logloss: 1.10951\tvalid_1's macroF1: 0.390991\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's multi_logloss: 1.25989\ttraining's macroF1: 0.510121\tvalid_1's multi_logloss: 1.25913\tvalid_1's macroF1: 0.407104\n",
      "******************** Execution ended in 00h 00hm 20.75s ********************\n",
      "######################################## 30 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02547\ttraining's macroF1: 0.566854\tvalid_1's multi_logloss: 1.08166\tvalid_1's macroF1: 0.376618\n",
      "[1000]\ttraining's multi_logloss: 0.894436\ttraining's macroF1: 0.613541\tvalid_1's multi_logloss: 1.05516\tvalid_1's macroF1: 0.377698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's multi_logloss: 0.811432\ttraining's macroF1: 0.665782\tvalid_1's multi_logloss: 1.05277\tvalid_1's macroF1: 0.386865\n",
      "Early stopping, best iteration is:\n",
      "[1161]\ttraining's multi_logloss: 0.864513\ttraining's macroF1: 0.633565\tvalid_1's multi_logloss: 1.05317\tvalid_1's macroF1: 0.404978\n",
      "******************** Execution ended in 00h 00hm 48.72s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03637\ttraining's macroF1: 0.563748\tvalid_1's multi_logloss: 1.07612\tvalid_1's macroF1: 0.419754\n",
      "[1000]\ttraining's multi_logloss: 0.90835\ttraining's macroF1: 0.612842\tvalid_1's multi_logloss: 1.03891\tvalid_1's macroF1: 0.391778\n",
      "Early stopping, best iteration is:\n",
      "[513]\ttraining's multi_logloss: 1.03148\ttraining's macroF1: 0.563371\tvalid_1's multi_logloss: 1.07421\tvalid_1's macroF1: 0.420106\n",
      "******************** Execution ended in 00h 00hm 30.49s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03811\ttraining's macroF1: 0.569678\tvalid_1's multi_logloss: 1.09035\tvalid_1's macroF1: 0.388063\n",
      "[1000]\ttraining's multi_logloss: 0.908934\ttraining's macroF1: 0.622721\tvalid_1's multi_logloss: 1.05499\tvalid_1's macroF1: 0.392397\n",
      "[1500]\ttraining's multi_logloss: 0.826864\ttraining's macroF1: 0.661415\tvalid_1's multi_logloss: 1.04531\tvalid_1's macroF1: 0.399989\n",
      "Early stopping, best iteration is:\n",
      "[1366]\ttraining's multi_logloss: 0.846922\ttraining's macroF1: 0.651622\tvalid_1's multi_logloss: 1.04781\tvalid_1's macroF1: 0.405348\n",
      "******************** Execution ended in 00h 01hm 05.61s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.04964\ttraining's macroF1: 0.564792\tvalid_1's multi_logloss: 1.0583\tvalid_1's macroF1: 0.449465\n",
      "[1000]\ttraining's multi_logloss: 0.918175\ttraining's macroF1: 0.632109\tvalid_1's multi_logloss: 1.01318\tvalid_1's macroF1: 0.462725\n",
      "Early stopping, best iteration is:\n",
      "[718]\ttraining's multi_logloss: 0.983411\ttraining's macroF1: 0.59325\tvalid_1's multi_logloss: 1.02808\tvalid_1's macroF1: 0.474515\n",
      "******************** Execution ended in 00h 00hm 38.31s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.04152\ttraining's macroF1: 0.571997\tvalid_1's multi_logloss: 1.0585\tvalid_1's macroF1: 0.411438\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's multi_logloss: 1.35044\ttraining's macroF1: 0.479388\tvalid_1's multi_logloss: 1.34157\tvalid_1's macroF1: 0.427106\n",
      "******************** Execution ended in 00h 00hm 17.65s ********************\n",
      "######################################## 31 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03575\ttraining's macroF1: 0.533501\tvalid_1's multi_logloss: 1.0427\tvalid_1's macroF1: 0.40639\n",
      "[1000]\ttraining's multi_logloss: 0.946765\ttraining's macroF1: 0.575516\tvalid_1's multi_logloss: 1.03494\tvalid_1's macroF1: 0.427779\n",
      "Early stopping, best iteration is:\n",
      "[924]\ttraining's multi_logloss: 0.95805\ttraining's macroF1: 0.569943\tvalid_1's multi_logloss: 1.03488\tvalid_1's macroF1: 0.432192\n",
      "******************** Execution ended in 00h 00hm 25.62s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02351\ttraining's macroF1: 0.533494\tvalid_1's multi_logloss: 1.05871\tvalid_1's macroF1: 0.383095\n",
      "[1000]\ttraining's multi_logloss: 0.932947\ttraining's macroF1: 0.572234\tvalid_1's multi_logloss: 1.05764\tvalid_1's macroF1: 0.383339\n",
      "Early stopping, best iteration is:\n",
      "[732]\ttraining's multi_logloss: 0.975351\ttraining's macroF1: 0.552582\tvalid_1's multi_logloss: 1.05771\tvalid_1's macroF1: 0.397003\n",
      "******************** Execution ended in 00h 00hm 21.42s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02996\ttraining's macroF1: 0.533861\tvalid_1's multi_logloss: 1.063\tvalid_1's macroF1: 0.422089\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's multi_logloss: 1.18601\ttraining's macroF1: 0.479403\tvalid_1's multi_logloss: 1.13839\tvalid_1's macroF1: 0.429481\n",
      "******************** Execution ended in 00h 00hm 11.28s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01178\ttraining's macroF1: 0.537605\tvalid_1's multi_logloss: 1.06632\tvalid_1's macroF1: 0.407252\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's multi_logloss: 1.0131\ttraining's macroF1: 0.535774\tvalid_1's multi_logloss: 1.06688\tvalid_1's macroF1: 0.411419\n",
      "******************** Execution ended in 00h 00hm 18.73s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02596\ttraining's macroF1: 0.523811\tvalid_1's multi_logloss: 1.08041\tvalid_1's macroF1: 0.434634\n",
      "[1000]\ttraining's multi_logloss: 0.935032\ttraining's macroF1: 0.574305\tvalid_1's multi_logloss: 1.06832\tvalid_1's macroF1: 0.405891\n",
      "Early stopping, best iteration is:\n",
      "[624]\ttraining's multi_logloss: 0.999414\ttraining's macroF1: 0.540549\tvalid_1's multi_logloss: 1.07719\tvalid_1's macroF1: 0.445665\n",
      "******************** Execution ended in 00h 00hm 22.13s ********************\n",
      "######################################## 32 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01671\ttraining's macroF1: 0.55479\tvalid_1's multi_logloss: 1.0582\tvalid_1's macroF1: 0.397147\n",
      "Early stopping, best iteration is:\n",
      "[358]\ttraining's multi_logloss: 1.06061\ttraining's macroF1: 0.533798\tvalid_1's multi_logloss: 1.07176\tvalid_1's macroF1: 0.401836\n",
      "******************** Execution ended in 00h 00hm 14.37s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00917\ttraining's macroF1: 0.543202\tvalid_1's multi_logloss: 1.05032\tvalid_1's macroF1: 0.400405\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's multi_logloss: 1.19291\ttraining's macroF1: 0.484455\tvalid_1's multi_logloss: 1.15475\tvalid_1's macroF1: 0.414551\n",
      "******************** Execution ended in 00h 00hm 12.02s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01777\ttraining's macroF1: 0.546218\tvalid_1's multi_logloss: 1.01684\tvalid_1's macroF1: 0.435931\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's multi_logloss: 1.19206\ttraining's macroF1: 0.481797\tvalid_1's multi_logloss: 1.12087\tvalid_1's macroF1: 0.445883\n",
      "******************** Execution ended in 00h 00hm 10.51s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01147\ttraining's macroF1: 0.553566\tvalid_1's multi_logloss: 1.07673\tvalid_1's macroF1: 0.388671\n",
      "[1000]\ttraining's multi_logloss: 0.907872\ttraining's macroF1: 0.604949\tvalid_1's multi_logloss: 1.06981\tvalid_1's macroF1: 0.381601\n",
      "Early stopping, best iteration is:\n",
      "[599]\ttraining's multi_logloss: 0.98609\ttraining's macroF1: 0.564663\tvalid_1's multi_logloss: 1.07048\tvalid_1's macroF1: 0.401987\n",
      "******************** Execution ended in 00h 00hm 18.24s ********************\n",
      "============================== 5 of 5 folds ==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00721\ttraining's macroF1: 0.551771\tvalid_1's multi_logloss: 1.03298\tvalid_1's macroF1: 0.433904\n",
      "Early stopping, best iteration is:\n",
      "[440]\ttraining's multi_logloss: 1.02496\ttraining's macroF1: 0.546462\tvalid_1's multi_logloss: 1.03587\tvalid_1's macroF1: 0.444432\n",
      "******************** Execution ended in 00h 00hm 16.53s ********************\n",
      "######################################## 33 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.0822\ttraining's macroF1: 0.508492\tvalid_1's multi_logloss: 1.0726\tvalid_1's macroF1: 0.415569\n",
      "Early stopping, best iteration is:\n",
      "[433]\ttraining's multi_logloss: 1.09828\ttraining's macroF1: 0.50161\tvalid_1's multi_logloss: 1.07782\tvalid_1's macroF1: 0.419936\n",
      "******************** Execution ended in 00h 00hm 21.63s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07349\ttraining's macroF1: 0.51102\tvalid_1's multi_logloss: 1.0793\tvalid_1's macroF1: 0.393853\n",
      "[1000]\ttraining's multi_logloss: 0.991742\ttraining's macroF1: 0.551456\tvalid_1's multi_logloss: 1.06561\tvalid_1's macroF1: 0.403261\n",
      "Early stopping, best iteration is:\n",
      "[988]\ttraining's multi_logloss: 0.993235\ttraining's macroF1: 0.549406\tvalid_1's multi_logloss: 1.06564\tvalid_1's macroF1: 0.406155\n",
      "******************** Execution ended in 00h 00hm 27.42s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09244\ttraining's macroF1: 0.511124\tvalid_1's multi_logloss: 1.07484\tvalid_1's macroF1: 0.416559\n",
      "[1000]\ttraining's multi_logloss: 1.01167\ttraining's macroF1: 0.54511\tvalid_1's multi_logloss: 1.04924\tvalid_1's macroF1: 0.410579\n",
      "Early stopping, best iteration is:\n",
      "[515]\ttraining's multi_logloss: 1.08914\ttraining's macroF1: 0.511694\tvalid_1's multi_logloss: 1.07351\tvalid_1's macroF1: 0.421321\n",
      "******************** Execution ended in 00h 00hm 20.57s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07046\ttraining's macroF1: 0.509282\tvalid_1's multi_logloss: 1.06899\tvalid_1's macroF1: 0.377472\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's multi_logloss: 1.33694\ttraining's macroF1: 0.432173\tvalid_1's multi_logloss: 1.31953\tvalid_1's macroF1: 0.401837\n",
      "******************** Execution ended in 00h 00hm 12.38s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07871\ttraining's macroF1: 0.510353\tvalid_1's multi_logloss: 1.08725\tvalid_1's macroF1: 0.402163\n",
      "[1000]\ttraining's multi_logloss: 0.997364\ttraining's macroF1: 0.552437\tvalid_1's multi_logloss: 1.07258\tvalid_1's macroF1: 0.405217\n",
      "[1500]\ttraining's multi_logloss: 0.943222\ttraining's macroF1: 0.579087\tvalid_1's multi_logloss: 1.07154\tvalid_1's macroF1: 0.411552\n",
      "Early stopping, best iteration is:\n",
      "[1078]\ttraining's multi_logloss: 0.988031\ttraining's macroF1: 0.554521\tvalid_1's multi_logloss: 1.06911\tvalid_1's macroF1: 0.407852\n",
      "******************** Execution ended in 00h 00hm 33.91s ********************\n",
      "######################################## 34 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.852234\ttraining's macroF1: 0.650822\tvalid_1's multi_logloss: 1.05239\tvalid_1's macroF1: 0.431011\n",
      "Early stopping, best iteration is:\n",
      "[339]\ttraining's multi_logloss: 0.92949\ttraining's macroF1: 0.608981\tvalid_1's multi_logloss: 1.06078\tvalid_1's macroF1: 0.440722\n",
      "******************** Execution ended in 00h 00hm 26.36s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.847053\ttraining's macroF1: 0.646211\tvalid_1's multi_logloss: 1.02727\tvalid_1's macroF1: 0.408629\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's multi_logloss: 0.978665\ttraining's macroF1: 0.578757\tvalid_1's multi_logloss: 1.04365\tvalid_1's macroF1: 0.420797\n",
      "******************** Execution ended in 00h 00hm 23.92s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.852742\ttraining's macroF1: 0.64836\tvalid_1's multi_logloss: 0.998733\tvalid_1's macroF1: 0.398557\n",
      "Early stopping, best iteration is:\n",
      "[340]\ttraining's multi_logloss: 0.927533\ttraining's macroF1: 0.614477\tvalid_1's multi_logloss: 1.00879\tvalid_1's macroF1: 0.420141\n",
      "******************** Execution ended in 00h 00hm 25.62s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.849625\ttraining's macroF1: 0.645769\tvalid_1's multi_logloss: 1.01497\tvalid_1's macroF1: 0.41569\n",
      "[1000]\ttraining's multi_logloss: 0.697249\ttraining's macroF1: 0.71957\tvalid_1's multi_logloss: 1.00083\tvalid_1's macroF1: 0.415297\n",
      "Early stopping, best iteration is:\n",
      "[907]\ttraining's multi_logloss: 0.719134\ttraining's macroF1: 0.710806\tvalid_1's multi_logloss: 1.00386\tvalid_1's macroF1: 0.426808\n",
      "******************** Execution ended in 00h 00hm 40.14s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.845161\ttraining's macroF1: 0.64668\tvalid_1's multi_logloss: 1.02901\tvalid_1's macroF1: 0.428614\n",
      "[1000]\ttraining's multi_logloss: 0.696357\ttraining's macroF1: 0.712922\tvalid_1's multi_logloss: 1.02995\tvalid_1's macroF1: 0.415175\n",
      "Early stopping, best iteration is:\n",
      "[614]\ttraining's multi_logloss: 0.803475\ttraining's macroF1: 0.661447\tvalid_1's multi_logloss: 1.02818\tvalid_1's macroF1: 0.433045\n",
      "******************** Execution ended in 00h 00hm 31.43s ********************\n",
      "######################################## 35 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.993955\ttraining's macroF1: 0.562904\tvalid_1's multi_logloss: 1.09696\tvalid_1's macroF1: 0.385846\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's multi_logloss: 1.33179\ttraining's macroF1: 0.449854\tvalid_1's multi_logloss: 1.31345\tvalid_1's macroF1: 0.399675\n",
      "******************** Execution ended in 00h 00hm 13.52s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.992036\ttraining's macroF1: 0.56286\tvalid_1's multi_logloss: 1.08386\tvalid_1's macroF1: 0.381783\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's multi_logloss: 1.28408\ttraining's macroF1: 0.459901\tvalid_1's multi_logloss: 1.26436\tvalid_1's macroF1: 0.409909\n",
      "******************** Execution ended in 00h 00hm 11.51s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00671\ttraining's macroF1: 0.552331\tvalid_1's multi_logloss: 1.03167\tvalid_1's macroF1: 0.422495\n",
      "Early stopping, best iteration is:\n",
      "[454]\ttraining's multi_logloss: 1.01988\ttraining's macroF1: 0.543686\tvalid_1's multi_logloss: 1.0327\tvalid_1's macroF1: 0.432632\n",
      "******************** Execution ended in 00h 00hm 20.44s ********************\n",
      "============================== 4 of 5 folds ==============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00322\ttraining's macroF1: 0.558358\tvalid_1's multi_logloss: 1.02263\tvalid_1's macroF1: 0.398597\n",
      "Early stopping, best iteration is:\n",
      "[419]\ttraining's multi_logloss: 1.02704\ttraining's macroF1: 0.54469\tvalid_1's multi_logloss: 1.02661\tvalid_1's macroF1: 0.406338\n",
      "******************** Execution ended in 00h 00hm 20.13s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00135\ttraining's macroF1: 0.55323\tvalid_1's multi_logloss: 1.04631\tvalid_1's macroF1: 0.431711\n",
      "[1000]\ttraining's multi_logloss: 0.899989\ttraining's macroF1: 0.597275\tvalid_1's multi_logloss: 1.03441\tvalid_1's macroF1: 0.424828\n",
      "Early stopping, best iteration is:\n",
      "[604]\ttraining's multi_logloss: 0.974869\ttraining's macroF1: 0.564847\tvalid_1's multi_logloss: 1.04184\tvalid_1's macroF1: 0.440739\n",
      "******************** Execution ended in 00h 00hm 24.69s ********************\n",
      "######################################## 36 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02671\ttraining's macroF1: 0.549716\tvalid_1's multi_logloss: 1.08695\tvalid_1's macroF1: 0.397077\n",
      "[1000]\ttraining's multi_logloss: 0.915676\ttraining's macroF1: 0.605712\tvalid_1's multi_logloss: 1.05963\tvalid_1's macroF1: 0.412251\n",
      "[1500]\ttraining's multi_logloss: 0.843588\ttraining's macroF1: 0.640565\tvalid_1's multi_logloss: 1.05241\tvalid_1's macroF1: 0.42853\n",
      "Early stopping, best iteration is:\n",
      "[1442]\ttraining's multi_logloss: 0.851023\ttraining's macroF1: 0.634471\tvalid_1's multi_logloss: 1.05292\tvalid_1's macroF1: 0.428836\n",
      "******************** Execution ended in 00h 00hm 54.06s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02434\ttraining's macroF1: 0.566324\tvalid_1's multi_logloss: 1.08966\tvalid_1's macroF1: 0.37778\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's multi_logloss: 1.0629\ttraining's macroF1: 0.554748\tvalid_1's multi_logloss: 1.09945\tvalid_1's macroF1: 0.387581\n",
      "******************** Execution ended in 00h 00hm 25.74s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03086\ttraining's macroF1: 0.548459\tvalid_1's multi_logloss: 1.0719\tvalid_1's macroF1: 0.404111\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's multi_logloss: 1.14711\ttraining's macroF1: 0.506022\tvalid_1's multi_logloss: 1.13681\tvalid_1's macroF1: 0.421858\n",
      "******************** Execution ended in 00h 00hm 21.49s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03228\ttraining's macroF1: 0.522869\tvalid_1's multi_logloss: 1.05535\tvalid_1's macroF1: 0.415793\n",
      "[1000]\ttraining's multi_logloss: 0.920531\ttraining's macroF1: 0.586345\tvalid_1's multi_logloss: 1.01557\tvalid_1's macroF1: 0.427112\n",
      "[1500]\ttraining's multi_logloss: 0.846027\ttraining's macroF1: 0.627567\tvalid_1's multi_logloss: 1.00096\tvalid_1's macroF1: 0.442998\n",
      "[2000]\ttraining's multi_logloss: 0.789581\ttraining's macroF1: 0.651106\tvalid_1's multi_logloss: 0.994948\tvalid_1's macroF1: 0.447645\n",
      "Early stopping, best iteration is:\n",
      "[1819]\ttraining's multi_logloss: 0.808374\ttraining's macroF1: 0.645252\tvalid_1's multi_logloss: 0.99667\tvalid_1's macroF1: 0.451907\n",
      "******************** Execution ended in 00h 01hm 07.64s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.0307\ttraining's macroF1: 0.543153\tvalid_1's multi_logloss: 1.04543\tvalid_1's macroF1: 0.418474\n",
      "[1000]\ttraining's multi_logloss: 0.917415\ttraining's macroF1: 0.599318\tvalid_1's multi_logloss: 1.01972\tvalid_1's macroF1: 0.410708\n",
      "Early stopping, best iteration is:\n",
      "[764]\ttraining's multi_logloss: 0.96267\ttraining's macroF1: 0.574199\tvalid_1's multi_logloss: 1.02661\tvalid_1's macroF1: 0.423688\n",
      "******************** Execution ended in 00h 00hm 39.67s ********************\n",
      "######################################## 37 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01677\ttraining's macroF1: 0.541014\tvalid_1's multi_logloss: 1.06643\tvalid_1's macroF1: 0.397879\n",
      "[1000]\ttraining's multi_logloss: 0.920849\ttraining's macroF1: 0.593936\tvalid_1's multi_logloss: 1.05459\tvalid_1's macroF1: 0.404775\n",
      "[1500]\ttraining's multi_logloss: 0.857921\ttraining's macroF1: 0.633913\tvalid_1's multi_logloss: 1.04542\tvalid_1's macroF1: 0.406045\n",
      "Early stopping, best iteration is:\n",
      "[1077]\ttraining's multi_logloss: 0.910298\ttraining's macroF1: 0.601878\tvalid_1's multi_logloss: 1.05344\tvalid_1's macroF1: 0.409374\n",
      "******************** Execution ended in 00h 00hm 25.66s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02148\ttraining's macroF1: 0.541474\tvalid_1's multi_logloss: 1.04569\tvalid_1's macroF1: 0.402946\n",
      "[1000]\ttraining's multi_logloss: 0.923904\ttraining's macroF1: 0.596695\tvalid_1's multi_logloss: 1.03571\tvalid_1's macroF1: 0.406555\n",
      "[1500]\ttraining's multi_logloss: 0.856777\ttraining's macroF1: 0.625932\tvalid_1's multi_logloss: 1.03828\tvalid_1's macroF1: 0.400253\n",
      "Early stopping, best iteration is:\n",
      "[1036]\ttraining's multi_logloss: 0.918596\ttraining's macroF1: 0.600556\tvalid_1's multi_logloss: 1.03417\tvalid_1's macroF1: 0.410518\n",
      "******************** Execution ended in 00h 00hm 25.74s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00758\ttraining's macroF1: 0.548429\tvalid_1's multi_logloss: 1.0627\tvalid_1's macroF1: 0.396696\n",
      "[1000]\ttraining's multi_logloss: 0.910971\ttraining's macroF1: 0.585479\tvalid_1's multi_logloss: 1.05512\tvalid_1's macroF1: 0.396986\n",
      "Early stopping, best iteration is:\n",
      "[868]\ttraining's multi_logloss: 0.932159\ttraining's macroF1: 0.581217\tvalid_1's multi_logloss: 1.0556\tvalid_1's macroF1: 0.413977\n",
      "******************** Execution ended in 00h 00hm 23.30s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01919\ttraining's macroF1: 0.531981\tvalid_1's multi_logloss: 1.07474\tvalid_1's macroF1: 0.41185\n",
      "Early stopping, best iteration is:\n",
      "[383]\ttraining's multi_logloss: 1.05268\ttraining's macroF1: 0.516398\tvalid_1's multi_logloss: 1.08166\tvalid_1's macroF1: 0.425535\n",
      "******************** Execution ended in 00h 00hm 15.68s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01178\ttraining's macroF1: 0.533939\tvalid_1's multi_logloss: 1.0669\tvalid_1's macroF1: 0.397909\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's multi_logloss: 1.11954\ttraining's macroF1: 0.50005\tvalid_1's multi_logloss: 1.09802\tvalid_1's macroF1: 0.421943\n",
      "******************** Execution ended in 00h 00hm 12.78s ********************\n",
      "######################################## 38 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05383\ttraining's macroF1: 0.552114\tvalid_1's multi_logloss: 1.06229\tvalid_1's macroF1: 0.425461\n",
      "[1000]\ttraining's multi_logloss: 0.933959\ttraining's macroF1: 0.607429\tvalid_1's multi_logloss: 1.02575\tvalid_1's macroF1: 0.432307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's multi_logloss: 0.855132\ttraining's macroF1: 0.639923\tvalid_1's multi_logloss: 1.02189\tvalid_1's macroF1: 0.419514\n",
      "Early stopping, best iteration is:\n",
      "[1151]\ttraining's multi_logloss: 0.908306\ttraining's macroF1: 0.615028\tvalid_1's multi_logloss: 1.02364\tvalid_1's macroF1: 0.439037\n",
      "******************** Execution ended in 00h 00hm 46.06s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03343\ttraining's macroF1: 0.562409\tvalid_1's multi_logloss: 1.10655\tvalid_1's macroF1: 0.374947\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's multi_logloss: 1.3374\ttraining's macroF1: 0.482194\tvalid_1's multi_logloss: 1.33366\tvalid_1's macroF1: 0.38403\n",
      "******************** Execution ended in 00h 00hm 14.69s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.04092\ttraining's macroF1: 0.573427\tvalid_1's multi_logloss: 1.05798\tvalid_1's macroF1: 0.424174\n",
      "[1000]\ttraining's multi_logloss: 0.923455\ttraining's macroF1: 0.612582\tvalid_1's multi_logloss: 1.01882\tvalid_1's macroF1: 0.433451\n",
      "[1500]\ttraining's multi_logloss: 0.84667\ttraining's macroF1: 0.657833\tvalid_1's multi_logloss: 1.00497\tvalid_1's macroF1: 0.43474\n",
      "[2000]\ttraining's multi_logloss: 0.787182\ttraining's macroF1: 0.683583\tvalid_1's multi_logloss: 0.997645\tvalid_1's macroF1: 0.433394\n",
      "Early stopping, best iteration is:\n",
      "[1647]\ttraining's multi_logloss: 0.82776\ttraining's macroF1: 0.667925\tvalid_1's multi_logloss: 1.00283\tvalid_1's macroF1: 0.438878\n",
      "******************** Execution ended in 00h 00hm 55.24s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05851\ttraining's macroF1: 0.540001\tvalid_1's multi_logloss: 1.02842\tvalid_1's macroF1: 0.445449\n",
      "[1000]\ttraining's multi_logloss: 0.942961\ttraining's macroF1: 0.598999\tvalid_1's multi_logloss: 0.975758\tvalid_1's macroF1: 0.443242\n",
      "Early stopping, best iteration is:\n",
      "[764]\ttraining's multi_logloss: 0.989809\ttraining's macroF1: 0.569216\tvalid_1's multi_logloss: 0.991565\tvalid_1's macroF1: 0.457084\n",
      "******************** Execution ended in 00h 00hm 33.50s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.04009\ttraining's macroF1: 0.565106\tvalid_1's multi_logloss: 1.0805\tvalid_1's macroF1: 0.389318\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's multi_logloss: 1.14847\ttraining's macroF1: 0.533054\tvalid_1's multi_logloss: 1.14562\tvalid_1's macroF1: 0.408682\n",
      "******************** Execution ended in 00h 00hm 19.24s ********************\n",
      "######################################## 39 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.744887\ttraining's macroF1: 0.728834\tvalid_1's multi_logloss: 1.01988\tvalid_1's macroF1: 0.40288\n",
      "[1000]\ttraining's multi_logloss: 0.56334\ttraining's macroF1: 0.798168\tvalid_1's multi_logloss: 0.997805\tvalid_1's macroF1: 0.419331\n",
      "[1500]\ttraining's multi_logloss: 0.465834\ttraining's macroF1: 0.82516\tvalid_1's multi_logloss: 0.990013\tvalid_1's macroF1: 0.42712\n",
      "[2000]\ttraining's multi_logloss: 0.404464\ttraining's macroF1: 0.85563\tvalid_1's multi_logloss: 0.987939\tvalid_1's macroF1: 0.435266\n",
      "Early stopping, best iteration is:\n",
      "[1799]\ttraining's multi_logloss: 0.42586\ttraining's macroF1: 0.844553\tvalid_1's multi_logloss: 0.988636\tvalid_1's macroF1: 0.438515\n",
      "******************** Execution ended in 00h 01hm 28.50s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.755738\ttraining's macroF1: 0.71878\tvalid_1's multi_logloss: 0.994929\tvalid_1's macroF1: 0.369756\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's multi_logloss: 1.07641\ttraining's macroF1: 0.586625\tvalid_1's multi_logloss: 1.12217\tvalid_1's macroF1: 0.41653\n",
      "******************** Execution ended in 00h 00hm 24.63s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.754211\ttraining's macroF1: 0.730514\tvalid_1's multi_logloss: 1.02537\tvalid_1's macroF1: 0.419636\n",
      "Early stopping, best iteration is:\n",
      "[164]\ttraining's multi_logloss: 1.0284\ttraining's macroF1: 0.62492\tvalid_1's multi_logloss: 1.09698\tvalid_1's macroF1: 0.42417\n",
      "******************** Execution ended in 00h 00hm 27.14s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.741282\ttraining's macroF1: 0.72615\tvalid_1's multi_logloss: 1.0115\tvalid_1's macroF1: 0.397502\n",
      "[1000]\ttraining's multi_logloss: 0.55931\ttraining's macroF1: 0.807697\tvalid_1's multi_logloss: 0.990654\tvalid_1's macroF1: 0.402929\n",
      "Early stopping, best iteration is:\n",
      "[644]\ttraining's multi_logloss: 0.674446\ttraining's macroF1: 0.758213\tvalid_1's multi_logloss: 1.00111\tvalid_1's macroF1: 0.411027\n",
      "******************** Execution ended in 00h 00hm 46.20s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.74753\ttraining's macroF1: 0.711923\tvalid_1's multi_logloss: 1.02889\tvalid_1's macroF1: 0.393124\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttraining's multi_logloss: 0.886041\ttraining's macroF1: 0.665659\tvalid_1's multi_logloss: 1.0531\tvalid_1's macroF1: 0.407809\n",
      "******************** Execution ended in 00h 00hm 34.12s ********************\n",
      "######################################## 40 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.996406\ttraining's macroF1: 0.610451\tvalid_1's multi_logloss: 1.05479\tvalid_1's macroF1: 0.436863\n",
      "Early stopping, best iteration is:\n",
      "[488]\ttraining's multi_logloss: 1.00152\ttraining's macroF1: 0.610156\tvalid_1's multi_logloss: 1.05715\tvalid_1's macroF1: 0.437574\n",
      "******************** Execution ended in 00h 00hm 33.88s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.988754\ttraining's macroF1: 0.6215\tvalid_1's multi_logloss: 1.07304\tvalid_1's macroF1: 0.397766\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's multi_logloss: 1.31686\ttraining's macroF1: 0.536649\tvalid_1's multi_logloss: 1.31342\tvalid_1's macroF1: 0.431839\n",
      "******************** Execution ended in 00h 00hm 21.29s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.994214\ttraining's macroF1: 0.629102\tvalid_1's multi_logloss: 1.04089\tvalid_1's macroF1: 0.411555\n",
      "[1000]\ttraining's multi_logloss: 0.837709\ttraining's macroF1: 0.689634\tvalid_1's multi_logloss: 0.987492\tvalid_1's macroF1: 0.41716\n",
      "[1500]\ttraining's multi_logloss: 0.734775\ttraining's macroF1: 0.734572\tvalid_1's multi_logloss: 0.972339\tvalid_1's macroF1: 0.426651\n",
      "Early stopping, best iteration is:\n",
      "[1418]\ttraining's multi_logloss: 0.74953\ttraining's macroF1: 0.729404\tvalid_1's multi_logloss: 0.973896\tvalid_1's macroF1: 0.430636\n",
      "******************** Execution ended in 00h 01hm 05.05s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.989218\ttraining's macroF1: 0.641572\tvalid_1's multi_logloss: 1.09091\tvalid_1's macroF1: 0.398737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's multi_logloss: 0.832529\ttraining's macroF1: 0.699132\tvalid_1's multi_logloss: 1.04056\tvalid_1's macroF1: 0.405762\n",
      "Early stopping, best iteration is:\n",
      "[612]\ttraining's multi_logloss: 0.94564\ttraining's macroF1: 0.657669\tvalid_1's multi_logloss: 1.07217\tvalid_1's macroF1: 0.41403\n",
      "******************** Execution ended in 00h 00hm 39.87s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.992057\ttraining's macroF1: 0.619816\tvalid_1's multi_logloss: 1.0606\tvalid_1's macroF1: 0.39053\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's multi_logloss: 1.30842\ttraining's macroF1: 0.547442\tvalid_1's multi_logloss: 1.30183\tvalid_1's macroF1: 0.400937\n",
      "******************** Execution ended in 00h 00hm 17.57s ********************\n",
      "######################################## 41 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.08011\ttraining's macroF1: 0.528648\tvalid_1's multi_logloss: 1.06536\tvalid_1's macroF1: 0.421445\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttraining's multi_logloss: 1.19636\ttraining's macroF1: 0.5013\tvalid_1's multi_logloss: 1.15962\tvalid_1's macroF1: 0.434116\n",
      "******************** Execution ended in 00h 00hm 16.12s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.06853\ttraining's macroF1: 0.536143\tvalid_1's multi_logloss: 1.09022\tvalid_1's macroF1: 0.403448\n",
      "[1000]\ttraining's multi_logloss: 0.966549\ttraining's macroF1: 0.572656\tvalid_1's multi_logloss: 1.06585\tvalid_1's macroF1: 0.42179\n",
      "Early stopping, best iteration is:\n",
      "[757]\ttraining's multi_logloss: 1.00838\ttraining's macroF1: 0.556495\tvalid_1's multi_logloss: 1.07128\tvalid_1's macroF1: 0.434198\n",
      "******************** Execution ended in 00h 00hm 28.11s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05866\ttraining's macroF1: 0.559752\tvalid_1's multi_logloss: 1.10264\tvalid_1's macroF1: 0.376037\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's multi_logloss: 1.38155\ttraining's macroF1: 0.423281\tvalid_1's multi_logloss: 1.38016\tvalid_1's macroF1: 0.391942\n",
      "******************** Execution ended in 00h 00hm 10.98s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.06788\ttraining's macroF1: 0.541688\tvalid_1's multi_logloss: 1.0442\tvalid_1's macroF1: 0.403771\n",
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's multi_logloss: 1.1971\ttraining's macroF1: 0.513047\tvalid_1's multi_logloss: 1.1469\tvalid_1's macroF1: 0.41156\n",
      "******************** Execution ended in 00h 00hm 15.66s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07542\ttraining's macroF1: 0.538842\tvalid_1's multi_logloss: 1.0572\tvalid_1's macroF1: 0.431802\n",
      "[1000]\ttraining's multi_logloss: 0.973592\ttraining's macroF1: 0.578426\tvalid_1's multi_logloss: 1.02455\tvalid_1's macroF1: 0.423984\n",
      "Early stopping, best iteration is:\n",
      "[640]\ttraining's multi_logloss: 1.04006\ttraining's macroF1: 0.54648\tvalid_1's multi_logloss: 1.04116\tvalid_1's macroF1: 0.443351\n",
      "******************** Execution ended in 00h 00hm 38.97s ********************\n",
      "######################################## 42 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.955196\ttraining's macroF1: 0.562282\tvalid_1's multi_logloss: 1.05877\tvalid_1's macroF1: 0.382147\n",
      "Early stopping, best iteration is:\n",
      "[310]\ttraining's multi_logloss: 1.02017\ttraining's macroF1: 0.53182\tvalid_1's multi_logloss: 1.07263\tvalid_1's macroF1: 0.389184\n",
      "******************** Execution ended in 00h 00hm 23.34s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.950641\ttraining's macroF1: 0.582961\tvalid_1's multi_logloss: 1.00472\tvalid_1's macroF1: 0.399096\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's multi_logloss: 1.23832\ttraining's macroF1: 0.475625\tvalid_1's multi_logloss: 1.19022\tvalid_1's macroF1: 0.41609\n",
      "******************** Execution ended in 00h 00hm 14.04s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.955874\ttraining's macroF1: 0.571457\tvalid_1's multi_logloss: 1.06693\tvalid_1's macroF1: 0.402562\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's multi_logloss: 1.25641\ttraining's macroF1: 0.459752\tvalid_1's multi_logloss: 1.22813\tvalid_1's macroF1: 0.408631\n",
      "******************** Execution ended in 00h 00hm 15.12s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.956309\ttraining's macroF1: 0.581868\tvalid_1's multi_logloss: 1.05807\tvalid_1's macroF1: 0.450698\n",
      "Early stopping, best iteration is:\n",
      "[482]\ttraining's multi_logloss: 0.961761\ttraining's macroF1: 0.577648\tvalid_1's multi_logloss: 1.0578\tvalid_1's macroF1: 0.452365\n",
      "******************** Execution ended in 00h 00hm 25.12s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.950835\ttraining's macroF1: 0.577075\tvalid_1's multi_logloss: 1.06421\tvalid_1's macroF1: 0.409264\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's multi_logloss: 1.15733\ttraining's macroF1: 0.494577\tvalid_1's multi_logloss: 1.14174\tvalid_1's macroF1: 0.424674\n",
      "******************** Execution ended in 00h 00hm 15.74s ********************\n",
      "######################################## 43 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02826\ttraining's macroF1: 0.532045\tvalid_1's multi_logloss: 1.0474\tvalid_1's macroF1: 0.393664\n",
      "Early stopping, best iteration is:\n",
      "[301]\ttraining's multi_logloss: 1.08997\ttraining's macroF1: 0.501556\tvalid_1's multi_logloss: 1.07454\tvalid_1's macroF1: 0.405689\n",
      "******************** Execution ended in 00h 00hm 15.90s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02737\ttraining's macroF1: 0.54245\tvalid_1's multi_logloss: 1.07637\tvalid_1's macroF1: 0.400639\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's multi_logloss: 1.36659\ttraining's macroF1: 0.434252\tvalid_1's multi_logloss: 1.35748\tvalid_1's macroF1: 0.406741\n",
      "******************** Execution ended in 00h 00hm 10.75s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02939\ttraining's macroF1: 0.553651\tvalid_1's multi_logloss: 1.07179\tvalid_1's macroF1: 0.41958\n",
      "Early stopping, best iteration is:\n",
      "[295]\ttraining's multi_logloss: 1.09844\ttraining's macroF1: 0.522319\tvalid_1's multi_logloss: 1.09467\tvalid_1's macroF1: 0.429951\n",
      "******************** Execution ended in 00h 00hm 17.17s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.0308\ttraining's macroF1: 0.519255\tvalid_1's multi_logloss: 1.05197\tvalid_1's macroF1: 0.419775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's multi_logloss: 1.2408\ttraining's macroF1: 0.467019\tvalid_1's multi_logloss: 1.19559\tvalid_1's macroF1: 0.436337\n",
      "******************** Execution ended in 00h 00hm 13.19s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02193\ttraining's macroF1: 0.538434\tvalid_1's multi_logloss: 1.09459\tvalid_1's macroF1: 0.38199\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttraining's multi_logloss: 1.04971\ttraining's macroF1: 0.525631\tvalid_1's multi_logloss: 1.09851\tvalid_1's macroF1: 0.394088\n",
      "******************** Execution ended in 00h 00hm 18.63s ********************\n",
      "######################################## 44 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.906039\ttraining's macroF1: 0.621015\tvalid_1's multi_logloss: 1.04174\tvalid_1's macroF1: 0.398086\n",
      "Early stopping, best iteration is:\n",
      "[404]\ttraining's multi_logloss: 0.946457\ttraining's macroF1: 0.598531\tvalid_1's multi_logloss: 1.04901\tvalid_1's macroF1: 0.407009\n",
      "******************** Execution ended in 00h 00hm 22.68s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.900023\ttraining's macroF1: 0.61754\tvalid_1's multi_logloss: 1.07415\tvalid_1's macroF1: 0.381574\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's multi_logloss: 1.35512\ttraining's macroF1: 0.481305\tvalid_1's multi_logloss: 1.35272\tvalid_1's macroF1: 0.393546\n",
      "******************** Execution ended in 00h 00hm 13.39s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.909752\ttraining's macroF1: 0.609205\tvalid_1's multi_logloss: 1.04044\tvalid_1's macroF1: 0.420315\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttraining's multi_logloss: 0.949967\ttraining's macroF1: 0.586103\tvalid_1's multi_logloss: 1.04917\tvalid_1's macroF1: 0.434993\n",
      "******************** Execution ended in 00h 00hm 23.53s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.916846\ttraining's macroF1: 0.616842\tvalid_1's multi_logloss: 1.01495\tvalid_1's macroF1: 0.41987\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's multi_logloss: 1.37139\ttraining's macroF1: 0.455074\tvalid_1's multi_logloss: 1.36749\tvalid_1's macroF1: 0.445943\n",
      "******************** Execution ended in 00h 00hm 15.98s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.905638\ttraining's macroF1: 0.615648\tvalid_1's multi_logloss: 1.01624\tvalid_1's macroF1: 0.402911\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's multi_logloss: 1.08099\ttraining's macroF1: 0.545919\tvalid_1's multi_logloss: 1.08645\tvalid_1's macroF1: 0.417949\n",
      "******************** Execution ended in 00h 00hm 16.82s ********************\n",
      "######################################## 45 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03776\ttraining's macroF1: 0.537302\tvalid_1's multi_logloss: 1.05305\tvalid_1's macroF1: 0.391374\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 1.36583\ttraining's macroF1: 0.4411\tvalid_1's multi_logloss: 1.35786\tvalid_1's macroF1: 0.411507\n",
      "******************** Execution ended in 00h 00hm 13.26s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03601\ttraining's macroF1: 0.544485\tvalid_1's multi_logloss: 1.06732\tvalid_1's macroF1: 0.400342\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's multi_logloss: 1.2851\ttraining's macroF1: 0.482071\tvalid_1's multi_logloss: 1.26413\tvalid_1's macroF1: 0.429392\n",
      "******************** Execution ended in 00h 00hm 15.02s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03208\ttraining's macroF1: 0.547847\tvalid_1's multi_logloss: 1.03913\tvalid_1's macroF1: 0.408839\n",
      "[1000]\ttraining's multi_logloss: 0.922015\ttraining's macroF1: 0.602142\tvalid_1's multi_logloss: 1.02345\tvalid_1's macroF1: 0.41261\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's multi_logloss: 0.980069\ttraining's macroF1: 0.573121\tvalid_1's multi_logloss: 1.02734\tvalid_1's macroF1: 0.422646\n",
      "******************** Execution ended in 00h 00hm 32.45s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02937\ttraining's macroF1: 0.534353\tvalid_1's multi_logloss: 1.06443\tvalid_1's macroF1: 0.381606\n",
      "[1000]\ttraining's multi_logloss: 0.929313\ttraining's macroF1: 0.589828\tvalid_1's multi_logloss: 1.04253\tvalid_1's macroF1: 0.397611\n",
      "Early stopping, best iteration is:\n",
      "[845]\ttraining's multi_logloss: 0.954736\ttraining's macroF1: 0.575378\tvalid_1's multi_logloss: 1.04599\tvalid_1's macroF1: 0.399753\n",
      "******************** Execution ended in 00h 00hm 34.54s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03385\ttraining's macroF1: 0.541867\tvalid_1's multi_logloss: 1.08739\tvalid_1's macroF1: 0.405939\n",
      "Early stopping, best iteration is:\n",
      "[157]\ttraining's multi_logloss: 1.19453\ttraining's macroF1: 0.490066\tvalid_1's multi_logloss: 1.17613\tvalid_1's macroF1: 0.426928\n",
      "******************** Execution ended in 00h 00hm 16.46s ********************\n",
      "######################################## 46 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.990998\ttraining's macroF1: 0.563582\tvalid_1's multi_logloss: 1.06162\tvalid_1's macroF1: 0.379606\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's multi_logloss: 1.16949\ttraining's macroF1: 0.509137\tvalid_1's multi_logloss: 1.14837\tvalid_1's macroF1: 0.405086\n",
      "******************** Execution ended in 00h 00hm 13.90s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.996107\ttraining's macroF1: 0.564805\tvalid_1's multi_logloss: 1.01831\tvalid_1's macroF1: 0.425597\n",
      "[1000]\ttraining's multi_logloss: 0.888122\ttraining's macroF1: 0.61768\tvalid_1's multi_logloss: 0.998431\tvalid_1's macroF1: 0.413044\n",
      "Early stopping, best iteration is:\n",
      "[681]\ttraining's multi_logloss: 0.951378\ttraining's macroF1: 0.581912\tvalid_1's multi_logloss: 1.00716\tvalid_1's macroF1: 0.43923\n",
      "******************** Execution ended in 00h 00hm 26.75s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.989186\ttraining's macroF1: 0.564125\tvalid_1's multi_logloss: 1.07049\tvalid_1's macroF1: 0.396395\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's multi_logloss: 1.09921\ttraining's macroF1: 0.518754\tvalid_1's multi_logloss: 1.10299\tvalid_1's macroF1: 0.412277\n",
      "******************** Execution ended in 00h 00hm 15.56s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's multi_logloss: 1.001\ttraining's macroF1: 0.557184\tvalid_1's multi_logloss: 1.04656\tvalid_1's macroF1: 0.421612\n",
      "[1000]\ttraining's multi_logloss: 0.888269\ttraining's macroF1: 0.604892\tvalid_1's multi_logloss: 1.0336\tvalid_1's macroF1: 0.424329\n",
      "Early stopping, best iteration is:\n",
      "[868]\ttraining's multi_logloss: 0.912893\ttraining's macroF1: 0.59222\tvalid_1's multi_logloss: 1.03458\tvalid_1's macroF1: 0.438452\n",
      "******************** Execution ended in 00h 00hm 30.82s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.997987\ttraining's macroF1: 0.560056\tvalid_1's multi_logloss: 1.04512\tvalid_1's macroF1: 0.400122\n",
      "Early stopping, best iteration is:\n",
      "[429]\ttraining's multi_logloss: 1.02058\ttraining's macroF1: 0.552914\tvalid_1's multi_logloss: 1.05051\tvalid_1's macroF1: 0.414318\n",
      "******************** Execution ended in 00h 00hm 19.41s ********************\n",
      "######################################## 47 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.992126\ttraining's macroF1: 0.552009\tvalid_1's multi_logloss: 1.05054\tvalid_1's macroF1: 0.382892\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's multi_logloss: 1.15265\ttraining's macroF1: 0.493028\tvalid_1's multi_logloss: 1.11944\tvalid_1's macroF1: 0.393994\n",
      "******************** Execution ended in 00h 00hm 15.20s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00229\ttraining's macroF1: 0.55499\tvalid_1's multi_logloss: 1.01458\tvalid_1's macroF1: 0.451779\n",
      "[1000]\ttraining's multi_logloss: 0.898363\ttraining's macroF1: 0.6091\tvalid_1's multi_logloss: 0.992843\tvalid_1's macroF1: 0.448195\n",
      "Early stopping, best iteration is:\n",
      "[682]\ttraining's multi_logloss: 0.959849\ttraining's macroF1: 0.575525\tvalid_1's multi_logloss: 1.00042\tvalid_1's macroF1: 0.464197\n",
      "******************** Execution ended in 00h 00hm 23.11s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.982752\ttraining's macroF1: 0.551062\tvalid_1's multi_logloss: 1.0712\tvalid_1's macroF1: 0.390846\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's multi_logloss: 1.1792\ttraining's macroF1: 0.487169\tvalid_1's multi_logloss: 1.15031\tvalid_1's macroF1: 0.411127\n",
      "******************** Execution ended in 00h 00hm 13.93s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.978925\ttraining's macroF1: 0.564089\tvalid_1's multi_logloss: 1.05413\tvalid_1's macroF1: 0.391635\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's multi_logloss: 1.25478\ttraining's macroF1: 0.47612\tvalid_1's multi_logloss: 1.21567\tvalid_1's macroF1: 0.409676\n",
      "******************** Execution ended in 00h 00hm 15.06s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.990145\ttraining's macroF1: 0.556839\tvalid_1's multi_logloss: 1.0656\tvalid_1's macroF1: 0.410021\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's multi_logloss: 1.05434\ttraining's macroF1: 0.528657\tvalid_1's multi_logloss: 1.08026\tvalid_1's macroF1: 0.4288\n",
      "******************** Execution ended in 00h 00hm 18.05s ********************\n",
      "######################################## 48 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.923793\ttraining's macroF1: 0.685499\tvalid_1's multi_logloss: 1.08456\tvalid_1's macroF1: 0.414998\n",
      "[1000]\ttraining's multi_logloss: 0.741375\ttraining's macroF1: 0.743885\tvalid_1's multi_logloss: 1.03646\tvalid_1's macroF1: 0.41033\n",
      "[1500]\ttraining's multi_logloss: 0.627098\ttraining's macroF1: 0.788946\tvalid_1's multi_logloss: 1.0235\tvalid_1's macroF1: 0.423976\n",
      "[2000]\ttraining's multi_logloss: 0.545805\ttraining's macroF1: 0.815501\tvalid_1's multi_logloss: 1.0142\tvalid_1's macroF1: 0.423264\n",
      "[2500]\ttraining's multi_logloss: 0.484\ttraining's macroF1: 0.836929\tvalid_1's multi_logloss: 1.00804\tvalid_1's macroF1: 0.433489\n",
      "[3000]\ttraining's multi_logloss: 0.437195\ttraining's macroF1: 0.859489\tvalid_1's multi_logloss: 1.00442\tvalid_1's macroF1: 0.431708\n",
      "Early stopping, best iteration is:\n",
      "[2521]\ttraining's multi_logloss: 0.481757\ttraining's macroF1: 0.837376\tvalid_1's multi_logloss: 1.00783\tvalid_1's macroF1: 0.437513\n",
      "******************** Execution ended in 00h 01hm 57.51s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.924044\ttraining's macroF1: 0.673847\tvalid_1's multi_logloss: 1.02381\tvalid_1's macroF1: 0.419491\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's multi_logloss: 1.38068\ttraining's macroF1: 0.525539\tvalid_1's multi_logloss: 1.38025\tvalid_1's macroF1: 0.426382\n",
      "******************** Execution ended in 00h 00hm 23.28s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.910188\ttraining's macroF1: 0.686039\tvalid_1's multi_logloss: 1.05313\tvalid_1's macroF1: 0.412453\n",
      "[1000]\ttraining's multi_logloss: 0.722115\ttraining's macroF1: 0.745742\tvalid_1's multi_logloss: 0.994992\tvalid_1's macroF1: 0.403105\n",
      "Early stopping, best iteration is:\n",
      "[579]\ttraining's multi_logloss: 0.871519\ttraining's macroF1: 0.69422\tvalid_1's multi_logloss: 1.0383\tvalid_1's macroF1: 0.429939\n",
      "******************** Execution ended in 00h 00hm 44.87s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.91646\ttraining's macroF1: 0.675344\tvalid_1's multi_logloss: 1.08996\tvalid_1's macroF1: 0.359068\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_logloss: 1.36673\ttraining's macroF1: 0.557012\tvalid_1's multi_logloss: 1.36878\tvalid_1's macroF1: 0.376389\n",
      "******************** Execution ended in 00h 00hm 18.31s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.920504\ttraining's macroF1: 0.686953\tvalid_1's multi_logloss: 1.07457\tvalid_1's macroF1: 0.388753\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's multi_logloss: 1.23048\ttraining's macroF1: 0.602619\tvalid_1's multi_logloss: 1.25627\tvalid_1's macroF1: 0.400214\n",
      "******************** Execution ended in 00h 00hm 25.08s ********************\n",
      "######################################## 49 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.6674\ttraining's macroF1: 0.754632\tvalid_1's multi_logloss: 1.02318\tvalid_1's macroF1: 0.407913\n",
      "Early stopping, best iteration is:\n",
      "[286]\ttraining's multi_logloss: 0.812421\ttraining's macroF1: 0.70062\tvalid_1's multi_logloss: 1.03935\tvalid_1's macroF1: 0.43078\n",
      "******************** Execution ended in 00h 00hm 24.06s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.665848\ttraining's macroF1: 0.754978\tvalid_1's multi_logloss: 1.00465\tvalid_1's macroF1: 0.415097\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's multi_logloss: 0.810964\ttraining's macroF1: 0.703249\tvalid_1's multi_logloss: 1.0218\tvalid_1's macroF1: 0.441774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Execution ended in 00h 00hm 27.10s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.677019\ttraining's macroF1: 0.746144\tvalid_1's multi_logloss: 0.955075\tvalid_1's macroF1: 0.410817\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's multi_logloss: 0.889573\ttraining's macroF1: 0.671404\tvalid_1's multi_logloss: 1.00153\tvalid_1's macroF1: 0.449394\n",
      "******************** Execution ended in 00h 00hm 23.27s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.670395\ttraining's macroF1: 0.759203\tvalid_1's multi_logloss: 1.00607\tvalid_1's macroF1: 0.385483\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's multi_logloss: 1.09127\ttraining's macroF1: 0.608531\tvalid_1's multi_logloss: 1.12175\tvalid_1's macroF1: 0.411377\n",
      "******************** Execution ended in 00h 00hm 18.77s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.664407\ttraining's macroF1: 0.745588\tvalid_1's multi_logloss: 0.996957\tvalid_1's macroF1: 0.410021\n",
      "Early stopping, best iteration is:\n",
      "[363]\ttraining's multi_logloss: 0.748582\ttraining's macroF1: 0.71147\tvalid_1's multi_logloss: 1.00424\tvalid_1's macroF1: 0.428769\n",
      "******************** Execution ended in 00h 00hm 29.84s ********************\n",
      "######################################## 50 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12398\ttraining's macroF1: 0.501095\tvalid_1's multi_logloss: 1.09582\tvalid_1's macroF1: 0.383045\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's multi_logloss: 1.25119\ttraining's macroF1: 0.460179\tvalid_1's multi_logloss: 1.21176\tvalid_1's macroF1: 0.39134\n",
      "******************** Execution ended in 00h 00hm 12.08s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12101\ttraining's macroF1: 0.486921\tvalid_1's multi_logloss: 1.08568\tvalid_1's macroF1: 0.389132\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's multi_logloss: 1.22422\ttraining's macroF1: 0.454533\tvalid_1's multi_logloss: 1.17279\tvalid_1's macroF1: 0.413679\n",
      "******************** Execution ended in 00h 00hm 12.91s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12525\ttraining's macroF1: 0.476238\tvalid_1's multi_logloss: 1.08915\tvalid_1's macroF1: 0.399241\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's multi_logloss: 1.3265\ttraining's macroF1: 0.432023\tvalid_1's multi_logloss: 1.29889\tvalid_1's macroF1: 0.421274\n",
      "******************** Execution ended in 00h 00hm 11.54s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12943\ttraining's macroF1: 0.489734\tvalid_1's multi_logloss: 1.08623\tvalid_1's macroF1: 0.404816\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's multi_logloss: 1.37838\ttraining's macroF1: 0.409837\tvalid_1's multi_logloss: 1.3755\tvalid_1's macroF1: 0.424393\n",
      "******************** Execution ended in 00h 00hm 10.53s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12373\ttraining's macroF1: 0.482527\tvalid_1's multi_logloss: 1.11435\tvalid_1's macroF1: 0.388009\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's multi_logloss: 1.30449\ttraining's macroF1: 0.453599\tvalid_1's multi_logloss: 1.27447\tvalid_1's macroF1: 0.406146\n",
      "******************** Execution ended in 00h 00hm 13.95s ********************\n"
     ]
    }
   ],
   "source": [
    "total_shap_df  = pd.DataFrame()\n",
    "NUM_ITERATIONS = 50\n",
    "for SEED in range(NUM_ITERATIONS):\n",
    "    print('#'*40, '{} of {} iterations'.format(SEED+1, NUM_ITERATIONS), '#' * 40)\n",
    "    params = {'max_depth': np.random.choice([5, 6, 7, 8, 10, 12, -1]),\n",
    "             'learning_rate': np.random.rand() * 0.02,\n",
    "              'colsample_bytree': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'subsample': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'min_split_gain': np.random.rand() * 0.2,\n",
    "              'num_leaves': np.random.choice([32, 48, 64]),\n",
    "              'reg_alpha': np.random.rand() * 2,\n",
    "              'reg_lambda': np.random.rand() *2,\n",
    "              'bagging_freq': np.random.randint(4) +1,\n",
    "              'min_child_weight': np.random.randint(100) + 20\n",
    "             }\n",
    "    temp_shap_df = extract_good_features_using_shap_LGB(params, SEED)\n",
    "    total_shap_df = pd.concat([total_shap_df, temp_shap_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sorted_df = total_shap_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "feat_imp_sorted_df = total_shap_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n",
    "features_top_shap = shap_sorted_df['feature'][:500]\n",
    "features_top_feat_imp = feat_imp_sorted_df['feature'][:500]\n",
    "top_features = pd.Series(features_top_shap.tolist() + features_top_feat_imp.tolist())\n",
    "top_features = top_features.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4. Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_feautures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-18dd5bb9dd32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnew_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_feautures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'top_feautures' is not defined"
     ]
    }
   ],
   "source": [
    "new_train = train[top_features].copy()\n",
    "new_test = test[top_feautures].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new_train shape: ', new_train.shape, 'new_test shape: ', new_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorical_feats = [col for col in top_features if col in categorical_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_OOF(params, categorical_feats, N_FOLDs, SEED=1989):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 10\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "    predicts_result = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(new_train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = new_train.iloc[train_index], new_train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb,categorical_feature=new_categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        predicts_result.append(clf.predict(new_test))\n",
    "        print_execution_time(start)\n",
    "    return predicts_result, feat_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 6,\n",
    "         'learning_rate': 0.002,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_split_gain': 0.02,\n",
    "          'num_leaves': 48,\n",
    "          'reg_alpha': 0.04,\n",
    "          'reg_lambda': 0.073,\n",
    "          'bagging_freq': 2,\n",
    "          'min_child_weight': 40\n",
    "         }\n",
    "\n",
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "predicts_result, feat_importance_df = LGB_OOF(params, new_categorical_feats, N_Folds, SEED=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (20, 20))\n",
    "\n",
    "feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending = False).reset_index()\n",
    "\n",
    "num_features = 50\n",
    "sns.barplot(x=feat_importance_df_shap.shap_values[:num_features], y = feat_importance_df_shap.feature[:num_features], ax = ax[0])\n",
    "ax[0].set_title('Feature importance based on shap values')\n",
    "\n",
    "feat_importance_df = feat_importance_df.groupby('feature').mean().sort_values('feat_imp', ascending = False).reset_index()\n",
    "\n",
    "num_features= 50\n",
    "sns.barplot(x = feat_importance_df.shap_values[:num_features], y = feat_importance_df.feature[:num_features], ax=ax[1])\n",
    "\n",
    "ax[1].set_title('Feature importance based on feature importance from lgbm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predictions_result).mean(axis = 0).round().astype(int)\n",
    "\n",
    "# submission.to_csv('submission_with_new_feature_set.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_param = None\n",
    "lowest_cv = 1000\n",
    "total_iteration = 100\n",
    "\n",
    "for i in range(total_iteration):\n",
    "    print('-'*20, 'For {} of {} iterations'.format(i+1, total_iteration), '-'*20)\n",
    "    learning_rate = np.random.rand() * 0.02\n",
    "    n_folds = 3\n",
    "    \n",
    "    num_class = len(np.unique(y))\n",
    "    \n",
    "    params = {}\n",
    "    params['application'] = 'multiclass'\n",
    "    params['metric'] = 'multi_logloss'\n",
    "    params['num_class'] = num_class\n",
    "    params['class_weight'] = 'balanced'\n",
    "    params['num_leaves'] = np.random.randint(24, 48)\n",
    "    params['max_depth'] = np.random.randint(5, 8)\n",
    "    params['min_child_weight'] = np.random.randint(5, 50)\n",
    "    params['min_split_gain'] = np.random.rand() * 0.09\n",
    "    params['colsample_bytree'] = np.random.rand() * (0.9 - 0.1) + 0.1\n",
    "    params['subsample'] = np.random.rand() * (1 - 0.8) + 0.8\n",
    "    params['bagging_freq'] = np.random.randint(1, 5)\n",
    "    params['bagging_seed'] = np.random.randint(1, 5)\n",
    "    params['reg_alpha'] = np.random.rand() * 2\n",
    "    params['reg_lambda'] = np.random.rand() * 2\n",
    "    params['learning_rate'] = np.random.rand() * 0.02\n",
    "    params['seed']  =1989\n",
    "    \n",
    "    d_train = lgb.Dataset(data = new_train, label = y.values -1, categorical_feature = new_categorical_feats, free_raw_data = False)\n",
    "    cv_results = lgb.cv(params = params, train_set = d_train, num_boost_round = 10000, categorical_feature = new_categorical_feats, nfold = n_folds, stratified = True, shuffle = True, early_stopping_rounds = 1, verbose_eval = 1000)\n",
    "    \n",
    "    min_cv_results = min(cv_results['multi_logloss-mean'])\n",
    "    \n",
    "    if min_cv_results < lowest_cv:\n",
    "        lowest_cv = min_cv_results\n",
    "        optimized_param = params\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "\n",
    "predicts_result, feat_importance_df = LGB_OOF(optimized_param, new_categorical_feats, N_Folds, SEED = 1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissin['Target'] = np.array(predicts_result).mean(axis = 0)\n",
    "\n",
    "round().astype(int)\n",
    "# submission.to_csv('submission_shap_randomized_search.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
